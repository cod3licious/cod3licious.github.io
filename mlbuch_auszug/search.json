[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Practitioner‚Äôs Guide to Machine Learning",
    "section": "",
    "text": "Vorwort",
    "crumbs": [
      "Vorwort"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "A Practitioner‚Äôs Guide to Machine Learning",
    "section": "",
    "text": "Buchcover mit einer Zeichnung eines Teils einer Siphonophorae (einer Quallenart) von Ernst Haeckel aus seinem Buch ‚ÄúKunstformen der Natur‚Äù (1900, Tafel 37; Quelle: www.BioLib.de).‚Ü©Ô∏é",
    "crumbs": [
      "Vorwort"
    ]
  },
  {
    "objectID": "01a_intro.html",
    "href": "01a_intro.html",
    "title": "Einleitung",
    "section": "",
    "text": "ML ist √ºberall!\nDieses Kapitel illustriert mit verschiedenen motivierenden Beispiele den Aufstieg von Machine Learning (ML).\nMaschinelles Lernen wird bereits √ºberall um uns herum verwendet, um unser Leben bequemer zu machen:",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "01a_intro.html#sec-ml-everywhere",
    "href": "01a_intro.html#sec-ml-everywhere",
    "title": "Einleitung",
    "section": "",
    "text": "Gesichtserkennung\nEine der ersten Erfolgsgeschichten aus dem Bereich maschinelles Lernen und Computer Vision ist die Gesichtserkennungstechnologie, welche heutzutage in jeder Digitalkamera und jedem Smartphone verbaut ist.\nW√§hrend die in einer Kameraanwendung implementierten Algorithmen ziemlich einfach sind und nur Gesichter im Allgemeinen erkennen, um sicherzustellen, dass man bei der Aufnahme gut zu sehen ist, werden in immer mehr L√§ndern auch ausgefeiltere Algorithmen von Regierungen und Strafverfolgungsbeh√∂rden verwendet, um ein erkanntes Gesicht einer bekannten Person in ihren biometrischen Datenbanken zuzuordnen, um beispielsweise um Kriminelle zu identifizieren. Also ‚Ä¶bitte l√§cheln!?\n\n\n\nQuelle: https://thesocietypages.org/socimages/2008/12/15/nikon-s60-auto-focuses-on-voyeurs-savages-ghosts/ (15.12.2008)\n\n\n\n\nObjekterkennung (z.B. f√ºr autonomes Fahren)\nEin weiteres Beispiel aus dem Bereich Computer Vision ist die Objekterkennung oder die Bildsegmentierung im Allgemeinen. Dies wird beispielsweise in selbstfahrenden Autos verwendet, um sicherzustellen, dass Stra√üenschilder und Fu√üg√§nger erkannt werden.\n\n\n\nQuelle: https://medium.com/intro-to-artificial-intelligence/c01eb6eaf9d (16.06.2018)\n\n\n\n\nAnalyse von medizinischen Bildern\nEin abschlie√üendes Beispiel f√ºr die Auswertung von Bilddaten stammt aus dem Anwendungsbereich Medizin: Unten sind zwei Aufnahmen von der Netzhaut abgebildet, anhand derer eine h√§ufige Diabetes-Komplikation diagnostiziert werden kann. Unbehandelt kann diese zu Blindheit f√ºhren.\nDer Diagnosealgorithmus zur Erkennung von Krankheitsmarkern in solchen Bildern wurde von Forschern bei Google entwickelt und hat die gleiche Genauigkeit wie menschliche Experten auf diesem Gebiet. Google hatte sogar ein Team von Top-Spezialisten zusammengestellt, um die schwierigsten F√§lle noch einmal zu besprechen und einheitliche Labels f√ºr alle Bilder zu generieren, wodurch sie ihr Modell noch weiter verbessern konnten.\nDa die Ger√§te zur Aufnahme dieser Bilder relativ g√ºnstig sind, k√∂nnen mit diesem ML-Modell Experten-Diagnoseentscheidungen auch denjenigen zug√§nglich gemacht werden, die sonst eventuell nicht die M√∂glichkeit haben, einen Top-Spezialisten zu konsultieren.\n\n\n\nQuelle: https://ai.googleblog.com/2016/11/deep-learning-for-detection-of-diabetic.html (29.11.2016)\n\n\n\n\nSprachassistenten (oder genau genommen: Spracherkennung‚Ä¶)\nGenug zu Computer Vision; nun ein Beispiel aus dem Bereich Natural Language Processing (NLP; ‚ÄúVerarbeitung nat√ºrlicher Sprache‚Äù): Sprachassistenten, wie Siri oder Alexa, warten bei vielen Menschen zu Hause auf Befehle. W√§hrend einige der Antworten, die sie geben, noch von Menschen geschrieben wurden (wie im Screenshot unten), besteht die eigentliche Herausforderung darin, zu verstehen, was die Person tats√§chlich sagt. Die Spracherkennung, also das automatische Transkribieren gesprochener Sprache in Text, ist ein ziemlich schwieriges Problem, da Menschen z.B. in verschiedenen Dialekten sprechen und zus√§tzliche Hintergrundger√§usche auftreten k√∂nnen.\n\n\n\nScreenshot: Siri von macOS (13.12.2018)\n\n\n\n\nMaschinelle √úbersetzung\nNochmal aus dem Bereich NLP: Maschinelle √úbersetzung, also das automatische √úbersetzen von Texten in eine andere Sprache.\nFalls du Google Translate (als Beispiel im Screenshot unten gezeigt) kurz nach seiner Erscheinung 2006 verwendet hast, warst du wahrscheinlich meistens ziemlich entt√§uscht von den Ergebnissen. Die √úbersetzungen klangen so als h√§tte jemand die W√∂rter nur nacheinander in einem W√∂rterbuch nachgeschlagen (= statistische maschinelle √úbersetzung). Dies √§nderte sich 10 Jahre sp√§ter im Jahr 2016 als Google anfing, die √úbersetzungen mit einem neuronalen Netzmodell zu generieren: Jetzt sind die √ºbersetzten Texte tats√§chlich lesbar und erfordern in der Regel nur noch geringf√ºgige manuelle Korrekturen, wenn √ºberhaupt.\n\n\n\nScreenshot: https://translate.google.com/ (13.12.2018)\n\n\n\n\nEmpfehlungssysteme (Recommender Systems)\nEin weiteres ML-Anwendungsgebiet sind Empfehlungssysteme, z.B. auf E-Commerce-Plattformen wie Amazon (siehe Screenshot unten), die dem Nutzer (idealerweise) hilfreiche Suchergebnisse und Vorschl√§ge liefern, wodurch die jeweiligen Unternehmen wiederum Ums√§tze generieren. Auch Social Media Plattformen, Netflix, YouTube & Co fesseln ihre Nutzer damit l√§nger an den Bildschirm.\nManchmal helfen die generierten Vorschl√§ge dem Nutzer genau das zu finden, wonach er gesucht hat. Aber insbesondere Plattformen mit nicht-kuratierten Inhalten wie YouTube wurden in der Vergangenheit kritisiert, da sie durch personalisierte Empfehlungen unter anderem die Verbreitung von Verschw√∂rungstheorien f√∂rderten. Da diese Art von Inhalten ein besonderes Suchtpotential haben, wurden sie h√§ufiger empfohlen und trieben die Nutzer dadurch weiter in den postfaktischen Sumpf, anstatt auch Perspektiven au√üerhalb der eigenen Informationsblase anzubieten.\nAuf der anderen Seite hat die Erforschung von Empfehlungssystemen aber auch Entwicklungen in anderen Wissenschaftsbereichen befl√ºgelt. Zum Beispiel kann die Suche nach Heilmitteln f√ºr Krankheiten beschleunigt werden, indem Wirkstoffmolek√ºle empfohlen werden, die zu den Proteinen passen, die eine Schl√ºsselrolle in der Krankheit spielen.\n\n\n\n\n\n\n\n\nScreenshot: https://www.amazon.com/ (12.12.2018)\n\n\n\n\nBesser als der Mensch: AlphaGo\nIm Jahr 2016 pr√§sentierte DeepMind, ein sp√§ter von Google √ºbernommenes Startup, AlphaGo, das erste Computerprogramm, das einen menschlichen Go-Meister besiegte.\nDies war ein gro√üer Meilenstein f√ºr die KI-Forschungsgemeinschaft. Go ist mit einem Spielfeld von 19 x 19 Feldern viel komplexer als Schach (8 x 8 Felder und restriktivere Bewegungsmuster) und selbst die optimistischsten KI-Forscher hatten nicht erwartet, dass ein Computer vor 2020 gegen einen Go-Meister gewinnen k√∂nnte.\nDie in AlphaGo verwendeten Algorithmen stammen aus dem Teilgebiet des Reinforcement Learning, auf das wir sp√§ter noch genauer eingehen.\n\n\n\nQuelle: https://www.nature.com/nature/volumes/529/issues/7587 (28.01.2016)\n\n\n\n\nProteinfaltung ‚Äì ein 50 Jahre altes Problem ist gel√∂st\nIm Jahr 2020 konnte DeepMind eine weitere Erfolgsgeschichte erz√§hlen: Ihr AlphaFold-Modell kann die 3D-Struktur von Proteinen aus ihrer urspr√ºnglichen Aminos√§uresequenz bestimmen ‚Äì und zwar genauso akkurat wie traditionelle Simulationsmodelle.\nProteine spielen oft eine Schl√ºsselrolle in Krankheiten. Kennt man die 3D-Struktur eines Proteins, kann man bestimmen, welche Wirkstoffmolek√ºle an dieses Protein binden k√∂nnen. Dadurch k√∂nnen Zielstrukturen identifiziert werden, die weiter untersucht werden sollten, um ein Heilmittel f√ºr die entsprechende Krankheit zu finden.\nZwar gab es die exakten Simulationsmodelle zur Berechnung der 3D-Struktur eines Proteins schon l√§nger, diese waren jedoch sehr langsam und es dauerte oft mehrere Tage, um die Faltung eines einzelnen Proteins zu berechnen. Mit dem neuen neuronalen Netzmodell kann dieselbe Berechnung jetzt in Minuten oder sogar Sekunden durchgef√ºhrt werden, wodurch die Medikamentenentwicklung enorm beschleunigt wurde.\n\n\n\nQuelle: https://deepmind.google/discover/blog/alphafold-using-ai-for-scientific-discovery-2020/ (15.01.2020)\n\n\n\n\nNeuronale Netze werden kreativ\nViele unterhaltsame Anwendungen verwenden neuronale Netze, um neue Inhalte zu generieren, d.h. kreative T√§tigkeiten auszuf√ºhren, die bisher ausschlie√ülich den Menschen vorbehalten schienen.\nZum Beispiel hat eine KI ein etwas verwirrendes, aber urkomisches Skript f√ºr einen Film geschrieben, der dann sogar produziert wurde.\nNeuronale Netze auch verwendet, um Musik zu visualisieren. Dabei werden passende Bilder kombiniert und flie√üend transformiert wie in diesem Video:\n\nUnd du hast wahrscheinlich auch schon einige Beispiele f√ºr ‚ÄúNeural Style Transfer‚Äù gesehen, eine Technik mit der man z.B. ein Social-Media-Profilbild wie ein Van-Gogh-Gem√§lde aussehen lassen kann:\n\n\n\nQuelle: https://pytorch.org (28.05.2022)\n\n\nAuch Stock-Fotos sind nun im Grunde obsolet, da man mit Hilfe neuronaler Netze Bilder aus einer Textbeschreibung generieren kann:\n\n\n\nScreenshot: https://imagen.research.google/ (28.05.2022)\n\n\nUnd Chatbots k√∂nnen Gespr√§che f√ºhren und Informationen in verschiedenen Formen wiedergeben:\n\n\n\nScreenshot: https://chat.openai.com/chat (04.01.2023)",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "01a_intro.html#sec-ml-history",
    "href": "01a_intro.html#sec-ml-history",
    "title": "Einleitung",
    "section": "ML Geschichte: Warum jetzt?",
    "text": "ML Geschichte: Warum jetzt?\nWarum gibt es einen solchen Anstieg von ML Anwendungen? Allgegenw√§rtig ist ML nicht nur in unserem Alltag, auch die Zahl der j√§hrlich ver√∂ffentlichten Forschungsarbeiten zu dem Thema ist exponentiell gestiegen:\n\n\n\nDatenquelle: https://www.webofknowledge.com/\n\n\nInteressanterweise liegt das aber nicht etwa an einer F√ºlle bahnbrechender theoretischer Errungenschaften in den letzten Jahren (in der Grafik als violette Rauten gekennzeichnet). Im Gegenteil: Viele der heute verwendeten Algorithmen wurden bereits Ende der 50er / Anfang der 60er Jahre entwickelt. So ist beispielsweise das Perzeptron der Vorl√§ufer von neuronalen Netzen, die hinter allen im letzten Abschnitt gezeigten Beispielen stecken. Einige der wichtigsten neuronalen Netzarchitekturen, Recurrent Neural Networks (RNN, ‚Äúrekurrente neuronale Netze‚Äù) und Convolutional Neural Networks (CNN, ‚Äúfaltende neuronale Netze‚Äù), welche die Grundlage f√ºr moderne Sprach- bzw. Bildverarbeitung bilden, wurden in den fr√ºhen 80er und 90er Jahren entwickelt. Aber zu dieser Zeit hatten wir noch nicht die Rechenressourcen, um diese Modelle f√ºr mehr als kleine Experimente zu verwenden.\nAufgrund dessen korreliert der Anstieg der ML-Publikationen st√§rker mit der Anzahl der Transistoren auf CPUs (also den regul√§ren Prozessoren in normalen Computern) und GPUs (Grafikkarten, die die Arten von Berechnungen parallelisieren, die zum effizienten Trainieren von neuronalen Netzwerkmodellen erforderlich sind):\n\n\n\nDatenquelle: https://en.wikipedia.org/wiki/Transistor_count\n\n\nDar√ºber hinaus hat die Ver√∂ffentlichung vieler Open-Source-Bibliotheken wie scikit-learn (f√ºr traditionelle ML-Modelle) und theano, tensorflow und (py)torch (f√ºr die Implementierung neuronaler Netze) die Verwendung von ML-Algorithmen in anderen Fachbereichen deutlich erleichtert.\n\n\n\n\n\n\nHinweisDemokratisierung von ML birgt auch Risiken\n\n\n\nEinerseits demokratisieren solche Bibliotheken die Verwendung von ML, andererseits resultiert eine Nutzung ohne Wissen √ºber die theoretischen Grundlagen auch in Fehlanwendungen. Die Modelle zeigen dann oft nicht die erwartete Performance, was zu (deplatzierter) Entt√§uschung f√ºhrt. Im ung√ºnstigsten Fall kann es passieren, dass die Modelle bestimmte Teile der Bev√∂lkerung diskriminieren, z.B. Kreditbewertungsalgorithmen, die von Banken verwendet werden und die aufgrund von Verzerrungen in den historischen Daten Frauen systematisch Kredite zu h√∂heren Zinss√§tzen anbieten als M√§nnern. Wir werden solche Probleme im Kapitel zur Vermeidung h√§ufiger Fehler besprechen.\n\n\nEin weiterer Faktor, der zur Verbreitung von ML beitr√§gt, ist die Verf√ºgbarkeit von (digitalen) Daten. Unternehmen wie Google, Amazon und Meta hatten hier einen Vorsprung, da ihr Gesch√§ftsmodell von Anfang an auf Daten aufgebaute. Andere Unternehmen holen inzwischen langsam auf. W√§hrend traditionelle ML-Modelle nur minimal von diesen verf√ºgbaren Daten profitieren, k√∂nnen gro√üe neuronale Netzmodelle mit vielen Freiheitsgraden jetzt ihr volles Potenzial entfalten, indem sie aus all den Texten und Bildern lernen, die t√§glich im Internet ver√∂ffentlicht werden:\n\n\n\n\n\n\nAber wir sind nach wie vor noch weit von Artificial General Intelligence (AGI, ‚Äúk√ºnstliche allgemeine Intelligenz‚Äù oder ‚Äústarke KI‚Äù) entfernt!\n\n\n\n\n\nEine AGI ist ein hypothetisches Computersystem mit menschen√§hnlichen kognitiven F√§higkeiten, das in der Lage w√§re, ein breites Spektrum von Aufgaben in verschiedenen Bereichen zu verstehen, zu lernen und auszuf√ºhren. Speziell w√ºrde eine AGI nicht nur bestimmte Aufgaben ausf√ºhren, sondern auch ihre Umgebung verstehen und daraus lernen, autonom Entscheidungen treffen und ihr Wissen auf vollkommen neue Situationen verallgemeinern.\nIn der Praxis wird stattdessen Artificial Narrow Intelligence (ANI, auch ‚Äúschwache KI‚Äù) verwendet: Modelle, die explizit programmiert wurden, um eine bestimmte Aufgabe zu l√∂sen, z.B. Texte von einer Sprache in eine andere √ºbersetzen. Diese Modelle k√∂nnen nicht (eigenst√§ndig) verallgemeinern und neue Aufgaben lernen, sprich das maschinelle √úbersetzungsmodell wird nicht morgen auf die Idee kommen, dass es nun auch Gesichter in Bildern erkennen will. Nat√ºrlich kann man mehrere einzelne ANIs in einem gro√üen Programm kombinieren, um so mehrere verschiedene Aufgaben zu l√∂sen, aber auch diese Sammlung von ANIs ist nicht in der Lage, selbstst√§ndig neue F√§higkeiten dar√ºber hinaus zu erlernen.\nViele KI-Forscher sind derzeit √ºberzeugt, dass wir zumindest mit den aktuell verwendeten Methoden (z.B. den Large Language Models (LLMs) wie ChatGPT von OpenAI) wahrscheinlich nie eine echte menschen√§hnliche AGI erschaffen werden. Speziell mangelt es diesen KI-Systemen noch immer an einem allgemeinen Verst√§ndnis von Kausalit√§t und physikalischen Gesetzen wie der Objektpermanenz ‚Äì etwas, das sogar viele Haustiere verstehen.\nWenn du mehr √ºber die M√§ngel aktueller KI-Systeme erfahren m√∂chtest, sind die Blogartikel von Gary Marcus sehr zu empfehlen!\n\n\nTechnologische Entwicklung schafft neue M√∂glichkeiten\nTechnologie entwickelt sich in Phasen, oft beginnend als obskure Forschung und, falls erfolgreich, allgegenw√§rtig werdend. Historisch gesehen erm√∂glichten gro√üe Fortschritte wie Elektrizit√§t oder das Internet v√∂llig neue Produkte und Branchen, darunter K√ºhlschr√§nke und Fernseher oder E-Commerce und Streaming-Dienste. KI und ML haben inzwischen ein relativ reifes Stadium erreicht, was es zum richtigen Zeitpunkt macht, ernsthaft √ºber Produkte nachzudenken, die darauf aufbauen ‚Äì denn die Geschichte belohnt die Netflixes, nicht die Blockbusters.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "01b_basics.html",
    "href": "01b_basics.html",
    "title": "Grundlagen",
    "section": "",
    "text": "Daten sind das neue √ñl!?\nDieses Kapitel gibt eine allgemeine Einf√ºhrung in das Thema Machine Learning (ML) und zeigt auf in welchen Bereichen der Einsatz von ML sinnvoll ist und welche Probleme man lieber mit einfacheren Mitteln l√∂sen sollte.\nLass uns von vorne anfangen. Alles beginnt mit Daten. Wahrscheinlich hast du diese Behauptung schon einmal geh√∂rt: ‚ÄúDaten sind das neue √ñl!‚Äù. Dies legt nahe, dass Daten wertvoll sind. Aber sind sie das?\nDer Grund, warum √ñl als wertvoll angesehen wird, liegt darin, dass wir wichtige Anwendungsf√§lle daf√ºr haben: den Antrieb unserer Autos, die Beheizung unserer H√§user und die Herstellung von Kunststoffen oder D√ºngemitteln. Genauso verh√§lt es sich auch mit Daten: sie sind nur so wertvoll wie das was wir aus ihnen machen. Wof√ºr k√∂nnen wir also Daten verwenden?\nDie wichtigsten Anwendungsf√§lle fallen in eine von zwei Kategorien:",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Grundlagen</span>"
    ]
  },
  {
    "objectID": "01b_basics.html#sec-data-oil",
    "href": "01b_basics.html#sec-data-oil",
    "title": "Grundlagen",
    "section": "",
    "text": "Insights\nErkenntnisse k√∂nnen wir entweder durch kontinuierliches Monitoring (‚ÄúSind wir auf Kurs?‚Äù) oder eine tiefere Analyse (‚ÄúWas l√§uft falsch?‚Äù) generieren.\nIn dem wir wichtige Variablen oder Key Performance Indicators (KPIs) in Berichten oder Dashboards visualisieren, machen wir den Status Quo transparenter und quantifizieren wie nah wir einem bestimmten Ziel schon gekommen sind. Wenn ein KPI weit ab von seinem Zielwert liegt, k√∂nnen wir mit einer explorativen Datenanalyse tiefer in die Daten eintauchen, um die Ursache des Problems zu identifizieren und Fragen wie diese zu beantworten:\n\nWarum erreichen wir unser Ziel nicht?\nWas sollen wir als n√§chstes tun?\n\nZufriedenstellende Antworten zu finden ist allerdings oft mehr Kunst als Wissenschaft üòâ ‚Äì mehr dazu im Kapitel Datenanalyse.\n\n\nAutomatisierung\nWie in den folgenden Unterkapiteln beschrieben, k√∂nnen Machine Learning Modelle dazu verwendet werden, um eine ‚ÄòInput ‚Üí Output‚Äô Aufgabe zu automatisieren, welche sonst ein (speziell geschulter) Mensch erledigen m√ºsste. Diese Aufgaben fallen einem (entsprechend geschulten) Menschen in der Regel leicht:\n\n√úbersetzen von Texten von einer Sprache in eine andere\nProdukte mit Kratzern aussortieren, wenn sie einen Kontrollpunkt am Flie√üband passieren\nEinem Freund Filme empfehlen\n\nDie ML-Modelle m√ºssen daf√ºr mit einer gro√üen Menge historischer Daten trainiert werden (z.B. Texte in beiden Sprachen, Bilder von Produkten mit und ohne Kratzer, Informationen √ºber verschiedene Nutzer und welche Filme sie gesehen haben).\nDie resultierende Software kann dann entweder verwendet werden, um die Aufgabe vollst√§ndig zu automatisieren, oder wir k√∂nnen einen Menschen dazwischen schalten, der eingreifen und die Vorschl√§ge des Modells korrigieren kann.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Grundlagen</span>"
    ]
  },
  {
    "objectID": "01b_basics.html#sec-what-is-ml",
    "href": "01b_basics.html#sec-what-is-ml",
    "title": "Grundlagen",
    "section": "Was ist ML?",
    "text": "Was ist ML?\nWas genau ist nun dieses maschinelle Lernen, das bereits unser aller Leben ver√§ndert?\nML ist zun√§chst ein Forschungsgebiet im Bereich der theoretischen Informatik, an der Schnittstelle von Mathematik und Informatik:\n\n\n\n\n\nGenauer gesagt ist maschinelles Lernen ein √úberbegriff f√ºr Algorithmen, die Muster erkennen und Regeln aus Daten lernen.\n\n\n\n\n\n\nHinweisAlgorithmen als Probleml√∂sungsrezepte\n\n\n\nVereinfacht kann man sich einen Algorithmus als Strategie oder Rezept zur L√∂sung eines speziellen Problems vorstellen. Es gibt zum Beispiel effektive Algorithmen, um den k√ºrzesten Weg zwischen zwei St√§dten zu finden (z.B. genutzt in den Navigationssystemen von Google Maps) oder um Planungsprobleme zu l√∂sen wie z.B.: ‚ÄúWelche Aufgabe sollte zuerst erledigt werden und welche Aufgabe danach um alle Aufgaben vor ihrer Deadline zu schaffen unter Ber√ºcksichtigung eventueller Abh√§ngigkeiten zwischen den Aufgaben.‚Äù Maschinelles Lernen befasst sich mit der Teilmenge von Algorithmen, die statistische Regelm√§√üigkeiten in einem Datensatz erkennen und nutzen, um bestimmte Ergebnisse zu erzielen.\n\n\n\nAnalog zu den Werkzeugen, mit denen man etwas in einem traditionellen Produktionsprozess herstellt, kann man sich ML-Algorithmen als Werkzeuge vorstellen, um Wert aus Daten zu generieren:\n\n\n\n\n\nUm ML erfolgreich anzuwenden, sollte man sich einige wichtige Fragen stellen:\n\nWas k√∂nnte wertvoll sein? Dies kann beispielsweise ein neues Feature f√ºr ein existierendes Produkt sein, z.B. Face ID als neue M√∂glichkeit um ein Smartphone zu entsperren.\nWelche Daten werden ben√∂tigt? Einen Holzstuhl kann man nicht aus Stoff und Metall oder ein paar im Wald gefundenen Zweigen herstellen. Genauso ben√∂tigt man je nachdem, was man mit ML erreichen m√∂chte, auch die richtigen Daten in ausreichender Qualit√§t & Quantit√§t um die Algorithmen √ºberhaupt anwenden zu k√∂nnen. In vielen Anwendungsf√§llen ist dieser Teil besonders schwierig, da man die ben√∂tigten Daten oft nicht einfach kaufen kann, wie Holz im Baumarkt, sondern diese selbst sammeln ‚Äì also quasi einen eigenen Wald anpflanzen muss, was einige Zeit dauern kann.\nWelcher ML-Algorithmus ist das richtige Werkzeug f√ºr diese Aufgabe? (Welche Kategorie von ML-Algorithmen generiert die Art von Output, die wir ben√∂tigen?)\nVerf√ºge ich bzw. meine Mitarbeiter √ºber die notwendigen F√§higkeiten und gen√ºgend Rechenleistung, um das Vorhaben erfolgreich umzusetzen?\n\n\nDie unterschiedlichen Algorithmen bilden unseren ML Werkzeugkasten:\n\n\n\nML selbst ist ein Teilbereich der K√ºnstlichen Intelligenz (KI/AI), das derzeit zwar h√§ufiger verwendete Buzzword, jedoch basieren alle wirklich interessanten Anwendungen, z.B. die initial gezeigten Beispiele, tats√§chlich auf ML. Zu KI geh√∂ren ansonsten zum Beispiel noch einige Suchalgorithmen, die beim Bau der ersten Schachcomputer verwendet wurden. ML kann wiederum in drei Hauptbereiche unterteilt werden, Unsupervised (‚ÄúUn√ºberwachtes‚Äù), Supervised (‚Äú√úberwachtes‚Äù) und Reinforcement (‚ÄúBest√§rkendes‚Äù) Learning. Das Buzzword ‚ÄúDeep Learning‚Äù ist au√üerdem ein √úberbegriff f√ºr neuronale Netzwerkmodelle und beinhaltet auch Generative AI (GenAI) Modelle wie ChatGPT. Einige der einfachsten im ML verwendeten Algorithmen, wie die lineare Regression oder PCA (sehr √§hnlich der Faktorenanalyse), werden auch von Statistikern verwendet, die jedoch auch andere Werkzeuge wie Hypothesentests verwenden, welche keine Regeln oder Muster aus Daten lernen. Die meisten Data Scientists verwenden viele Methoden aus ML und Statistik, aber auch zus√§tzliche Werkzeuge wie A/B-Tests, z.B. um zu √ºberpr√ºfen, ob ein roter oder gr√ºner ‚ÄúKaufen‚Äù-Button auf einer Website mehr Umsatz generiert.\n\n\n\nML Algorithmen l√∂sen ‚ÄúInput ‚Üí Output‚Äù Probleme\nAll diesen ML-Algorithmen aus unserem Werkzeugkasten ist gemein, dass sie ‚ÄúInput ‚Üí Output‚Äù Probleme wie diese l√∂sen:\n\n\n\nBeispiel ‚ÄúInput ‚Üí Output‚Äù ML Probleme: Erkennen von Objekten in Bildern; √úbersetzen von Text von einer Sprache in eine andere; Bestimmen eines guten n√§chsten Zuges angesichts des aktuellen Zustands eines Go-Boards; Gruppieren √§hnlicher Nutzer/Kunden anhand verschiedener Informationen √ºber sie, wie z.B. Umfrageantworten (im Marketing als Kundensegmentierung bezeichnet dient dies dazu z.B. unterschiedliche Kundengruppen in sozialen Medien mit spezifischen Werbekampagnen anzusprechen).\n\n\nW√§hrend in den obigen Beispielen ein (entsprechend geschulter) Mensch zur jeweiligen Eingabe in der Regel leicht die richtige Ausgabe erzeugt (z.B. kann sogar ein kleines Kind die Katze im ersten Bild erkennen), f√§llt es Menschen oft schwer zu beschreiben, wie sie zur richtigen Antwort gekommen sind (woran erkennt man, dass dies eine Katze und kein kleiner Hund ist? an den spitzen Ohren? den Schnurrhaaren?). Im Gegensatz dazu lernen ML-Algorithmen solche Regeln aus den gegebenen Beispieldaten.\n\n\nML vs.¬†herk√∂mmliche Software\nW√§hrend man herk√∂mmliche Software-L√∂sungen dazu verwenden kann, um Aufgaben zu automatisieren, bei denen eine vordefinierte Abfolge von Aktionen nach einigen festgeschriebenen Regeln ausgef√ºhrt wird (z.B. ‚ÄúEine T√ºr soll sich √∂ffnen, wenn ein Objekt eine Lichtschranke durchquert und sich 20 Sekunden sp√§ter wieder schlie√üen‚Äù), kann man mit maschinellem Lernen ‚ÄúInput ‚Üí Output‚Äù-Aufgaben automatisieren, f√ºr die es sonst schwierig w√§re, solche Regeln aufzustellen.\nDie Qualit√§tskontrolle in einer Keks-Fabrik ist ein Beispiel f√ºr eine solche ‚ÄúInput (Keks) ‚Üí Output (ok/fehlerhaft)‚Äù-Aufgabe: W√§hrend z.B. zerbrochene Kekse automatisch aussortiert werden k√∂nnten, indem man √ºberpr√ºft, dass jeder Keks etwa 15g wiegt, ist es schwierig, Regeln zu formulieren, die alle m√∂glichen Produktionsfehler zuverl√§ssig abfangen. Also m√ºsste entweder ein Mensch die Produktionslinie beobachten, um z.B. zus√§tzlich verbrannte Kekse zu erkennen, oder man k√∂nnte Bilder von den Keksen machen und sie als Input f√ºr ein Machine Learning Modell verwenden, um die fehlerhaften Kekse zu erkennen:\n\n\n\n\n\nUm dieses Problem mit ML zu l√∂sen, muss zun√§chst ein gro√üer Datensatz mit Fotos vieler guter, aber auch allerlei fehlerhafter Kekse zusammengestellt werden, inklusive der entsprechenden Annotationen, also einem Label f√ºr jedes Bild, ob es einen guten oder fehlerhaften Keks zeigt (aber nicht unbedingt die Art des Fehlers). Aus diesen Beispielen kann dann ein ML-Algorithmus lernen, zwischen guten und fehlerhaften Keksen zu unterscheiden.\n\n\nWann man ML (nicht) verwenden sollte\nML ist √ºbertrieben, wenn:\n\nein manuell definiertes Regelwerk oder ein mechanistisches (white box) Modell das Problem l√∂sen kann. Wenn beispielsweise in unserer Keks-Fabrik das einzige Qualit√§tsproblem immer nur zerbrochene Kekse w√§ren, dann w√ºrde die Regel ‚ÄúKeks-Gewicht muss zwischen 14-16g liegen‚Äù ausreichen, um alle fehlerhaften Kekse zuverl√§ssig zu erkennen. Eine solche Regel ist au√üerdem einfacher zu implementieren, da nicht erst ein gro√üer Datensatz gesammelt werden muss.\n\nML ist deine beste Chance, wenn:\n\nMenschen von sehr komplexen, hochdimensionalen Daten √ºberfordert sind. Z.B. f√§llt es einem Menschen schwer, bei einer Excel-Tabelle mit hunderten von Spalten den Durchblick zu behalten. Wir k√∂nnen in so einem Meer von Zahlen oft keine Muster erkennen. Im ung√ºnstigsten Fall gibt es tats√§chlich keine Zusammenh√§nge in den Daten, da vielleicht nicht alle relevanten Faktoren gemessen wurden, aber wenn doch, wird ML die Zusammenh√§nge h√∂chstwahrscheinlich finden.\n\nML hat gro√ües Potenzial, wenn:\n\neine exakte Simulation mit einem mechanistischen Modell zu lange dauert (dieses aber verwendet werden kann, um einen qualitativ hochwertigen Datensatz zu generieren). Z.B. wurde das in der Einleitung erw√§hnte AlphaFold-Modell, mit dem die 3D-Struktur eines Proteins anhand seiner Aminos√§uresequenz vorhergesagt werden kann, auf den Daten trainiert, die das urspr√ºngliche Simulationsmodell zur L√∂sung dieser Aufgabe zuvor generiert hat, welches allerdings zu langsam ist, um auf eine gro√üe Anzahl von Proteinen angewendet zu werden.\neine ‚Äúeinfache‚Äù, aber schwer zu erkl√§renden Aufgabe gel√∂st werden soll, die ein (geschulter) Mensch in ~1 Sekunde l√∂sen kann, z.B. etwas auf einem Bild erkennen\n‚áí Dadurch k√∂nnen repetitive Aufgaben automatisiert und Expertenwissen f√ºr alle zug√§nglich gemacht werden, wie z.B. beim eingangs gezeigten Diagnosemodell f√ºr diabetische Retinopathie von Google.\nAber: Erfolg h√§ngt von der Datenqualit√§t & -quantit√§t ab!\n‚Üí Menschen k√∂nnen aus wenigen Beispielen viel besser verallgemeinern. Ein Arzt kann beispielsweise eine Krankheit auch dann noch leicht erkennen, wenn die Bilder z.B. mit einer √§lteren Maschine aufgenommen wurden. Ein ML-Modell muss f√ºr dieses ge√§nderte Setup u.U. neu trainiert werden, wof√ºr wieder viele zus√§tzliche Daten gesammelt werden m√ºssen.\n\n\n\n\n\n\n\nVorsichtML-Modelle werden Fehler machen\n\n\n\nVerwende ML nur dann, wenn gelegentliche Fehler akzeptabel sind. ML-Modelle werden normalerweise mit von Menschen erstellten Daten trainiert, die anf√§llig f√ºr Rauschen sind, da selbst Experten bei bestimmten F√§llen unterschiedlicher Meinung sein k√∂nnen. Au√üerdem m√ºssen ML-Modelle m√∂glicherweise extrapolieren und Vorhersagen f√ºr neue Datenpunkte machen, die sich von den Trainingsdaten unterscheiden, was zu falschen Ergebnissen f√ºhren kann. Um Fehler zu minimieren, kann es hilfreich sein, die Vorhersagen des ML-Modells gelegentlich von einem Menschen √ºberpr√ºfen zu lassen (‚Äúhuman in the loop‚Äù).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Grundlagen</span>"
    ]
  },
  {
    "objectID": "01b_basics.html#sec-how-machines-learn",
    "href": "01b_basics.html#sec-how-machines-learn",
    "title": "Grundlagen",
    "section": "Wie ‚Äúlernen‚Äù Maschinen?",
    "text": "Wie ‚Äúlernen‚Äù Maschinen?\nWie l√∂sen ML-Algorithmen diese ‚ÄúInput ‚Üí Output‚Äù Probleme, also wie erkennen sie Muster und lernen Regeln aus Daten?\nML-Algorithmen lassen sich nach ihrer Funktionsweise, d.h. wie sie lernen, weiter unterteilen. Diese Unterteilung ist inspiriert von der Art und Weise wie Menschen lernen:\n\n\n\nUnsupervised Learning: Menschen sind sehr gut darin, statistische Gesetzm√§√üigkeiten in der Welt zu erkennen, ohne dass sie ausdr√ºcklich dazu aufgefordert werden. Ist dir zum Beispiel schon einmal aufgefallen, dass wir beim Sprechen keine ‚Ä¶ Pausen ‚Ä¶ zwischen ‚Ä¶ W√∂rtern machen? Dennoch lernen Kinder intuitiv, welche Silben zu einem Wort geh√∂ren und wo dieses Wort endet und das n√§chste beginnt. Dies funktioniert, weil die Silben eines Wortes immer in dieser spezifischen Kombination vorkommen, diesem Wort dann aber unterschiedliche W√∂rter, beginnend mit vielen verschiedenen Silben, folgen. Das bedeutet, dass wir durch H√∂ren von gesprochenem Text die bedingten Wahrscheinlichkeitsverteilungen von Silben erfassen. Supervised Learning: Diese Art des Lernens ben√∂tigt eine Lehrerin, die uns die richtigen Antworten sagt und uns korrigiert, wenn wir etwas falsch machen. Um z.B. einem Kind ein Wort beizubringen veranschaulicht man ihm die Bedeutung anhand von Beispielen, und wenn das Kind etwas falsch benennt, z.B. einen kleinen Hund als Katze bezeichnet, korrigiert man es. Reinforcement Learning: Auch diese Art von ‚ÄúLearning by Doing‚Äù passiert ganz nat√ºrlich wenn Menschen aus den Konsequenzen ihrer Handlungen lernen. Durch Experimentieren und √úben k√∂nnen wir zum Beispiel eine komplexe Abfolge von Handbewegungen einstudieren, mit der wir einer Geige sch√∂ne Kl√§nge entlocken, anstatt schmerzhaftes Kreischen zu erzeugen. Zwar ist keine einzelne Handbewegung an sich gut oder schlecht, jedoch nur die richtige Kombination bringt Musik in unsere Ohren.\n\n\nAnalog dazu k√∂nnen auch Maschinen nach diesen drei Strategien lernen:\n\n\n\nUnsupervised Learning: Diese Algorithmen erkennen statistische Regelm√§√üigkeiten in den Daten, z.B. k√∂nnen sie Gruppen √§hnlicher Dinge identifizieren (Beispiel Kundensegmentierung) oder einzelne Punkte finden, die aus der Reihe tanzen (Anomalieerkennung), z.B. ungew√∂hnliches Verhalten einer Maschine aufgrund eines defekten Teils oder verd√§chtige Kreditkartentransaktionen im Onlinehandel. Supervised Learning: Diese Algorithmen lernen aus vielen Input-Output-Beispielen, z.B. Bilder und darauf sichtbare Objekte oder Produktionsbedingungen zusammen mit der resultierenden Produktqualit√§t. Das gelernte Modell kann dann f√ºr einen neuen Input den dazugeh√∂rigen Output vorhersagen. Reinforcement Learning: Diese Art des Lernens ist etwas komplizierter: Der Lernalgorithmus wird hier als Agent bezeichnet, welcher sich in einer Umgebung bewegt, z.B. ein Roboter in der realen Welt oder ein virtueller Agent in einer Simulationsumgebung wie einem Videospiel (was normalerweise viel billiger ist ;-)). Die Umgebung teilt dem Agenten mit, in welchem Zustand oder in welcher Situation er sich gerade befindet, dann kann der Agent ausw√§hlen, wie er in diesem Zustand reagieren will, d.h. welche (vordefinierte) Aktion er ausf√ºhrt. Die Konsequenzen dieser Aktion werden anschlie√üend durch die Umgebung bestimmt (z.B. ein Monster in einem Videospiel besiegen oder von einer Klippe fallen) und je nach Ergebnis wird eine Belohnung zur√ºckgeben (z.B. zus√§tzliche Punkte f√ºr eingesammelte M√ºnzen). Dann wiederholt sich der Zyklus, da sich der Agent im n√§chsten Zustand befindet. Basierend auf der erhaltenen Belohnung lernt der Agent im Laufe der Zeit, welche Aktionen in welchen Situationen von Vorteil sind und wie er sich in der Umgebung zurechtfindet. Das Schwierige daran ist, dass der Agent die Belohnungssignale teilweise erst lange nachdem die Aktion ausgef√ºhrt wurde erh√§lt. In einem Videospiel zum Beispiel findet der Agent zu Beginn eines Levels einen Schl√ºssel, aber die T√ºr, die damit ge√∂ffnet werden kann, kommt erst viele Frames sp√§ter. Eine verz√∂gerte Belohnung macht es dem Agent schwerer diese mit der entsprechenden Aktion zu verkn√ºpfen. Da Menschen viel Hintergrundwissen haben, ist es f√ºr uns viel einfacher herauszufinden, was in einem Spiel funktioniert und was nicht.\n\n\n\nDaten-Voraussetzungen f√ºr das Lernen mit diesen Strategien:\n\nUnsupervised Learning: ein Datensatz mit Beispielen\n\n\n\n\n\nSupervised Learning: ein Datensatz mit gelabelten Beispielen\n\n\n\n\n\nReinforcement Learning: eine (Simulations-) Umgebung, die, basierend auf den Aktionen des Agenten, Daten (Belohnung + neue Zust√§nde) generiert\n\n\n\n\n\nAufgrund der Abh√§ngigkeit von einer datenerzeugenden Umgebung ist Reinforcement Learning ein Sonderfall. Au√üerdem ist es derzeit noch sehr schwer, Reinforcement Learning Algorithmen zum Laufen zu bringen, weshalb sie haupts√§chlich in der Forschung und weniger f√ºr praktische Anwendungen verwendet werden.\n\n\n\nSupervised Learning\nSupervised Learning ist die verbreitetste Art des maschinellen Lernens in heutigen Anwendungen.\nBeim Supervised Learning m√∂chten wir ein Modell (= eine mathematische Funktion) \\(f(x)\\) lernen, um den Zusammenhang zwischen einem oder mehreren Input(s) \\(x\\) (z.B. Produktionsbedingungen wie Temperatur, Material, etc.) und einem Output \\(y\\) (z.B. resultierende Produktqualit√§t) zu beschreiben.\nDieses Modell kann dann verwendet werden, um Vorhersagen f√ºr neue Datenpunkte zu machen, also \\(f(x') = y'\\) f√ºr ein neues \\(x'\\) zu berechnen (z.B. f√ºr einen neuen Satz von Produktionsbedingungen vorhersagen, ob das Produkt von hoher Qualit√§t sein wird, oder ob man den Vorgang lieber gleich abbrechen sollte).\nSupervised Learning ‚Äì kurz und knapp:\n\n\n\nZuerst muss man sich dar√ºber im Klaren sein, was vorhergesagt werden soll und inwiefern einem die Vorhersage hilft, das eigentliche Ziel zu erreichen und Mehrwert generiert. Au√üerdem muss man sich √ºberlegen, wie man den Erfolg misst, d.h. den Key Performance Indicator (KPI) des Prozesses bestimmen. Anschlie√üend muss man Trainingsdaten sammeln. Da wir hier im Bereich des Supervised Learnings sind, m√ºssen dies gelabelte Daten sein, also inkl. der Zielvariable, die man vorhersagen m√∂chte. Dann ‚Äúlernt‚Äù (oder ‚Äútrainiert‚Äù oder ‚Äúfittet‚Äù) man ein Modell auf diesen Daten um schlie√ülich Vorhersagen f√ºr neue Datenpunkte zu generieren.\n\n\n\nFeatures & Labels\nEin typisches Supervised Learning Problem w√§re beispielsweise ein Produktionsprozess, bei dem wir vorhersagen m√∂chten, ob ein unter bestimmten Produktionsbedingungen produziertes Teil Ausschuss ist. Hier beinhalten die gesammelten Daten f√ºr jedes produzierte Teil die Prozessbedingungen, unter denen es hergestellt wurde, und ob das resultierende Produkt in Ordnung oder Ausschuss war:\n\n\n\nBei den f√ºr diesen Anwendungsfall erhobenen Daten handelt es sich um strukturierte Daten in tabellarischer Form (z.B. in einer Excel-Tabelle). Ein Datenpunkt / eine Probe / eine Beobachtung befindet sich immer in einer Zeile dieser Tabelle.\n\n\n\n\n\nDie Spalten der Tabelle enthalten die unterschiedlichen Messwerte/Variablen, welche f√ºr jeden Datenpunkt erhoben wurden. Dabei unterscheiden wir zwischen Features (in diesem Fall die Produktionsbedingungen) und Labels (ob das jeweilige Produkt in Ordnung oder Ausschuss war). Features, auch als Matrix \\(X\\) bezeichnet, sind typischerweise diejenigen Messwerte, die wir ohne Aufwand erhalten, da sie w√§hrend des Prozesses bereits f√ºr andere Zwecke gesammelt werden. Wenn beispielsweise der Bediener der Maschine die Temperatur f√ºr die Produktion auf einen bestimmten Wert einstellt, wird dies aufgezeichnet w√§hrend das Signal an das Heizger√§t weitergeleitet wird. Das Sammeln der dazugeh√∂rigen Labels, bezeichnet als Vektor \\(\\mathbf{y}\\), ist oft kostspieliger. Um beispielsweise im Produktionsprozess einen Datenpunkt mit dem Label ‚ÄúAusschuss‚Äù zu sammeln, muss (vors√§tzlich) ein fehlerhaftes Produkt produziert werden, was uns wertvolle Ressourcen kostet. Ein anderes Beispiel f√ºr die mit Labels verbunden Kosten ist die Tatsache, dass Google ein Team von Fach√§rzten bezahlte, um mehrere Bilder von diabetischer Retinopathie, zu denen es widerspr√ºchliche Meinungen gab, zu diskutieren und neu zu bewerten.\n\n\nIm Supervised Learning werden die Features als Input (Eingabe) f√ºr das Modell verwendet, w√§hrend die Labels die Zielvariable, d.h. der vorhergesagte Output (Ausgabe) darstellen. Im Allgemeinen sollten Features unabh√§ngige Variablen sein (z.B. Einstellungen, die der Bediener nach Belieben w√§hlen kann), w√§hrend der Zielwert von diesen Eingaben abh√§ngig sein sollte, damit wir ihn vorhersagen k√∂nnen.\n\n\nEin Modell aus Daten ‚Äúlernen‚Äù\nZiel: Beschreibe den Zusammenhang zwischen Input(s) \\(x\\) und Output \\(y\\) mit einem Modell, d.h. einer mathematischen Funktion \\(f(x)\\)\n\n\n\n\n\n\nW√§hle eine Modell Klasse (= Struktur der Funktion): Annahme: Zusammenhang ist linear\n‚Üí lineares Regressionsmodell: \\(y = f(x) = b + w\\cdot x\\)\nDefiniere die Zielfunktion: Minimiere die Abweichung zwischen echtem & vorhergesagtem \\(y\\):\n‚Üí \\(\\min_{b,w} \\sum_i (y_i - f(x_i))^2\\)\nFinde die besten Modellparameter f√ºr die gegebenen Daten: d.h. l√∂se das in Schritt 2 definierte Optimierungsproblem\n‚áí \\(f(x) = -2.7 + 5.2x\\)\n\n\n\n\n\n\n\n\nTippVideo Empfehlung: lineare Regression\n\n\n\nWenn dir lineare Regression nichts sagt, findest du hier eine tolle Erkl√§rung von der Google-Mitarbeiterin Cassie Kozyrkov zur Funktionsweise der linearen Regression, des einfachsten Supervised Learning Algorithmus: [Teil 1] [Teil 2] [Teil 3]\n\n\nDie existierenden Supervised Learning Algorithmen unterscheiden sich in der Art des \\(x \\to y\\) Zusammenhangs, den sie beschreiben k√∂nnen (z.B. linear oder nichtlinear) und welche Art von Zielfunktion (auch Fehlerfunktion genannt) sie minimieren. Die Aufgabe eines Data Scientists besteht darin, einen f√ºr den Datensatz passenden Modelltyp auszuw√§hlen. Den Rest erledigt dann eine Optimierungsmethode, die Parameter f√ºr das Modells findet, welche die Zielfunktion des Modells minimieren, d.h. sodass der Vorhersagefehler des Modells auf den gegebenen Daten so klein wie m√∂glich ist.\n\n\n\n\n\n\nHinweisML-Algorithmus vs.¬†ML-Modell\n\n\n\nIn diesem Buch werden die Begriffe ‚ÄúML-Algorithmus‚Äù und ‚ÄúML-Modell‚Äù meist synonym verwendet. Wenn man es aber genau nimmt, verarbeitet der Algorithmus die gegebenen Daten und lernt die Parameterwerte. Die gefundenen Parameter bestimmen das eigentliche Modell. Ein lineares Regressionsmodell wird beispielsweise durch seine Koeffizienten (d.h. die Parameter des Modells) definiert. Diese werden gefunden, in dem die Schritte des linearen Regressionsalgorithmus befolgt werden, also das Optimierungsproblem auf den gegebenen Daten gel√∂st wird.\n\n\n\nDa geht noch mehr!\n\n\n\nIn vielen Anwendungsf√§llen reicht es nicht aus, einfach ‚Äúnur‚Äù die Zielvariable f√ºr einen neuen Datenpunkt vorherzusagen; ob beispielsweise ein unter bestimmten Bedingungen hergestelltes Produkt von hoher Qualit√§t sein wird oder nicht. Stattdessen ist es oft notwendig, zus√§tzlich erkl√§ren zu k√∂nnen, warum diese Vorhersage gemacht wurde und welche Features f√ºr die Vorhersage entscheidend waren, sowohl um m√∂gliche Ursachen eines Problems besser zu verstehen, aber auch um sicherzustellen, dass die Vorhersagen des Modells auf vern√ºnftigen Annahmen basieren. Dar√ºber hinaus kann ein erlerntes Modell auch innerhalb einer √§u√üeren Optimierungsschleife verwendet werden, um optimale Inputs zu bestimmen. Im einfachsten Fall k√∂nnte man z.B. systematisch √ºberpr√ºfen, welche Produktqualit√§t das Modell f√ºr verschiedene Prozessbedingungen vorhersagt, um f√ºr neue Produkte die Einstellungen mit der am h√∂chsten vorhergesagten Qualit√§t zu w√§hlen. Aber Vorsicht: ML-Modelle sind nur zum Interpolieren, nicht zum Extrapolieren konzipiert, d.h. es muss sichergestellt werden, dass die getesteten Eingaben im gleichen Wertebereich liegen wie in den Daten, die zum Trainieren des Modells verwendet wurden.\n\n\n\nPr√§diktive Analyse\nMit Supervised Learning Algorithmen k√∂nnen wir basierend auf historischen Daten ein Vorhersagemodell generieren, das Prognosen √ºber zuk√ºnftige Szenarien anstellt um uns bei Planungen zu unterst√ºtzen.\nBeispiel: Verkaufsprognosen verwenden, um Lagerbest√§nde besser zu planen.\nInterpretation Pr√§diktiver Modelle\nInterpretiere das Vorhersagemodell und seine Prognosen, um die zugrundeliegenden Ursache-Wirkung Beziehungen des Prozesses besser zu verstehen.\nBeispiel: Gegeben ein Modell, welches die Qualit√§t eines Produkts aus den Produktionsbedingungen vorhersagt, verstehe welche Faktoren dazu f√ºhren dass Produkte von geringerer Qualit√§t sind.\nWas-w√§re-wenn Analyse & Optimierung\nVerwende ein Vorhersagemodell f√ºr eine Was-w√§re-wenn-Vorhersage, um zu untersuchen, wie ein System auf unterschiedliche Bedingungen reagieren k√∂nnte (aber Vorsicht!).\nBeispiel: Gegeben ein Modell, welches die verbleibende Lebenszeit f√ºr eine Maschinenkomponente aus den Prozessbedingungen vorhersagt, wie schnell w√ºrde diese Komponente unter anderen Prozessbedingungen verschlei√üen?\nWenn wir noch einen Schritt weiter gehen wollen, k√∂nnen wir auch automatisch verschiedene Inputs mit dem Vorhersagemodell in einer Optimierungsschleife bewerten, um systematisch optimale Einstellungen zu finden.\nBeispiel: Gegeben ein Modell, welches die Qualit√§t eines Produkts aus den Produktionsbedingungen vorhersagt, bestimme automatisch die besten Produktionseinstellungen f√ºr einen neuen Rohstofftyp.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Grundlagen</span>"
    ]
  },
  {
    "objectID": "01b_basics.html#sec-ml-use-cases",
    "href": "01b_basics.html#sec-ml-use-cases",
    "title": "Grundlagen",
    "section": "ML Anwendungsf√§lle",
    "text": "ML Anwendungsf√§lle\nML-Algorithmen k√∂nnen auf Input Daten in verschiedensten Formaten angewendet werden‚Ä¶\n\nStrukturierte vs.¬†Unstrukturierte Daten\nDaten k√∂nnen in verschiedenen Formaten vorliegen und w√§hrend einige Datentypen evtl. zus√§tzliche Verarbeitungsschritte erfordern, k√∂nnen ML-Algorithmen im Prinzip mit jeder Art von Daten arbeiten.\n\n\n\nDie wichtigste Unterscheidung bei der Charakterisierung von Daten liegt zwischen strukturierten Daten, das ist jeder Datensatz, der einzelne Messgr√∂√üen/Variablen/Attribute/Features enth√§lt, die eindeutige Gr√∂√üen darstellen, und unstrukturierten Daten, die nicht in sinnvolle Variablen unterteilt werden k√∂nnen. Z.B. in Bildern ‚Äúerster Pixel von links‚Äù oder in Texten ‚Äú10. Wort im 2. Absatz‚Äù w√ºrden wir nicht Variablen nennen, im Gegensatz zu ‚ÄúFl√§che in Quadratmetern‚Äù oder ‚ÄúAnzahl Schlafzimmern‚Äù, womit man sinnvoll eine Wohnung beschreiben k√∂nnte. Strukturierte Daten sind oft heterogen, da die verschiedenen Variablen in einem Datensatz typischerweise f√ºr sehr unterschiedliche Dinge stehen. Wenn man beispielsweise mit Sensordaten arbeitet enth√§lt ein Datensatz nicht nur Temperaturmessungen, sondern zus√§tzlich z.B. Druck und Durchflusswerte, die unterschiedliche Einheiten haben und in sehr unterschiedlichen Skalen gemessen werden k√∂nnen. Unstrukturierte Daten hingegen sind homogen, z.B. gibt es keinen qualitativen Unterschied zwischen dem 10. und dem 100. Pixel in einem Bild.\n\n\n\n‚Ä¶aber unser Ziel, also der gew√ºnschte Output, bestimmt welche Art von Algorithmus wir f√ºr das Problem verwenden sollten:\n\n\n\n\nWenn unser Ziel darin besteht, Muster in einem Datensatz zu entdecken (discover), sind Unsupervised Learning Algorithmen ideal: mit Dimensionsreduktion bekommen wir durch eine 2D Visualisierung eine √úbersicht √ºber die Daten, Anomalieerkennung identifiziert Ausrei√üer (z.B. eine defekte Maschine oder eine betr√ºgerische Kreditkartentransaktion), und Clustering gruppiert √§hnliche Datenpunkte (z.B. zur Kundensegmentierung).\nSupervised Learning Modelle werden verwendet, um unbekannte Werte zu sch√§tzen (estimate) (z.B. vorhersagen, ob ein Produkt fehlerhaft ist, wenn es unter bestimmten Bedingungen produziert wird): Regression sagt kontinuierliche Werte voraus (z.B. Anzahl der Nutzer, Preis etc.), w√§hrend Klassifikation diskrete Labels basierend auf den Inputdaten zuweist (z.B. kann ein Tier in einem Bild entweder eine Katze oder ein Hund sein, aber nichts dazwischen).\nRecommender Systems und Information Retrieval-Algorithmen k√∂nnen Artikel von Interesse empfehlen (recommend), wie Dokumente, Songs oder Filme, basierend auf den Pr√§ferenzen eines Nutzers oder den Artikeln, mit denen sie interagiert haben.\nDie vielseitigsten Modelle sind Generative AI und Deep Learning, die haupts√§chlich unstrukturierte Daten nutzen. Sie k√∂nnen vielf√§ltige Outputs erzeugen (generate) ‚Äì wie Bilder, Texte (z.B. f√ºr maschinelle √úbersetzung) oder Musik ‚Äì basierend auf einem gegebenen Prompt.\nSchlie√ülich werden Reinforcement Learning-Algorithmen verwendet, um Prozesse zu planen und zu steuern (plan and control), indem optimale Aktionssequenzen unter spezifischen Umweltbedingungen bestimmt werden.\n\n\n\nEinige Beispiele f√ºr ‚ÄòInput ‚Üí Output‚Äô Aufgaben und welche Art von ML-Algorithmus verwendet werden kann, um sie zu l√∂sen:\n\n\n\nInput \\(X\\)\nOutput \\(Y\\)\nML-Algorithmus Kategorie\n\n\n\n\nFragebogenantworten\nKundensegmentierung\nClustering\n\n\nSensormessungen\nalles normal?\nAnomalieerkennung\n\n\nVergangene Nutzung einer Maschine\nRestlebensdauer\nRegression\n\n\nE-Mail\nSpam (ja/nein)\nKlassifikation (bin√§r)\n\n\nBild\nwelches Tier?\nKlassifikation (mehrere Klassen)\n\n\nBisherige Eink√§ufe des Nutzers\nProduktvorschl√§ge\nEmpfehlungssysteme\n\n\nSuchanfrage\nrelevante Dokumente\nInformation Retrieval\n\n\nAudio\nText\nSpracherkennung\n\n\nText auf Englisch\nText auf Franz√∂sisch\nMaschinelle √úbersetzung\n\n\n\nZusammengefasst (siehe auch: √úbersichtstabelle als PDF):\nExistierende ML-L√∂sungen & entsprechende Outputs (f√ºr einen Datenpunkt):\n\nDimensionsreduktion: (normalerweise) 2D-Koordinaten (um den Datensatz zu visualisieren)\nAusrei√üer-/Anomalieerkennung: Anomalie-Score (normalerweise ein Wert zwischen 0 und 1, der angibt, inwiefern dieser Punkt von der Norm abweicht)\nClustering: Cluster-Index (eine Zahl zwischen 0 und k-1, die angibt, zu welchem der k Cluster ein Datenpunkt geh√∂rt (oder -1 f√ºr Ausrei√üer))\nRegression: ein kontinuierlicher Wert (eine numerischer Gr√∂√üe, die vorhergesagt werden soll)\nKlassifikation: ein diskreter Wert (eine von mehreren sich gegenseitig ausschlie√üenden Kategorien)\nGenerative AI: unstrukturierte Outputs wie Text oder Bild (z.B. Spracherkennung, maschinelle √úbersetzung, Bild Generierung oder Neural Style Transfer)\nEmpfehlungssysteme & Information Retrieval: Rangliste einer Menge von Elementen (Empfehlungssysteme ordnen beispielsweise die Produkte nach Relevanz f√ºr den jeweiligen Nutzer; Information Retrieval Systeme sortieren Elemente nach ihrer √Ñhnlichkeit zu einer gegebenen Suchanfrage)\nReinforcement Learning: eine Sequenz von Aktionen (abh√§ngig vom Zustand in dem sich der Agent befindet)\n\nBeginnen wir mit einem detaillierteren Blick auf die verschiedenen Unsupervised und Supervised Learning Algorithmen und wie sie uns helfen k√∂nnen:\n\n\n\nF√ºr die Anwendung von Unsupervised Learning Algorithmen braucht man nur eine Feature Matrix \\(X\\), w√§hrend man zum Erlernen eines Vorhersagemodells mit Supervised Learning Algorithmen auch die dazugeh√∂rigen Labels \\(\\mathbf{y}\\) ben√∂tigt.\n\n\n\n\n\n\n\n\nTippUnsupervised Learning als Vorbereitung f√ºr bessere Vorhersagen\n\n\n\nAuch wenn unser eigentliches Ziel darin besteht, etwas vorherzusagen (also Supervised Learning zu verwenden), kann es dennoch sehr hilfreich sein, zun√§chst Unsupervised Learning Algorithmen anzuwenden, um den Datensatz besser zu verstehen. Beispielsweise kann man die Daten im Vorfeld mit Dimensionsreduktionsmethoden visualisieren, um alle Datenpunkte und ihre Vielfalt auf einen Blick zu sehen. Anschlie√üend kann man den Datensatz bereinigen, in dem man Ausrei√üer identifiziert. Bei einem Klassifikationsproblem ist es h√§ufig sinnvoll, die Datenpunkte zuerst zu clustern, um zu √ºberpr√ºfen, in wie weit die angegebenen Klassenlabels mit den nat√ºrlich vorkommenden Gruppen in den Daten √ºbereinstimmen. Beispielsweise sieht man dann vielleicht, dass man das Problem vereinfachen kann, in dem man zwei sehr √§hnliche Klassen kombiniert.\n\n\n\nGleicher Datensatz, unterschiedliche Anwendungsf√§lle\nWir veranschaulichen den Nutzen der f√ºnf verschiedenen Arten von Unsupervised und Supervised Learning Algorithmen in dem wir sie auf diesen Beispieldatensatz anwenden:\n\nDies ist ein kleiner Musterdatensatz mit strukturierten Daten √ºber verschiedene Wohnungen, wie sie jemand √ºber eine Immobilienwebsite gesammelt haben k√∂nnte, z.B. die Gr√∂√üe der Wohnung in Quadratmetern, die Anzahl der Schlafzimmer, die Anzahl der Badezimmer, das Jahr der letzten Renovierung und schlie√ülich den Preis der Wohnung und ob sie zu diesem Preis verkauft wurde (1) oder nicht (0).\n\n\nm2\n# Schlafz.\n# Bad\nRenoviert\n‚Ä¶\nPreis\nVerkauft\n\n\n\n\n125\n4\n2\n2000\n‚Ä¶\n500k\n1\n\n\n75\n2\n1\n1990\n‚Ä¶\n350k\n1\n\n\n150\n6\n2\n2010\n‚Ä¶\n750k\n0\n\n\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n‚Ä¶\n\n\n35\n5\n2\n1999\n‚Ä¶\n620k\n0\n\n\n65\n3\n1\n2015\n‚Ä¶\n220k\n1\n\n\n100\n3\n1\n2003\n‚Ä¶\n450k\n0\n\n\n\n\n\nDimensionsreduktion\nAnwendungsf√§lle:\n\nErstellen einer 2D-Visualisierung, um den Datensatz im Ganzen zu √ºberblicken, wobei wir oft bereits beim Draufschauen Muster identifizieren k√∂nnen, wie Datenpunkte, die zusammen gruppiert werden k√∂nnen (Cluster) oder die nicht ins Bild passen (Ausrei√üer)\nRauschunterdr√ºckung und/oder Feature-Engineering als Datenvorverarbeitungsschritt zur Verbesserung der Ergebnisse eines Vorhersagemodells\n\n\nBeispiel Unsupervised Learning: Dimensionsreduktion\nZiel: Datensatz visualisieren\n\n\n\nDer erste Schritt bei der Analyse eines neuen Datensatzes besteht normalerweise darin, diesen zu visualisieren, um einen besseren √úberblick √ºber alle Datenpunkte und ihre Vielfalt zu erhalten. Daf√ºr eignet sich ein Dimensionsreduktionsalgorithmus, der die urspr√ºnglichen hochdimensionalen Daten als Input nimmt, wobei jede Spalte (= Feature) in der Tabelle eine Dimension darstellt, und eine niedrigerdimensionale Darstellung der Datenpunkte ausgibt, d.h. eine neue Matrix mit weniger Spalten (normalerweise zwei f√ºr eine Visualisierung). Diese beiden neuen Features, in unserem Fall \\(z_1\\) und \\(z_2\\) genannt, k√∂nnen jetzt verwendet werden, um einen Scatterplot des Datensatzes zu erstellen. Dabei wird jeder Datenpunkt / Zeile (also in diesem Fall jede Wohnung) als Punkt in diesem neuen 2D-Koordinatensystems dargestellt. Wir k√∂nnen uns diese Darstellung als eine Landkarte unseres Datensatzes vorstellen, die es uns erm√∂glicht, alle Datenpunkte auf einen Blick zu sehen und evtl. schon interessante Muster zu erkennen, z.B. Gruppen √§hnlicher Datenpunkte, die auf dieser 2D-Karte eng beieinander liegen. Aber bitte beachte: was sich hinter diesen neuen Koordinaten verbirgt l√§sst sich bei den meisten Dimensionsreduktionsmethoden nicht genau nachvollziehen. Insbesondere sind dies nicht einfach die beiden informativsten Originalfeatures, sondern v√∂llig neue Variablen, die die Informationen der urspr√ºnglichen Inputs zusammenfassen. Um den Scatterplot besser interpretieren zu k√∂nnen, ist es oft hilfreich, die Punkte nachtr√§glich mit den Werten einer Variablen einzuf√§rben, wodurch m√∂glicherweise die treibenden Faktoren hinter den auff√§lligsten Mustern im Datensatz aufgedeckt werden k√∂nnen. In diesem Beispiel h√§tten wir die Punkte nach dem Preis der entsprechenden Wohnung einf√§rben k√∂nnen und dadurch gesehen, ob √§hnlich bepreiste Wohnungen nah beieinander liegen.\n\n\n\nM√∂gliche Herausforderungen:\n\ndie Transformation der Daten mit Dimensionsreduktionsmethoden konstruiert neue Features als (nicht)lineare Kombination der urspr√ºnglichen Features, was die Interpretation der nachfolgenden Analyseergebnisse erschwert\n\n\n\nAnomalieerkennung\nAnwendungsf√§lle:\n\nBereinigung der Daten, z.B. durch Entfernen von Datenpunkten mit falsch eingegebenen Werten, als Datenvorverarbeitungsschritt zur Verbesserung der Ergebnisse eines Vorhersagemodells\nWarnung f√ºr Anomalien einrichten, zum Beispiel:\n\nBetrugserkennung: Identifizierung betr√ºgerischer Kreditkartentransaktionen im E-Commerce\n√úberwachen einer Maschine, um zu erkennen, wenn etwas Au√üergew√∂hnliches passiert oder die Maschine m√∂glicherweise gewartet werden muss\n\n\n\nBeispiel Unsupervised Learning: Anomalieerkennung\nZiel: Ausrei√üer im Datensatz finden\n\n\n\nAls n√§chstes pr√ºfen wir unseren Datensatz auf Ausrei√üer/Anomalien (Outliers/Anomalies), um diese Datenpunkte dann gegebenenfalls nachtr√§glich zu korrigieren oder zu entfernen. Ein Algorithmus zur Anomalieerkennung gibt f√ºr jeden Datenpunkt einen Anomalie-Score aus, der angibt, inwieweit dieser Datenpunkt von der Norm abweicht. Diese Scores k√∂nnen wir auch verwenden, um die 2D-Landkarte unseres Datensatzes aus dem vorherigen Schritt einzuf√§rben. Dadurch werden die Anomalien im Kontext sichtbar. Leider sagt uns ein Anomalieerkennungsalgorithmus nicht, warum ein bestimmter Punkt als Ausrei√üer erkannt wurde. Ein Data Scientist muss deshalb die gefundenen Anomalien untersuchen und entscheiden, ob diese z.B. aufgrund fehlerhafter Messungen entfernt werden sollten oder ob sie interessante Sonderf√§lle darstellen. In unserem Beispiel handelt es sich bei dem als Anomalie identifizierten Datenpunkt um eine Wohnung, die angeblich nur eine Gr√∂√üe von 35\\(m^2\\), aber gleichzeitig 5 Schlafzimmer hat. Da liegt die Vermutung nahe, dass hier beim Eintragen der Daten ein Fehler passiert ist und die Gr√∂√üe der Wohnung stattdessen 135\\(m^2\\) sein sollte.\n\n\n\nM√∂gliche Herausforderungen:\n\ndu solltest immer einen guten Grund haben, Datenpunkte weg zu lassen ‚Äì Ausrei√üer sind selten zuf√§llig, manchmal sind dies interessante Randf√§lle, die nicht ignoriert werden sollten\n\n\n\nClustering\nAnwendungsf√§lle:\n\nIdentifizieren von Gruppen verwandter Datenpunkte, zum Beispiel:\n\nKundensegmentierung f√ºr gezielte Marketingkampagnen\n\n\n\nBeispiel Unsupervised Learning: Clustering\nZiel: Nat√ºrlich vorkommende Gruppen im Datensatz finden\n\n\n\nAls letzte explorative Analyse k√∂nnen wir √ºberpr√ºfen, ob der Datensatz nat√ºrlich vorkommende Gruppen enth√§lt. Das funktioniert mit einem Clustering-Algorithmus, der einen Cluster-Index f√ºr jeden Datenpunkt zur√ºckgibt, wobei Punkte mit demselben Index in der selben Gruppe sind. Bitte beachte, dass diese Cluster-Indizes nicht geordnet sind und beim erneuten Ausf√ºhren des Algorithmus den Datenpunkten m√∂glicherweise andere Nummern zugewiesen werden. Die Datenpunkte, denen vorher die gleiche Nummer zugewiesen wurde, sollten allerdings immer noch im gleichen Cluster sein, nur kann es eben sein, dass dieser Cluster nun ‚Äò5‚Äô statt ‚Äò3‚Äô hei√üt. Auch diese Cluster-Indizes k√∂nnen wir zur Einf√§rbung unserer Daten-Landkarte verwenden, um die Cluster im Kontext zu sehen. Allerdings sagt uns auch ein Clustering-Algorithmus wieder nur, welche Punkte sich √§hnlich genug sind, um zusammen gruppiert zu werden, aber nicht, warum die Punkte dem Cluster zugeordnet wurden und was die Cluster bedeuten. Die Data Scientistin muss auch hier wieder die Ergebnisse untersuchen und versuchen zu interpretieren, worin sich die Cluster unterscheiden. In unserem Beispiel k√∂nnten die Cluster ‚Äúbillige Studiowohnungen‚Äù, ‚Äúgro√üe Familienwohnungen‚Äù und ‚Äúluxuri√∂se Penthouse Wohnungen‚Äù sein. Beim Unsupervised Learning gibt es keine richtige L√∂sung und ein anderer Clustering-Algorithmus k√∂nnte andere Ergebnisse liefern. Verwende einfach die L√∂sung, die f√ºr deinen Anwendungsfall am hilfreichsten ist.\n\n\n\nM√∂gliche Herausforderungen:\n\nkeine Ground Truth: Modell- und Parameterselektion nicht trivial ‚Üí die Algorithmen werden immer etwas finden, aber ob dies sinnvoll ist (d.h. was die identifizierten Muster bedeuten), kann ein Menschen in einem Nachbearbeitungsschritt bestimmen\nviele der Algorithmen beruhen auf √Ñhnlichkeiten oder Distanzen zwischen Datenpunkten, und es kann schwierig sein, daf√ºr ein geeignetes Ma√ü zu definieren oder im Voraus zu wissen, welche Merkmale verglichen werden sollten (z.B. was macht zwei Kunden √§hnlich?)\n\n\nUnsupervised Learning hat keine zugrundeliegende Wahrheit\nBei Unsupervised Learning Problemen sollte uns bewusst sein, dass es keine richtigen oder falschen Antworten gibt. Unsupervised Learning Algorithmen erkennen lediglich Muster in den Daten. Das Ergebnis kann f√ºr uns Menschen sinnvoll sein oder auch nicht.\nEin Beispiel: Im Bereich Unsupervised Learning gibt es eine Reihe verschiedener Algorithmen, die Datenpunkte in Cluster gruppieren. Dabei arbeitet jeder Algorithmus nach einer etwas anderen Strategie und bewertet unterschiedlich, ab wann zwei Punkte √§hnlich genug sind, dass sie in denselben Cluster eingeordnet werden k√∂nnen.\n\n\n\nDie offensichtlichste Reaktion eines Menschen ist, diese Bilder nach den darauf gezeigten Fr√ºchten zu sortieren. Theoretisch ist es jedoch genauso richtig, die Bilder anhand eines anderen Merkmals zu gruppieren, z.B. der Hintergrundfarbe, ob an der Frucht ein Blatt h√§ngt, in welche Richtung der Stiel zeigt usw.\n\n\nEs ist unsere Aufgabe, die Ergebnisse eines Unsupervised Learning Algorithmus zu untersuchen und zu verstehen. Entsprechen die Resultate nicht unseren Erwartungen, spricht nichts dagegen, einen anderen Algorithmus auszuprobieren.\n\n\n\nRegression & Klassifikation\nAnwendungsf√§lle:\n\nLerne ein Modell, um eine Input-Output-Beziehung zu beschreiben und Vorhersagen f√ºr neue Datenpunkte zu treffen, zum Beispiel:\n\nvor der Produktion vorhersagen, ob ein unter den vorgeschlagenen Prozessbedingungen hergestelltes Produkt von hoher Qualit√§t oder Ressourcenverschwendung sein wird\nChurn Prediction: Erkenne Kunden, die kurz davor stehen, ihren Vertrag zu k√ºndigen (oder Mitarbeiter, die kurz davor stehen zu k√ºndigen), damit du sie kontaktieren und √ºberzeugen kannst zu bleiben\nPreisoptimierung: Bestimme den optimalen Preis f√ºr ein Produkt (oft f√ºr dynamische Preisgestaltung verwendet, z.B. um Preise basierend auf dem Ger√§t anzupassen, das ein Kunde verwendet, wenn er auf eine Website zugreift, wie z.B. ein neues iPhone gegen√ºber einem alten Android-Handy)\nPredictive Maintenance: Sage voraus, wie lange ein Maschinenbauteil halten wird\nUmsatzprognosen: Sag den Umsatz in den kommenden Wochen und den erforderlichen Lagerbestand voraus, um die Nachfrage zu befriedigen\n\n\n\n\nBeispiel Supervised Learning: Klassifikation\nZiel: Vorhersage eines diskreten Werts f√ºr jeden Datenpunkt\n\n\n\nNun k√∂nnten wir vorhersagen, ob eine Wohnung zum angegebenen Preis verkauft wird. Da die Variable ‚ÄúVerkauft‚Äù nur die diskreten Werte ‚Äòja‚Äô (1) oder ‚Äònein‚Äô (0) annehmen kann, ist dies ein bin√§res Klassifikationsproblem. Ein Klassifikationsmodell nimmt die Attribute einer Wohnung zusammen mit dem Angebotspreis als Input und berechnet dann, ob die Wohnung zu diesem Preis verkauft wird oder nicht. Da wir hier nun die wahren Labels kennen (zumindest f√ºr den urspr√ºnglich gesammelten Datensatz), k√∂nnen wir die Genauigkeit des Modells bewerten, indem wir berechnen, wie viele falsche Vorhersagen es generiert. Das ist ein Vorteil beim Supervised Learning: Wir k√∂nnen objektiv bestimmen, wie gut eine L√∂sung ist, und somit verschiedene Modelle systematisch miteinander vergleichen, w√§hrend die Data Scientistin beim Unsupervised Learning die Ergebnisse manuell im Detail untersuchen muss, um sie zu bewerten.\n\n\n\n\nBeispiel Supervised Learning: Regression\nZiel: Vorhersage eines kontinuierlichen Werts f√ºr jeden Datenpunkt\n\n\n\nSchlie√ülich m√∂chten wir vielleicht f√ºr eine neue Wohnung einen angemessenen Preis vorhersagen. Da Preise kontinuierliche Werte sind, ist dies ein Regressionsproblem. Das Modell verwendet die Attribute der Wohnungen als Input und schl√§gt dann einen geeigneten Preis vor. Da uns f√ºr die erhobenen Daten die tats√§chlichen (bzw. vom Immobilienmakler bestimmten) Preise vorliegen, k√∂nnen wir erneut berechnen, inwieweit das Regressionsmodell mit seinen Sch√§tzungen vom Originalpreis abweicht.\n\n\n\nM√∂gliche Herausforderungen:\n\nErfolg ungewiss: die Anwendung der Algorithmen ist zwar relativ einfach, aber es ist schwierig, im Voraus festzustellen, ob √ºberhaupt ein Zusammenhang zwischen den gemessenen Inputs und Outputs besteht (‚Üí Achtung: Garbage in, Garbage out!)\nangemessene Definition des Ergebnisses/Ziels/KPI, das modelliert werden soll, d.h. was bedeutet es eigentlich, dass ein Prozess gut l√§uft, und wie k√∂nnten externe Faktoren diese Definition beeinflussen (k√∂nnen wir z.B. die gleiche Leistung in einem au√üergew√∂hnlich hei√üen Sommertag erwarten?)\nwichtige Inputs fehlen, z.B. wenn es andere Einflussfaktoren gibt, die wir nicht ber√ºcksichtigt haben oder nicht messen konnten, wodurch nicht die gesamte Varianz der Zielgr√∂√üe erkl√§rt werden kann\nviele m√∂glicherweise irrelevante Inputs, die eine sorgf√§ltige Feature Selektion erfordern, um Scheinkorrelationen zu vermeiden, die zu falschen ‚ÄúWas-w√§re-wenn‚Äù-Prognosen f√ºhren w√ºrden, da die wahre kausale Beziehung zwischen den Inputs und Outputs nicht erfasst wird\noft sehr zeitintensive Datenvorverarbeitung notwendig, z.B. bei der Zusammenf√ºhrung von Daten aus unterschiedlichen Quellen und manuellem Feature Engineering\n\n\n\nDeep Learning & Generative AI\nAnwendungsf√§lle:\n\nAutomatisierung langwieriger, repetitiver Aufgaben, die sonst ein Menschen erledigt w√ºrde, z.B. (siehe auch ML ist √ºberall!):\n\nTextklassifizierung (z.B. Spam / Hate Speech / Fake News erkennen; Kundensupportanfragen an die passende Abteilung weiterleiten)\nSentimentanalyse (Teilaufgabe der Textklassifikation: Positive oder negative Texte erkennen, z.B. um Produktbewertungen oder das, was Social-Media-Nutzer √ºber ein Unternehmen sagen, zu √ºberwachen)\nSpracherkennung (z.B. diktierte Notizen transkribieren oder Videos mit Untertiteln versehen)\nmaschinelle √úbersetzung (Texte von einer Sprache in eine andere √ºbersetzen)\nBildklassifizierung / Objekterkennung (z.B. Identifizierung problematischer Inhalte (wie Kinderpornografie) oder Erkennung von Stra√üenschildern und Fu√üg√§ngern beim autonomen Fahren)\nBildbeschreibungen generieren (z.B. um das Online-Erlebnis f√ºr Menschen mit Sehbehinderung zu verbessern)\nPredictive Typing (z.B. bei der Texteingabe auf dem Smartphone m√∂gliche n√§chste W√∂rter vorschlagen)\nDatengenerierung (z.B. neue Fotos/Bilder von bestimmten Objekten oder Szenen generieren)\nStyle Transfer (ein Bild in einen anderen Stil zeigen, z.B. Fotos wie van Gogh-Gem√§lde aussehen lassen)\neinzelne Quellen eines Audiosignals trennen (z.B. einen Song entmischen, d.h. Gesang und Instrumente in einzelne Spuren trennen)\n\nklassische Simulationsmodelle durch ML Modelle ersetzen: da exakte Simulationsmodelle oft langsam sind, kann die Berechnung f√ºr neue Datenpunkte beschleunigt werden, indem die Ergebnisse stattdessen mit einem ML-Modell vorhergesagt werden, z.B.:\n\nAlphaFold: 3D-Proteinstruktur aus Aminos√§uresequenz generieren (zur Erleichterung der Arzneimittelentwicklung)\nSchNet: Energie und andere Eigenschaften von Molek√ºlen anhand ihrer Atomkonfiguration vorhersagen (um die Materialforschung zu beschleunigen)\n\n\nM√∂gliche Herausforderungen:\n\nAusw√§hlen einer geeigneten neuronalen Netzarchitektur und daf√ºr sorgen, dass das Modell gute Vorhersagen generiert; insbesondere beim Ersetzen traditioneller Simulationsmodelle ist es h√§ufig erforderlich, eine v√∂llig neue Art von neuronaler Netzarchitektur zu entwickeln, die speziell f√ºr diese Aufgabe und Inputs/Outputs ausgelegt ist, was viel ML- und Dom√§nenwissen, Intuition und Kreativit√§t erfordert\nRechenressourcen (trainiere kein neuronales Netz ohne GPU!)\nDatenqualit√§t und -quantit√§t: es werden viele konsistent (von Menschen) gelabelte Daten ben√∂tigt\n\n\nKI-Agenten: Gen AI + ‚ÄúTools‚Äù (externe Funktionalit√§t)\nGenerative KI‚Äîoder genauer gesagt Large Language Models (LLMs)‚Äîwerden typischerweise in einem einfachen Loop verwendet: Man sendet einen Prompt und das Modell antwortet basierend auf Mustern, die es w√§hrend des Trainings gelernt hat.\nKI-Agenten bauen auf LLMs auf, indem sie dieses grundlegende Setup um den Zugriff auf Tools erweitern, also externe Funktionalit√§t, die dem Modell zur Verf√ºgung gestellt wird. Im einfachsten Fall k√∂nnte ein Tool dem KI-Agenten erm√∂glichen, das Internet zu durchsuchen; fortgeschrittenere Tools k√∂nnten auf Datenbanken zugreifen, Code ausf√ºhren oder Dateien manipulieren.\n\n\n\nKI-Agenten-Workflow: Das LLM analysiert den Prompt des Nutzers, um zu bestimmen, was dieser m√∂chte und ob der Aufruf von Tools helfen w√ºrde, die Aufgabe zu erledigen. Tools sind externe Funktionen‚Äîdas LLM sendet Anfragen und erh√§lt Antworten, aber die Ausf√ºhrung erfolgt in separaten Prozessen. Nach Erhalt der Ergebnisse pr√ºft das LLM, ob die Aufgabe abgeschlossen ist oder ob weitere Arbeit n√∂tig ist. Dieser Loop wird fortgesetzt, bis die Aufgabe erledigt ist, dann generiert der Agent eine finale Antwort f√ºr den Nutzer.\n\n\nDer Agent muss explizit dar√ºber informiert werden, welche Tools verf√ºgbar sind‚Äîim Wesentlichen durch eine Liste von Tool-Namen mit Beschreibungen und Nutzungsanweisungen (z.B., dass Suchbegriffe f√ºr die Internetsuche erforderlich sind). Man kann auch eigene Tools implementieren, etwa um dem LLM Zugriff auf die Unternehmensdatenbank zu geben, um Lagerbest√§nde zu durchsuchen. W√§hrend bereits viel mit Tools erreicht werden kann, die nur Lesezugriff haben, ist noch mehr m√∂glich (im Guten wie im Schlechten), wenn man dem Agenten Schreibzugriff gibt, etwa die Option, Dateien auf dem Computer zu manipulieren. Dies ist beispielsweise f√ºr Coding-Agenten notwendig, die Code-Dateien erstellen und modifizieren, um neue Funktionalit√§t zu programmieren.\nEin wesentliches Merkmal von KI-Agenten ist ihre F√§higkeit, autonom zu handeln durch einen internen Loop, der weiterarbeitet und Tools aufruft, bis das LLM entscheidet, dass die Aufgabe abgeschlossen ist. Dies erm√∂glicht mehrstufige Workflows wie das Durchsuchen verschiedener Informationsquellen, das Treffen von Zwischenentscheidungen und das Iterieren basierend auf Ergebnissen. Beispielsweise bearbeitet ein Coding-Agent Skripte, f√ºhrt Tests aus, behebt Fehler wenn Tests fehlschlagen und wiederholt dies, bis alles funktioniert.\nKI-Agenten haben jedoch auch wichtige Einschr√§nkungen, die ber√ºcksichtigt werden m√ºssen:\n\nChat ist nicht immer das richtige Interface. Manche Aufgaben ben√∂tigen reichhaltige UIs (z.B. Sitzplatzauswahl beim Ticketkauf). Solche Interaktionen in Text zu kodieren kann umst√§ndlich und fehleranf√§llig sein.\nLLM-Outputs k√∂nnen immer noch falsch sein. Selbst bei Nutzung externer, vermeintlich zuverl√§ssiger Quellen ist menschliche Verifikation weiterhin notwendig.\nSchreibzugriff erh√∂ht das Risiko. Fehler sind gravierender, wenn Agenten Dateien oder Systeme modifizieren k√∂nnen. Guardrails sind n√∂tig, um destruktive Aktionen zu verhindern (z.B. L√∂schen wichtiger Daten).\nBenutzerdefinierte Tools erfordern gut strukturierte Softwaresysteme. KI-Agenten mit eigener Funktionalit√§t auszustatten ist deutlich einfacher, wenn die bestehende Software √ºber klare, wiederverwendbare Schnittstellen verf√ºgt.\nKosten- und Missbrauchs√ºberlegungen: LLMs werden meist √ºber kostenpflichtige APIs (z.B. OpenAI) angesprochen und jeder Agenten-Schritt verursacht Kosten. Bei Zugriff durch externe Nutzer ist oft Rate Limiting notwendig, um Missbrauch zu verhindern.\n\n\n\n\nInformation Retrieval\nAnwendungsf√§lle:\n\nVerbesserte Suchergebnisse durch Identifizierung √§hnlicher Artikel, zum Beispiel:\n\nbei einer Suchanfrage passende Dokumente / Websites zur√ºckgeben\ngegeben einem Film, den der Nutzer gerade anschaut, √§hnliche Filme anzeigen (z.B. gleiches Genre, gleicher Regisseur usw.)\n\n\nM√∂gliche Herausforderungen:\n\nQualit√§t der Ergebnisse h√§ngt stark von der gew√§hlten √Ñhnlichkeitsmetrik ab; die Identifizierung semantisch verwandter Elemente ist derzeit f√ºr einige Datentypen (z.B. Bilder) schwieriger als f√ºr andere (z.B. Text)\n\n\n\nEmpfehlungssysteme\nAnwendungsf√§lle:\n\npersonalisierte Vorschl√§ge: gegeben einer Instanz (z.B. Benutzer, Proteinstruktur) die relevantesten Elemente identifizieren (z.B. Film, Arzneimittelzusammensetzung), zum Beispiel:\n\neinem Nutzer Filme vorschlagen, die anderen Nutzern mit √§hnlichem Geschmack ebenfalls gefallen haben\nMolek√ºlstrukturen empfehlen, die in eine, f√ºr eine bestimmte Krankheit relevante, Proteinstruktur passen k√∂nnte\n\n\nM√∂gliche Herausforderungen:\n\nwenig / unvollst√§ndige Daten, z.B. m√∂gen verschiedene Nutzer denselben Artikel aus unterschiedlichen Gr√ºnden und es ist unklar, ob z.B. ein Nutzer einen Film nicht angesehen hat, weil er sich nicht daf√ºr interessiert oder weil er ihn einfach noch nicht gefunden hat\n\n\n\nReinforcement Learning\nAnwendungsf√§lle:\n\nErmittlung einer optimalen Handlungsabfolge bei wechselnden Umgebungsbedingungen, z.B.:\n\nVirtueller Agent, der ein (Video-)Spiel spielt\nRoboter mit komplexen Bewegungsmustern, z.B. Aufnehmen unterschiedlich geformter Gegenst√§nde aus einer Kiste\n\n\n‚áí Anders als bei der regul√§ren Optimierung, wo eine optimale Eingabe f√ºr einen spezifischen externen Zustand bestimmt wird, versucht hier ein ‚ÄúAgent‚Äù (= der RL-Algorithmus) eine optimale Reihenfolge von Eingaben zu finden, um die kumulative Belohnung √ºber mehrere Schritte zu maximieren. Dabei kann zwischen einer Handlung und der dazugeh√∂rigen Belohnung eine erhebliche Zeitverz√∂gerung liegen (z.B. wenn in einem Videospiel zu Beginn eines Levels ein Schl√ºssel gefunden werden muss, aber die T√ºr, die damit ge√∂ffnet werden kann, erst einige Frames sp√§ter kommt).\nM√∂gliche Herausforderungen:\n\nerfordert normalerweise eine Simulationsumgebung, in der der Agent ‚Äúangelernt‚Äù wird, bevor er anf√§ngt, in der realen Welt zu handeln. Die Entwicklung eines exakten Simulationsmodells ist allerdings nicht einfach und der Agent wird alle Bugs ausnutzen, wenn dies zu h√∂heren Belohnungen f√ºhrt\nes kann schwierig sein, eine klare Belohnungsfunktion zu definieren, die optimiert werden soll (‚ÄúImitation Learning‚Äù ist dabei oft einfacher, wobei der Agent stattdessen versucht, die Entscheidungen eines Menschen in einer bestimmten Situation nachzuahmen)\nlange Verz√∂gerungen zwischen kritischen Aktionen und der dazugeh√∂rigen Belohnung erschweren das lernen korrekter Assoziationen\nder Agent generiert seine eigenen Daten: Wenn er mit einer schlechten Policy startet, wird es schwierig, dieser zu entkommen (z.B. wenn der Agent in einem Videospiel immer in eine L√ºcke f√§llt, anstatt dar√ºber zu springen, sieht er nie die Belohnung, die auf der anderen Seite wartet und lernt daher nicht, dass es von Vorteil w√§re, √ºber die L√ºcke zu springen)\n\n\n\nAndere\n\n\n\n\n\n\nWichtigW√§hle ein ML-Modell, das zu deinem Zieloutput passt\n\n\n\nML-Algorithmen werden anhand des Outputs kategorisiert, den sie f√ºr eine Eingabe generieren. Wenn man ein ‚ÄòInput ‚Üí Output‚Äô-Problem mit einem anderen als den oben aufgef√ºhrten Outputs l√∂sen m√∂chte, wird das wahrscheinlich auf ein mehrj√§hriges Forschungsprojekt hinauslaufen ‚Äì wenn das Problem √ºberhaupt mit ML gel√∂st werden kann!\n\n\n\nUm komplexe Probleme zu l√∂sen, ben√∂tigt man m√∂glicherweise mehrere Algorithmen\nBeispiel: virtueller Assistent (z.B. Siri oder Alexa): ‚ÄúHey &lt;Sprachassistent&gt;, erz√§hl mir einen Witz!‚Äù ‚Üí ein zuf√§lliger Witz\n\nDas sieht zwar zun√§chst wie ein Input-Output-Problem aus, es direkt zu l√∂sen w√§re allerdings sehr schwierig und ineffizient. Stattdessen zerlegen wir das Problem in kleinere Teilaufgaben, die mit bestehenden Algorithmen gel√∂st werden k√∂nnen:\n\n\nTriggerwort Erkennung:\nAudio ‚Üí ‚ÄúHey &lt;Sprachassistent&gt;‚Äù (ja/nein)?\nSpracherkennung:\nAudio ‚Üí Text\nKlassifizierung der Absicht:\nText ‚Üí (Witz/Timer/Wettervorhersage/‚Ä¶)?\nF√ºhre spezifisches Programm aus (z.B. w√§hle zuf√§lligen Witz aus)\nSprachgenerierung:\nText ‚Üí Audio\n\n\nZun√§chst muss der Smart Speaker wissen, ob er mit einem bestimmten Triggerwort (z.B. ‚ÄúHey Siri‚Äù) angesprochen wurde. Dies ist eine einfache bin√§re Klassifikation (ja/nein), die normalerweise auf dem Ger√§t selbst ausgef√ºhrt wird, da wir nicht m√∂chten, dass alles was wir sagen permanent in die Cloud gestreamt wird. Als n√§chstes werden die nach dem Triggerwort gesprochenen W√∂rter in Text √ºbersetzt. Text ist einfacher zu handhaben, da beispielsweise Variationen aufgrund unterschiedlicher Akzente entfernt werden. Anhand dieses Textes wird die Absicht des Nutzers erkannt, also welche der verschiedenen Funktionalit√§ten des virtuellen Assistenten genutzt werden soll (z.B. Witz erz√§hlen, Musik abspielen, Wecker stellen etc.). Dies ist ein Multiclass-Klassifikationsproblem. Zur Ausf√ºhrung des Befehls wird kein ML ben√∂tigt, sondern ein normales, aufgabenspezifisches Programm, das als App auf dem Ger√§t installiert ist, z.B. wird ein Witz aus einer Datenbank ausgew√§hlt oder ein Timer gesetzt usw.. Anschlie√üend muss der Output des ausgef√ºhrten Programms wieder in ein Audiosignal umgewandelt werden. Ein ML-Modell kann dabei helfen, fl√ºssig gesprochenen Text zu erzeugen ‚Äì und in naher Zukunft vielleicht auch mit der Stimme von Morgan Freeman oder einer anderen ber√ºhmten Person, wie bei ‚ÄúDeep Fake‚Äù-Anwendungen.\n\n‚áí Generell sollte man zun√§chst dar√ºber nachzudenken, ob man ein Problem in leichter zu l√∂sende Teilprobleme zerlegen kann, da es daf√ºr oft schon gro√üe Datens√§tze oder sogar fertige Modelle gibt. Ein Modell f√ºr Spracherkennung kann beispielsweise zus√§tzlich auf H√∂rb√ºchern und transkribierten politische Reden trainiert werden, nicht nur auf den Daten, die von den Sprachassistent-Nutzern gesammelt wurden.\n\n\n\n\n\n\nVorsichtTrainiere nachgelagerte Modelle neu, wenn sich die Outputs vorgelagerter Modelle √§ndern\n\n\n\nWenn ein ML-Modell als Input den Output eines anderen ML-Modells erh√§lt, bedeutet dies, dass wir, sobald wir eine neue Version des ersten ML-Modells verwenden, auch die folgenden Modelle neu trainieren sollten, da diese Modelle dann evtl. leicht andere Inputs erhalten, d.h. wir es mit einem Daten Drift zu tun haben.\n\n\n\n\n\n\n\n\n\nTippNutzung vortrainierter Modelle\n\n\n\nAbh√§ngig vom Datentyp kann es sinnvoll sein, anstelle eines Trainings von Grund auf bestehende Modelle direkt zu verwenden oder sie auf den eigenen Daten feinzujustieren. Wie weit dies m√∂glich ist, h√§ngt davon ab, wie generisch die Daten sind. Textdaten sind vergleichsweise universell, w√§hrend Bildmodelle zwar allgemeine visuelle Muster lernen, aber dennoch an das jeweilige Einsatzszenario angepasst werden m√ºssen. F√ºr andere Datentypen ‚Äì insbesondere tabellarische Daten und Zeitreihen ‚Äì ist es in der Regel erforderlich, eigene Modelle von Grund auf auf den eigenen Daten zu trainieren (unter Nutzung bestehender Algorithmen aus Open-Source-Bibliotheken), da Datens√§tze zwischen Anwendungsf√§llen selten vergleichbar sind, etwa aufgrund unterschiedlicher Sensoren oder einer variierenden Anzahl und Bedeutung von Features.\n\n\n\nF√ºr sehr generische Anwendungsf√§lle wie OCR (Optical Character Recognition), maschinelle √úbersetzung oder Speech-to-Text-Anwendungen (z.B. Software zur automatischen Protokollierung von Meetings) ist es in der Regel kosteneffizienter, ein bestehendes Produkt zu nutzen ‚Äì sofern dies nicht genau die Art von Software ist, die das eigene Unternehmen verkauft. F√ºr viele Anwendungen, die man selbst entwickelt, ist es jedoch h√§ufig m√∂glich, auf vortrainierte Modelle zur√ºckzugreifen. Dazu z√§hlen beispielsweise LLMs f√ºr Textdaten, entweder √ºber eine API oder als Open-Weights-Modelle, sowie Modelle, die auf den eigenen Daten feinjustiert werden. Letzteres ist oft der beste Ansatz f√ºr Computer-Vision-Aufgaben, bei denen die Daten, auf denen das urspr√ºngliche Modell trainiert wurde, nicht direkt mit den eigenen Daten vergleichbar sind (etwa wenn ein Modell an Bilder aus einer spezifischen Produktionslinie angepasst werden muss).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Grundlagen</span>"
    ]
  },
  {
    "objectID": "01b_basics.html#sec-solving-problems",
    "href": "01b_basics.html#sec-solving-problems",
    "title": "Grundlagen",
    "section": "Mit ML Probleme l√∂sen",
    "text": "Mit ML Probleme l√∂sen\nDas L√∂sen von ‚ÄúInput ‚Üí Output‚Äù-Problemen mit ML erfordert drei Hauptschritte:\n\n\n\n\n\n\n1. Identifiziere ein Problem\nDer erste (und wohl wichtigste) Schritt besteht darin, zu identifizieren, wo maschinelles Lernen √ºberhaupt eingesetzt werden kann (und sollte).\n\n\n\nWir wollen etwas entwickeln, das Nutzer (intern oder extern) tats√§chlich wollen, indem wir einen echten Schmerzpunkt adressieren, beispielsweise durch die Automatisierung einer m√ºhsamen, sich wiederholenden Aufgabe. Gleichzeitig muss die L√∂sung dieses Problems wirtschaftlich sinnvoll sein, indem sie Umsatz steigert oder Kosten reduziert, und mit den √ºbergeordneten strategischen Zielen der Organisation √ºbereinstimmt, z.B. einen Wettbewerbsvorteil bringt. Schlie√ülich muss die L√∂sung technisch umsetzbar sein, das hei√üt, sie muss realistischerweise mit bestehenden ML-Methoden und verf√ºgbaren Daten gel√∂st werden k√∂nnen.\n\n\n\nSchritte zur Identifizierung eines potenziellen ML-Projekts\n\nErstelle ein Prozessdiagramm: Welche Schritte werden in einem Gesch√§ftsprozess ausgef√ºhrt und welche Daten werden wo gesammelt (Material- & Informationsfluss). Zum Beispiel in einem Produktionsprozess, bei dem einige der produzierten Teile fehlerhaft sind:\n\n\n\n\n\nIdentifiziere Teile des Prozesses, die entweder mit ML automatisiert werden k√∂nnten (z.B. einfache, sich wiederholende Aufgaben, die sonst von Menschen erledigt werden) oder die auf andere Weise durch eine Analyse von Daten verbessert werden k√∂nnten (z.B. um die Ursachen eines Problems zu verstehen, die Planung mit Was-w√§re-wenn-Simulationen zu verbessern, oder die Ressourcennutzung zu optimieren):\n\n\n\nDie erste Idee besteht darin, die bisher von einem Menschen durchgef√ºhrte Qualit√§tspr√ºfung zu automatisieren: Da der Mensch die Defekte in den aufgenommenen Produktbildern leicht erkennen kann, sollte ein ML-Modell dies auch schaffen. Die n√§chste Idee besteht darin, anhand der Zusammensetzung der Rohstoffe und der gegebenen Prozessbedingungen vor der Herstellung vorherzusagen, ob ein Produkt fehlerhaft sein wird oder nicht: Der Erfolg ist hier unklar, da eine menschliche Expertin nicht von vorne herein absch√§tzen kann, ob alle relevanten Informationen daf√ºr in diesen Daten enthalten sind. Aber dennoch w√§re es einen Versuch wert, da man dadurch viele Ressourcen sparen k√∂nnte. W√§hrend das endg√ºltige ML-Modell, welches das Input-Output-Problem l√∂st, als Software im laufenden Betrieb eingesetzt werden kann, kann ein Data Scientist zus√§tzlich die Ergebnisse analysieren und das Modell interpretieren und somit Erkenntnisse gewinnen und Handlungsempfehlungen aussprechen.\n\n\nPriorisieren: Welches Projekt h√§tte eine gro√üe Wirkung und gleichzeitig gute Erfolgsaussichten, h√§tte also einen hohen Return on Investment (ROI)? Als Beispiel: Die Verwendung von ML zur Automatisierung einer einfachen Aufgabe ist aus technischer Sicht eine vergleichsweise risikoarme Investition, kann jedoch dazu f√ºhren, dass einige Flie√übandarbeiter ihre Jobs verlieren. Andererseits k√∂nnten durch die Ermittlung der Ursachen, warum in einem Produktionsprozess 10% Ausschuss produziert werden, Millionen eingespart werden. Allerdings ist nicht vorhersehbar, ob eine solche Analyse tats√§chlich n√ºtzliche Ergebnisse liefert, da die gesammelten Daten zu den Prozessbedingungen m√∂glicherweise nicht alle erforderlichen Informationen enthalten.\n\nProjektideen werden am besten in einem kollaborativen Workshop mit Data Scientists, Fachexperten und Entwicklern identifiziert:\n\n\n\nFangt damit an, den Prozess zu verstehen, den ihr verbessern wollt, und visualisiert ihn auf einfache, informelle Weise, zum Beispiel mit Post-its. Als N√§chstes sollen alle potenzielle Schmerzpunkte identifizieren, etwa manuelle Schritte oder fehleranf√§llige Aufgaben. Notiert dann verf√ºgbare Datenquellen und die Art der gesammelten Daten, um ungenutzte Potenziale aufzudecken. Ordnet schlie√ülich m√∂gliche ML-L√∂sungen den identifizierten Schmerzpunkten und Datenquellen zu. W√§hlt zwei bis drei vielversprechende Ideen aus ‚Äì jede bestehend aus einem Schmerzpunkt, einer Datenquelle und einem ML-Ansatz ‚Äì um diese gr√ºndlicher zu bewerten und m√∂glicherweise als Proof of Concepts umzusetzen.\n\n\n\n\nML Projekt Checkliste\nMotivation\n\nWelches Problem m√∂chtest du l√∂sen?\nMachine Learning kann dir in verschiedenen Situationen helfen, z.B. indem es Erkenntnisse aus gro√üen Mengen (m√∂glicherweise unstrukturierter) Daten generiert, Entscheidungsfindungs- und Planungsprozesse durch Vorhersagen √ºber zuk√ºnftige Ereignisse verbessert, oder m√ºhsame Aufgaben automatisiert, die sonst menschliche Experten erfordern.\nWo l√§uft etwas ineffizient, was durch eine effektivere Nutzung von Daten verbessert werden k√∂nnte? Du k√∂nntest zum Beispiel nach M√∂glichkeiten suchen, verschwendete Ressourcen/Zeit/Kosten zu reduzieren oder den Umsatz/die Kundenzufriedenheit/usw. zu steigern.\nUm systematisch Probleme oder Verbesserungsm√∂glichkeiten zu erkennen, kann es auch helfen, ein Prozessdiagramm oder eine Customer Journey Map zu erstellen.\nAuf welche Art und Weise w√ºrde dies Wert f√ºr eure Organisation generieren?\nWie k√∂nnte eure Organisation damit Geld verdienen oder Kosten senken?\n\nK√∂nnte dies einen internen Prozess verbessern (z.B. k√∂nnte ein Prozess mit den Erkenntnissen aus einer Analyse effizienter gestaltet werden oder eine l√§stige Aufgabe, die sonst einen menschlichen Arbeiter erfordern w√ºrde, kann mithilfe eines ML-Modells automatisiert werden)?\nK√∂nnte das ML-Modell als neues Feature in ein bestehendes Produkt integriert werden und dadurch z.B. dieses Produkt f√ºr Kunden attraktiver machen?\nK√∂nnte die ML-L√∂sung als v√∂llig neues Produkt oder Service verkauft werden, z.B. als Software-as-a-Service (SaaS)-L√∂sung angeboten werden?\n\n\n\nBitte beachte, dass die letztendliche Verwendung der ML-L√∂sung auch eine strategische Entscheidung sein kann, die f√ºr jede Organisation unterschiedlich sein kann. Beispielsweise k√∂nnte eine ML-L√∂sung, die Kratzer auf produzierten Produkten erkennt, von einem Unternehmen verwendet werden, um ihren internen Produktionsprozess zu verbessern, w√§hrend ein anderes Unternehmen, das die Maschinen herstellt, die die Produkte herstellen, dies als neues Feature in seine Maschinen integrieren k√∂nnte, und ein drittes Unternehmen bietet dies m√∂glicherweise als SaaS-L√∂sung an, die mit verschiedenen Produktionslinien kompatibel ist.\n\n\nIn welcher Gr√∂√üenordnung k√∂nnte dieses Projekt Mehrwerte generieren?\n√úberlege dir den Impact im Hinblick auf\n\nGr√∂√üenordnung: Kleine Verbesserung oder Revolution? W√ºrde die L√∂sung einen strategischen Vorteil schaffen?\nSkalierung: Wie oft wird es verwendet? Wie viele Benutzer/Kunden/Mitarbeiter werden davon profitieren?\nZum Beispiel:\n\nKleine Prozessoptimierung, aber da dieser Prozess t√§glich in der gesamten Organisation verwendet wird, spart dies unz√§hlige Stunden\nNeue Funktion, die ein Produkt revolutioniert und euch von der Konkurrenz abhebt, aber der Markt daf√ºr ist winzig\n\nH√§tte dies irgendwelche wertvollen Nebenwirkungen? Was wird anders sein? Gibt es zus√§tzliche M√∂glichkeiten, die sich daraus ergeben k√∂nnten? K√∂nnen Synergien geschaffen werden zwischen Abteilungen, die mit √§hnlichen Daten arbeiten?\n\nWann hast du dein Ziel erreicht?\nWie w√ºrde Erfolg aussehen, d.h. was ist deine Definition von ‚Äòfertig‚Äô?\n\nKannst du den Fortschritt mit einem KPI quantifizieren?\nWie ist der Status quo, d.h. wie weit bist du derzeit von deinem Ziel entfernt?\nWelche Metriken sollten sich nicht ver√§ndern (verschlechtern) durch das Projekt?\n\n\nL√∂sungsansatz\n\nWie sieht deine Vision f√ºr die Zukunft mit ML aus?\n\nWie sieht dein bestehender Prozess / dein bestehendes System aus und was wird nach der Integration der ML-L√∂sung anders sein?\nWer sind die Nutzer und wie werden sie von dieser Ver√§nderung betroffen sein, brauchen sie z.B. zus√§tzliche Schulungen, um das neue System zu nutzen?\n\nWas sind die Deliverables?\nBesteht die L√∂sung aus einer Software, die irgendwo eingesetzt wird, um kontinuierlich Vorhersagen f√ºr neue Datenpunkte zu generieren, oder interessierst du dich f√ºr die Erkenntnisse, die aus einer einmaligen Analyse historischer Daten gewonnen werden?\nWie wird im Falle einer Softwarel√∂sung das ML-Modell in das bestehende Setup integriert?\n\nWie sieht eine Interaktion mit dem System aus (= 1 Datenpunkt / Beobachtung), z.B. ein Nutzer, der eine Anfrage stellt oder ein produziertes Produkt, das eine Qualit√§tskontrolle passiert?\nVon welchem System stammen die Inputs f√ºr das ML-Modell? Was passiert mit den Outputs des ML-Modells?\nWird eine zus√§tzliche Benutzeroberfl√§che (UI) oder API ben√∂tigt, um mit dem ML-Modell zu interagieren?\nMuss das ML-Modell Vorhersagen sofort treffen, sobald neue Daten eintreffen, oder kann es Daten asynchron in Batches verarbeiten? Wie hoch ist der erwartete Traffic (d.h. die Anzahl der Datenpunkte, die pro Sekunde verarbeitet werden m√ºssen)?\nWie sollte das ML-Modell deployed werden (z.B. Cloud, On-Premise oder Edge-Ger√§t)? Erfordert dies zus√§tzliche Infrastruktur oder spezielle Hardware (z.B. GPUs)?\nModellwartung: Was sind die Pl√§ne im Hinblick auf Pipelines f√ºr zuk√ºnftige Datenerfassung, Modell√ºberwachung und automatisiertes Nachtrainieren?\n\nWie sehen die Input Daten aus? Wie sollen die Outputs aussehen?\n\nWelche Art von Inputs bekommt das ML Modell (z.B. Bild / Text / Sensormessungen / etc.)?\nWelche Art von Outputs soll das ML-Modell produzieren, d.h. welche Kategorie von ML-Algorithmen l√∂st dieses Problem?\nHast du bereits Zugriff auf einen initialen Datensatz, um das Modell zu trainieren?\n\nWie soll die Performance des ML-Modells evaluiert werden?\n\nWelche Evaluierungsmetriken sind f√ºr den gegebenen ML-Anwendungsfall geeignet (z.B. Accuracy)?\nWie stehen diese Metriken in Zusammenhang mit den Gesch√§fts-KPIs, die durch diese L√∂sung verbessert werden sollen?\nWie kann die Performance des Modells im laufenden Betrieb √ºberwacht werden? Werden daf√ºr kontinuierlich neue gelabelte Daten gesammelt?\n\nGibt es eine einfachere L√∂sung ohne ML?\nVerwende ML, um unbekannte, komplexe Regeln aus Daten zu lernen.\n\nAuch wenn ML hier die richtige Wahl ist, k√∂nntest du ein minimal funktionsf√§higes Produkt ohne ML entwickeln, um die L√∂sung als Ganzes zu validieren, bevor du in ML investierst?\n\n\nHerausforderungen & Risiken\n\nGibt es gen√ºgend hochwertige Daten um das Modell zu trainieren und zu evaluieren?\n\nQualit√§t: Hast du die richtigen Inputs und eindeutige Labels?\n‚Üí Frage eine Fachexpertin, ob sie denkt, dass alle relevanten Inputs vorhanden sind, um das gew√ºnschte Ergebnis zu berechnen. Dies ist bei unstrukturierten Daten wie Bildern in der Regel leicht zu bestimmen - wenn ein Mensch das Objekt im Bild sehen kann, sollte es ML auch k√∂nnen. Aber bei strukturierten Daten, wie z.B. einer Tabelle mit Hunderten von Spalten mit Sensormessungen, kann dies unm√∂glich zu bestimmen sein, bevor man eine Analyse der Daten durchf√ºhrt.\nQuantit√§t: Wie viele Daten wurden bereits gesammelt (einschlie√ülich seltener Ereignisse und Labels)? Wie lange w√ºrde es dauern, mehr Daten zu sammeln? K√∂nnten zus√§tzliche Daten von einem Anbieter gekauft werden und wenn ja, wie viel w√ºrde das kosten?\nWie schwierig ist es, auf alle Daten zuzugreifen und sie ordentlich an einem Ort zu kombinieren? Mit wem w√ºrdest du sprechen, um die Dateninfrastruktur einzurichten/zu verbessern?\nWie viel Vorverarbeitung ist notwendig (z.B. Entfernung von Ausrei√üern, Korrigieren fehlender Werte, Feature Engineering, d.h. Berechnung neuer Variablen aus den bestehenden Messungen, etc.)? Was sollten die n√§chsten Schritte sein, um die Datenqualit√§t und -quantit√§t systematisch zu verbessern und die Vorverarbeitungsanforderungen in Zukunft zu verringern?\n\nKann das Problem mit einem existierenden ML-Algorithmus gel√∂st werden?\nFrage eine ML-Expertin, ob ein √§hnliches Problem bereits mit einem bew√§hrten Algorithmus gel√∂st wurde.\n\nF√ºr bekannte L√∂sungen: Wie komplex ist es, das Modell zum Laufen zu bringen (z.B. lineare Regression vs.¬†tiefes neuronales Netz)?\nF√ºr unbekannte L√∂sungen: Anstatt Jahre in die Forschung zu investieren, um einen neuartigen Algorithmus zu entwickeln, w√§re es m√∂glich, das Input-Output-Problem in einfachere Teilprobleme mit bekannten L√∂sungen zu zerlegen?\n\nWas w√ºrde im schlimmsten Fall passieren, wenn das Modell falsch liegt?\nDas ML-System wird (wie Menschen auch) Fehler machen. Benutze kein ML wenn du immer 100% korrekte Ergebnisse brauchst!\n\nWelches Performance-Level wird mindestens ben√∂tigt, damit die ML-L√∂sung Mehrwert liefert? Z.B. welche Falsch Positiv oder Falsch Negativ Rate w√§re noch akzeptabel? Was w√§re das Worst-Case-Szenario und wie viel Risiko bist du bereit einzugehen?\nWie wahrscheinlich ist es, dass sich die Inputs im Laufe der Zeit √§ndern, beispielsweise auf Grund sich √§ndernder Demographie der Nutzer oder durch unerwartete Ereignisse (Black Swan Events) wie eine Pandemie (z.B. COVID-19)? Wie oft m√ºsste man das Modell nachtrainieren, um diese Ver√§nderungen zu kompensieren und werden daf√ºr schnell genug neue (gelabelte) Daten gesammelt?\nBesteht f√ºr die Nutzer ein Anreiz, das System absichtlich zu t√§uschen (z.B. entwickeln Spammer raffiniertere Nachrichten, wenn ihre urspr√ºnglichen Nachrichten vom Spamfilter abgefangen werden)?\nGibt es eine M√∂glichkeit, das System erst zu √ºberwachen und trotzdem einen Mehrwert zu generieren (z.B. mit einer ‚ÄúHuman in the Loop‚Äù L√∂sung), statt vom ersten Tag an voll auf ML zu setzen?\n\nGibt es rechtliche oder ethische Bedenken beim Einsatz der L√∂sung?\n\nVerbietet irgendeine Verordnung, zum Beispiel das EU-Gesetz √ºber k√ºnstliche Intelligenz (EU AI Act), den Einsatz von ML f√ºr diese Anwendung?\nGibt es datenschutzrechtliche Bedenken, zum Beispiel weil personenbezogene Daten verwendet werden?\nM√ºssen die Entscheidungen des ML-Modells transparent und nachvollziehbar sein, z.B. wenn jemandem aufgrund eines algorithmisch generierten Kreditscores ein Kredit verweigert wird?\nBesteht die Gefahr, dass das Modell Nutzer diskriminieren k√∂nnte, beispielsweise weil es mit verzerrten Daten trainiert wurde?\n\nWas k√∂nnte sonst noch schief gehen?\n\nWarum k√∂nnten die Nutzer von der L√∂sung frustriert sein? An welcher Stelle w√ºrden sie z.B. lieber mit einem echten Menschen statt einem Chatbot interagieren?\n\n\n\n\n\nGl√ºcklicherweise sind lebensbedrohliche Situationen bei den meisten Machine Learning Anwendungsf√§llen kein Thema. Es ist jedoch wichtig, das Worst-Case-Szenario in Betracht zu ziehen, sollte das Modell falsche Ergebnisse liefern. Besonders bei komplexen Modellen, wie den Large Language Models (LLMs), die generative KI m√∂glich machen, ist es oft schwer, gute Schutzma√ünahmen gegen Missbrauch zu entwickeln.\n\n\nSelbst bauen oder einkaufen?\n\nKernbereich vs.¬†generische Anwendung: Schafft diese L√∂sung einen strategischen Vorteil?\nWird die L√∂sung ein wichtiger Bestandteil eures Gesch√§fts sein, z.B. ein neues Feature, das euer Produkt attraktiver macht und/oder erfordert die L√∂sung spezifisches Dom√§nenwissen, das nur in eurer Organisation verf√ºgbar ist, z.B. weil du Daten analysierst, die von euren eigenen speziellen Prozessen/Maschinen generiert werden? Oder ist dies ein allgemeines (aber komplexes) Problem, f√ºr das es bereits eine L√∂sung gibt (z.B. als Software-as-a-Service (SaaS)-Produkt), die ihr von der Stange kaufen k√∂nntet?\nBeispielsweise ist das Extrahieren der relevanten Informationen aus gescannten Rechnungen zur Automatisierung von Buchhaltungsprozessen eine relativ komplexe Aufgabe, f√ºr die es bereits viele gute L√∂sungen gibt. Wenn du nicht gerade in einem Unternehmen arbeitest, das Buchhaltungssoftware entwickelt, und ihr plant, eine bessere Alternative zu diesen vorhandenen L√∂sungen zu verkaufen, ist es wahrscheinlich nicht sinnvoll, dies selbst zu implementieren.\nBesitzt ihr die n√∂tige technische Expertise und Wissen im Anwendungsbereich, um die L√∂sung selbst zu implementieren?\n\nWie schwierig w√§re es, die ML-L√∂sung selbst zu implementieren? Welche Open-Source-Bibliotheken gibt es, die eine solche Aufgabe l√∂sen?\nVerf√ºgt eure Organisation √ºber das n√∂tige ML-Talent? Falls nicht k√∂nnte auch eine hybride Entwicklung zusammen mit einer Universit√§t oder Forschungsinstitution oder externen Beratern m√∂glich sein.\n\nWas w√§re der Return on Investment (ROI) einer eingekauften L√∂sung?\n\nWie zuverl√§ssig ist die eingekaufte ML-L√∂sung? Gibt es Benchmarks und/oder k√∂nnt ihr sie mit einigen g√§ngigen Beispielen und Randf√§llen selbst testen?\nWie aufw√§ndig w√§re die Vorverarbeitung eurer Daten um die eingekaufte ML-L√∂sung zu verwenden?\nWie kompliziert w√§re es, die Outputs der eingekauften ML-L√∂sung in euer System zu integrieren? Macht diese L√∂sung genau das, was ihr braucht, oder w√§ren zus√§tzliche Nachbearbeitungsschritte erforderlich?\nKann die eingekaufte ML-L√∂sung intern deployed werden oder l√§uft sie auf einem externen Server und w√ºrde dies Datenschutzprobleme mit sich bringen?\nWie hoch sind die laufenden Lizenzgeb√ºhren und was ist in der Wartung enthalten (z.B. wie oft werden die Modelle nachtrainiert)?\n\n\nSofern die ML-L√∂sung kein integraler Bestandteil eures Gesch√§ftsmodells sein wird, wird es am Ende wahrscheinlich darauf hinauslaufen, die internen Kosten f√ºr die Entwicklung, Implementierung, den Betrieb und die Wartung des Systems mit den Kosten f√ºr die Integration der Standardl√∂sung in euren bestehenden Arbeitsablauf (einschlie√ülich der erforderlichen Datenvorverarbeitung) und den laufenden Lizenzgeb√ºhren zu vergleichen.\nAuch wenn ihr euch daf√ºr entscheidet, eine eigene ML-L√∂sung zu bauen, f√§ngt man dabei selten komplett bei null an ‚Äì in der Regel nutzt man generische Bausteine wie Open-Source-Bibliotheken oder vortrainierte Modelle.\n\n\n\nDie Entscheidung ‚ÄúBuild or Buy‚Äù liegt oft auf einem Kontinuum: Man kann ein fertiges Tool kaufen, das direkt funktioniert; die gekaufte Software l√§sst sich eventuell noch verbessern, wenn man sie mit eigenen Daten finetuned; oder man entwickelt eine eigene L√∂sung ‚Äì meist basierend auf bestehenden Komponenten wie Cloud-Infrastruktur, Open-Source-Bibliotheken oder vortrainierten Modellen.\n\n\nIn dem Zusammenhang solltet ihr euch auch √ºberlegen, welche Teile eures ML-Produkts f√ºr Wettbewerber am schwersten zu kopieren sind: Meistens ist das die firmeneigene Datenbasis, auf der eure Modelle trainiert wurden. Zwar lassen sich viele Datens√§tze auch aus dem Netz ziehen (was gerade bei urheberrechtlich gesch√ºtzten Inhalten rechtlich sehr umstritten ist), aber mit euren eigenen Daten hebt ihr euch wirklich ab ‚Äì weil sie den speziellen Kontext eures Unternehmens widerspiegeln, nicht einfach kopierbar sind und oft auch zu besseren Modellen f√ºhren.\n\nEine kompakte Zusammenfassung dieser Punkte findest du auch im Data Product Canvas und ML Project Assessment.\nF√ºr weitere Informationen lies diesen Blog Artikel.\n\n\n2. Entwickle eine L√∂sung\nSobald ein geeignetes ‚ÄúInput ‚Üí Output‚Äù-Problem identifiziert wurde, m√ºssen historische Daten gesammelt und der richtige ML-Algorithmus ausgew√§hlt und angewendet werden, um eine funktionierende L√∂sung zu erhalten. Darum geht es in den n√§chsten Kapiteln.\nUm ein konkretes Problem mit ML zu l√∂sen, gehen wir in der Regel wie folgt vor:\n\n\n\nWir beginnen immer mit einer Fragestellung oder einem Problem, das mit ML gel√∂st werden soll. Und um es zu l√∂sen, ben√∂tigen wir Daten, die in der Regel bereinigt werden m√ºssen, bevor man mit ihnen arbeiten kann (z.B. verschiedene Excel-Dateien zusammenf√ºhren, fehlende Werte korrigieren usw.). Dann ist es Zeit f√ºr eine explorative Analyse, um besser zu verstehen, womit wir es zu tun haben. Abh√§ngig von der Art der Daten ist es evtl. erforderlich, geeignete ‚ÄúFeatures‚Äù (Charakteristiken oder Kennzahlen) zu extrahieren oder zus√§tzlich zu berechnen, wobei Dom√§nenwissen sehr hilfreich ist. Alle diese Schritte sind unter ‚ÄúPreprocessing‚Äù (Vorverarbeitung) gruppiert (roter Kasten) und die Arbeitsschritte sind nicht linear angeordnet, da wir oft zwischen diesen Schritten hin- und herspringen. Beispielsweise stellen wir bei der Visualisierung des Datensatzes fest, dass es Ausrei√üer in den Daten gibt, die wir entfernen m√ºssen, oder nachdem neue Features berechnet wurden, gehen wir zur√ºck und visualisieren den Datensatz erneut. Als n√§chstes kommt der ML-Teil (gr√ºner Kasten): Normalerweise f√§ngt man mit einem einfachen Modell an, evaluiert es, probiert ein komplexeres Modell aus, experimentiert mit verschiedenen Hyperparametern, ‚Ä¶ und stellt dann fest, dass man den ML-Werkzeugkasten durch hat, aber kein Modell eine zufriedenstellende Performance zeigt. An diesem Punkt muss man einen Schritt zur√ºck gehen und entweder aussagekr√§ftigere Features berechnen oder, wenn das auch nicht hilft, mehr und/oder bessere Daten sammeln (z.B. mehr Proben, Daten von zus√§tzlichen Sensoren, eindeutigere Labels usw.). Wenn wir uns schlie√ülich auf die Vorhersagen des Modells verlassen k√∂nnen, gibt es zwei Wege, die man gehen kann: Entweder die Data Science Route, bei der die gewonnen Erkenntnisse an Stakeholder √ºbermittelt werden (was oft zu weiteren Fragen f√ºhrt). Oder die ML-Software Route, in welcher das endg√ºltige Modell in den Prozess eingebunden wird. Aber Achtung: Die Performance des Modells muss kontinuierlich √ºberwacht werden und es m√ºssen auch in Zukunft weiterhin neue Daten gesammelt werden, damit das Modell immer wieder nachtrainiert werden kann, vor allem falls es √Ñnderungen im Prozess gibt. Insgesamt ist die Arbeit an einem Machine Learning Projekt ein sehr iterativer Prozess.\n\n\nDa viele Unternehmen keine standardisierte Dateninfrastruktur besitzen, ist die traurige Wahrheit leider, dass eine Data Scientistin normalerweise (mindestens) etwa 90% ihrer Zeit damit verbringt, die Daten zu sammeln, zu bereinigen und anderweitig vorzuverarbeiten, um sie in ein Format zu bringen worauf die ML-Algorithmen angewendet werden k√∂nnen:\n\n\n\n\n\nAuch wenn es manchmal frustrierend ist, ist die Zeit, die man mit der Bereinigung und Vorverarbeitung der Daten verbringt, nie verschwendet, da die ML-Algorithmen nur mit einer soliden Datengrundlage brauchbare Ergebnisse erzielen k√∂nnen.\n\n\n3. Setze die L√∂sung ein\nWenn die prototypische L√∂sung implementiert ist und das geforderte Performance-Level erf√ºllt, muss diese L√∂sung dann ‚Äúdeployed‚Äù werden, d.h. produktiv in den allgemeinen Workflow und die Infrastruktur integriert werden, damit sie in der Praxis tats√§chlich zur Verbesserung des jeweiligen Prozesses eingesetzt werden kann (als Software, die kontinuierlich Vorhersagen f√ºr neue Datenpunkte macht). Das k√∂nnte auch den Bau zus√§tzlicher Software rund um das ML-Modell erfordern, wie etwa eine API, um das Modell programmatisch abzufragen, oder eine dedizierte Benutzeroberfl√§che, um mit dem System zu interagieren. Schlie√ülich gibt es im Allgemeinen zwei Strategien, wie die fertige L√∂sung betrieben werden kann:\n\nDas ML-Modell l√§uft auf einem ‚ÄúEdge-Ger√§t‚Äù, d.h. auf jedem einzelnen Ger√§t (z.B. Smartphone), das Inputdaten erzeugt und die Ergebnisse des Modells im nachfolgenden Prozessschritt verwendet. Dies ist oft die beste Strategie, wenn Ergebnisse in Echtzeit berechnet werden m√ºssen und/oder eine durchgehende Internetverbindung nicht gew√§hrleistet ist, wie z.B. bei selbstfahrenden Autos. Der Nachteil dieser Strategie ist jedoch, dass je nach Art des ML-Modells vergleichsweise teure Rechenressourcen in jedes Ger√§t eingebaut werden m√ºssen, z.B. GPUs f√ºr neuronale Netze.\nDas ML-Modell l√§uft in der ‚ÄúCloud‚Äù, d.h. auf einem zentralen Server, z.B. in Form einer Webanwendung, die Daten einzelner Nutzer entgegennimmt, verarbeitet und die Ergebnisse zur√ºcksendet. Dies ist oft die effizientere L√∂sung, wenn f√ºr den Anwendungsfall eine Antwort innerhalb weniger Sekunden ausreicht. Die Verarbeitung personenbezogener Daten in der ‚ÄúCloud‚Äù kann jedoch Datenschutzbedenken mit sich bringen. Einer der Hauptvorteile dieser L√∂sung besteht darin, dass man das ML-Modell einfacher aktualisieren kann, sobald mehr historische Daten verf√ºgbar werden oder wenn sich der Prozess √§ndert und das Modell nun mit leicht anderen Eingaben umgehen muss (worauf wir in sp√§teren Kapiteln noch ausf√ºhrlicher eingehen).\n\nEin Modell einmalig zu deployen reicht jedoch nicht aus. Man braucht auch kontinuierliches Monitoring sowohl der Input Daten (z.B. Vollst√§ndigkeit, Korrektheit, Ausrei√üer, Drift) als auch der Vorhersagen und Performance des Modells auf neuen Samples, um Probleme fr√ºhzeitig zu erkennen, bevor sie Nutzer beeintr√§chtigen. Modelle m√ºssen au√üerdem regelm√§√üig mit frischen Daten neu trainiert werden, was wiederum eine solide Dateninfrastruktur erfordert, um kontinuierlich neue Daten und Labels zu sammeln. Dies wird deutlich einfacher mit ausgereiften DevOps-Praktiken, wie CI/CD-Pipelines und automatisierten Deployments, sowie Mechanismen f√ºr schrittweise Rollouts neuer Modellversionen ‚Äì beispielsweise Canary Deployments oder A/B-Tests, um zu verifizieren, dass ein neues Modell die Performance tats√§chlich verbessert.\nWenn du neugierig geworden bist, lies das Buch Designing Machine Learning Systems, um mehr √ºber diese Themen zu lernen.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Grundlagen</span>"
    ]
  },
  {
    "objectID": "02_data.html",
    "href": "02_data.html",
    "title": "Datenanalyse & Preprocessing",
    "section": "",
    "text": "Datenanalyse\nWie wir gesehen haben, l√∂sen ML-Algorithmen Input-Output-Aufgaben. Und um ein ML-Problem zu l√∂sen, m√ºssen wir zun√§chst Daten sammeln, diese verstehen und dann so transformieren, dass ML-Algorithmen angewendet werden k√∂nnen (= Daten Vorverarbeitung / ‚ÄúPreprocessing‚Äù):\nDas Analysieren von Daten ist nicht nur ein wichtiger Schritt, bevor diese Daten f√ºr ein Machine Learning Projekt verwendet werden, sondern kann auch wertvolle Erkenntnisse generieren, die zu besseren (datengest√ºtzten) Entscheidungen f√ºhren. Normalerweise analysieren wir Daten aus einem von zwei Gr√ºnden:\nWas alle Arten der Datenanalyse gemein haben, ist, dass wir nach ‚Äú(umsetzbaren) Erkenntnissen‚Äù suchen.\nIm besten Fall werden wichtige Kennzahlen kontinuierlich in Dashboards oder Berichten √ºberwacht, um Abweichungen von der Norm so schnell wie m√∂glich zu erkennen, w√§hrend die Identifizierung der Ursache oft eine ma√ügeschneiderte Analyse erfordert.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Datenanalyse & Preprocessing</span>"
    ]
  },
  {
    "objectID": "02_data.html#sec-data-analysis",
    "href": "02_data.html#sec-data-analysis",
    "title": "Datenanalyse & Preprocessing",
    "section": "",
    "text": "Wir ben√∂tigen bestimmte Informationen, um eine (bessere) Entscheidung zu treffen (reaktive Analyse, zum Beispiel wenn etwas schief gelaufen ist und wir nicht wissen, warum).\nWir sind neugierig auf die Daten und wissen noch nicht, was die Analyse bringen wird (proaktive Analyse, zum Beispiel um die Daten zu Beginn eines ML-Projekts besser zu verstehen).\n\n\nErgebnisse einer Datenanalyse k√∂nnen auf verschiedene Arten generiert und kommuniziert werden\n\nEine ma√ügeschneiderte Analyse, deren Ergebnissen zum Beispiel in einer PowerPoint-Pr√§sentation pr√§sentiert werden\nEin standardisierter Bericht, zum Beispiel in Form eines PDF-Dokuments, der statische Visualisierungen historischer Daten zeigt\nEin Dashboard, also eine Webanwendung, die (fast) Echtzeitdaten zeigt, normalerweise mit interaktiven Elementen (z.B. Optionen zum Filtern der Daten)\n\n\n\n\n\n\nW√§hrend die Datenstory in einer Pr√§sentation in der Regel vorgegeben ist, haben Nutzer in einem interaktiven Dashboard mehr M√∂glichkeiten, die Daten zu interpretieren und selbst zu analysieren.\n\n\n\nWas ist sind Erkenntnisse?\nDer Psychologe Gary Klein definiert eine Erkenntnis als ‚Äúeine unerwartete Ver√§nderung in der Art, wie wir Dinge verstehen‚Äù.\n\n\n\nSpannend wird es, wenn wir in den Daten etwas unerwartetes finden. [Adaptiert von: Effective Data Storytelling von Brent Dykes]\n\n\nZu einer Erkenntnis kommen wir somit in zwei Schritten:\n\nEtwas Unerwartetes entdecken, zum Beispiel einen pl√∂tzlichen R√ºckgang oder Anstieg in einer Metrik.\nVerstehen, warum dies passiert ist, also tiefer in die Daten eintauchen, um die Ursache (Root Cause) zu identifizieren.\n\nWenn wir verstehen, warum etwas passiert ist, k√∂nnen wir oft auch eine potenzielle Ma√ünahme identifizieren, die uns wieder auf Kurs bringen k√∂nnte, wodurch dies zu einer umsetzbaren Erkenntnis (actionable insight) wird.\n\n\n\n\n\n\nTippZiehe einen Fachexperten zu Rate\n\n\n\nDom√§nenwissen ist oft hilfreich, um zu wissen, welche Werte unerwartet sind und wo es sich lohnen k√∂nnte, tiefer in die Daten einzusteigen. Daher kann es sinnvoll sein, die Ergebnisse zusammen mit einem Fachexperten durchzugehen.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTippFrage ‚ÄòWarum?‚Äô, um den wahren Grund hinter Analyseanfragen zu erkennen\n\n\n\nAls Datenanalyst wird man manchmal mit spezifischeren Fragen konfrontiert, wie zum Beispiel ‚ÄúWir √ºberlegen, wo wir eine neue Marketingkampagne starten sollen. Kannst du mir die Anzahl der Nutzer f√ºr alle europ√§ischen L√§nder zeigen?‚Äù. In solchen F√§llen kann es hilfreich sein, nach dem Warum zu fragen, um zu verstehen, wo die Person etwas Unerwartetes bemerkt hat, das diese Analyseanfrage ausgel√∂st hat. Wenn die Antwort lautet ‚ÄúOh, wir haben noch etwas Marketingbudget √ºbrig und m√ºssen das Geld irgendwo ausgeben‚Äù, dann gib ihnen einfach die Ergebnisse. Wenn die Antwort jedoch lautet ‚ÄúUnser Umsatz f√ºr dieses Quartal war niedriger als erwartet‚Äù, k√∂nnte es sich lohnen, andere m√∂gliche Ursachen zu untersuchen, denn vielleicht liegt das Problem nicht in der Anzahl der Nutzer, die die Website besuchen, sondern darin, dass viele Nutzer vor Erreichen der Checkout-Seite aussteigen. Das Geld k√∂nnte m√∂glicherweise besser in eine Usability-Studie investiert werden, um zu verstehen, warum Nutzer den Verkaufsprozess nicht abschlie√üen.\n\n\n\nDatengest√ºtzte Entscheidungen\nSo spannend es auch sein kann, etwas √ºber die Daten und ihren Kontext zu lernen ‚Äì wir generieren damit noch keinen Wert. Erkenntnisse werden erst wertvoll, wenn sie eine Entscheidung beeinflussen und dazu f√ºhren, dass jemand anders handelt, als er oder sie es ohne die Analyse getan h√§tte.\n\n\n\n\n\nDazu m√ºssen wir zun√§chst klarstellen, welche Entscheidung unsere Erkenntnisse beeinflussen sollen.\n\n\n\n\n\n\nHinweisSei transparent dar√ºber, welche Entscheidungen Daten beeinflussen k√∂nnen\n\n\n\nNicht alle Entscheidungen m√ºssen datengest√ºtzt getroffen werden. Entscheidungstr√§ger sollten aber ehrlich sein, ob eine Entscheidung von den Ergebnissen der Analyse beeinflusst werden kann und welche Daten sie dazu bringen w√ºrden, ihre Meinung zu √§ndern und einen anderen Handlungsweg zu w√§hlen. Wenn Daten nur angefordert werden, um eine Entscheidung zu untermauern, die in Wirklichkeit bereits getroffen wurde, erspare den Analysten den Aufwand!\n\n\nBevor wir mit einer Datenanalyse beginnen m√ºssen wir uns im Klaren dar√ºber sein:\n\nWer sind die relevanten Stakeholder, also wer wird die Ergebnisse unserer Analyse sehen (= die Zielgruppe / Dashboardnutzer)?\nWas ist ihr Ziel? \n\nIm gesch√§ftlichen Kontext h√§ngen die Ziele der Nutzer in der Regel irgendwie mit der Gewinnerzielung f√ºr das Unternehmen zusammen, zum Beispiel durch Umsatzsteigerung (z.B. durch effektivere L√∂sung von Kundenproblemen im Vergleich zur Konkurrenz) oder Kostenreduzierung.\nUm das Erreichen dieser Ziele zu tracken verwenden wir sogenannte Key Performance Indicators (KPIs), d.h. benutzerdefinierte Metriken, die uns anzeigen, wie gut die Dinge laufen. Wenn wir beispielsweise an einer Webanwendung arbeiten, k√∂nnte ein interessanter KPI die ‚ÄúNutzerzufriedenheit‚Äù sein. Leider kann man die tats√§chliche Nutzerzufriedenheit nur schwer messen, aber wir k√∂nnen stattdessen die Anzahl der wiederkehrenden Nutzer und wie lange sie auf unserer Seite bleiben tracken, und diese und andere Messungen dann geschickt zu einer Proxy-Variablen kombinieren, die wir dann ‚ÄúNutzerzufriedenheit‚Äù nennen.\n\n\n\n\n\n\nVorsichtAchte auf das Goodhart-Gesetz\n\n\n\nEin KPI ist nur dann eine zuverl√§ssige Metrik, wenn er nicht gleichzeitig dazu verwendet wird, das Verhalten von Personen zu steuern, da diese sonst versuchen, das System auszutricksen (Goodharts Gesetz). Wenn unser Ziel beispielsweise eine qualitativ hochwertige Software ist, ist die Anzahl von Bugs in unserer Software kein zuverl√§ssiges Qualit√§tsma√ü, wenn wir gleichzeitig Programmierer f√ºr jeden gefundenen und behobenen Bug belohnen.\n\n\n\nLagging vs.¬†Leading KPIs\nLeider k√∂nnen die Dinge, die uns wirklich interessieren, oft nur nachtr√§glich gemessen werden, also wenn es schon zu sp√§t ist, um korrigierend einzugreifen. Zum Beispiel interessieren uns im Vertrieb die ‚Äúrealisierten Ums√§tze‚Äù, also das auf der Bank eingegangene Geld. Aber wenn die Einnahmen am Ende des Quartals geringer sind als erhofft, k√∂nnen wir nur versuchen, im n√§chsten Quartal besser zu sein. Diese Kennzahlen nennt man lagging (nachlaufende) KPIs.\nLeading (f√ºhrende) KPIs hingegen sagen uns, wann wir handeln sollten, bevor es zu sp√§t ist. Im Vertrieb k√∂nnte das zum Beispiel das Volumen der Deals in der Vertriebspipeline sein. Auch wenn nicht alle diese Deals letztendlich zu realisierten Ums√§tzen f√ºhren, wissen wir sicher, dass wir unsere Umsatzziele nicht erreichen werden, wenn die Pipeline leer ist.\nWenn die Ursache-Wirkung-Beziehungen zwischen Variablen zu komplex sind, um direkt leading KPIs zu identifizieren, k√∂nnen wir stattdessen versuchen, lagging KPIs mit einem Machine Learning Modell vorherzusagen. Zum Beispiel k√∂nnte in einem Produktionsprozess f√ºr Kunststoff ein wichtiges Qualit√§tsma√ü die Zugfestigkeit sein, die 24 Stunden nach dem Aush√§rten gemessen wird. Falls wir nach 24 Stunden feststellen, dass die Qualit√§t nicht ausreichend ist, kann es sein, dass wir die komplette Produktion verwerfen m√ºssen. Wenn die Beziehungen zwischen den Prozessparametern (wie Produktionstemperatur) und der resultierenden Qualit√§t zu komplex sind, um ein leading KPI zu identifizieren, k√∂nnten wir stattdessen ein ML-Modell mit vergangenen Prozessparametern (Inputs) und dazugeh√∂rigen Qualit√§tsmessungen (Outputs) trainieren, um dann kontinuierlich die Qualit√§t w√§hrend der Produktion vorherzusagen. Wenn das Modell vorhersagt, dass die Qualit√§t nicht im Zielbereich liegt, k√∂nnen die Bediener sofort eingreifen und das Problem beheben, bevor weitere Produktionszeit verschwendet wird.\nDamit wir uns auf die Vorhersagen verlassen k√∂nnen, m√ºssen wir nun allerdings zus√§tzlich die Performance des Modells √ºberwachen. Die Vorhersagegenauigkeit auf neuen Daten dient hier als lagging KPI, da wir erst 24h sp√§ter, also nachdem die echten Messungen eingetroffen sind, wissen, ob die Vorhersagen korrekt waren. Als leading KPI k√∂nnen wir die Diskrepanz zwischen den f√ºr das Modelltraining verwendeten Prozessparameterwerten und den in der Produktion gemessenen Werten berechnen, um Datendrifts zu identifizieren. Solche Drifts, wie z.B. √Ñnderungen in den Werten aufgrund von Sensorst√∂rungen, k√∂nnen zu falschen Vorhersagen f√ºr betroffenen Proben f√ºhren.\n\nDer erste Schritt bei einer datengest√ºtzen Entscheidung ist zu erkennen, dass wir handeln sollten, indem wir unsere KPIs √ºberwachen, um festzustellen, ob wir dabei sind, unsere Ziele zu verfehlen.\nIdealerweise werden diese Metriken mit Schwellwerten f√ºr Warnungen kombiniert, um uns automatisch zu benachrichtigen, wenn etwas schief geht und eine Korrekturma√ünahme erforderlich ist. Beispielsweise k√∂nnten wir eine Warnung zum Zustand eines Systems oder einer Maschine einrichten, um einen Techniker zu benachrichtigen, wenn eine Wartung erforderlich ist. Um Alarmm√ºdigkeit zu vermeiden, ist es wichtig, falsche Alarme zu reduzieren, also die Warnung so zu konfigurieren, dass die verantwortliche Person sagt: ‚ÄúWenn dieser Schwellwert erreicht ist, lasse ich alles stehen und liegen und behebe das Problem‚Äù (nicht ‚Äúan diesem Punkt sollten wir es wahrscheinlich im Auge behalten‚Äù).\nJe nachdem, wie h√§ufig sich der Wert des KPI √§ndert und wie schnell Korrekturma√ünahmen Wirkung zeigen, m√∂chten wir die Alarmbedingung entweder alle paar Minuten √ºberpr√ºfen, um jemanden in Echtzeit zu benachrichtigen, oder zum Beispiel jeden Morgen, jeden Montag oder einmal im Monat, wenn sich die Werte langsamer √§ndern.\n\nIst das signifikant?\nKleine Schwankungen in den KPIs sind normal, und wir sollten nicht √ºberreagieren, wenn es sich um zuf√§lliges Rauschen handelt. Statistik kann uns sagen, ob die beobachtete Abweichung von dem, was wir erwartet haben, signifikant ist.\nStatistische Inferenz erm√∂glicht es uns Schlussfolgerungen zu ziehen, die √ºber die vorliegenden Daten hinausgehen. Oft m√∂chten wir eine Aussage √ºber eine ganze Population treffen (z.B. alle Menschen, die derzeit auf dieser Erde leben), aber wir haben nur Zugriff auf einige (hoffentlich repr√§sentative) Beobachtungen, aus denen wir unsere Schlussfolgerung ziehen k√∂nnen. Bei der statistischen Inferenz geht es darum, unsere Meinung trotz dieser Unsicherheit zu √§ndern: Wir nehmen eine Nullhypothese (= unsere Erwartung bevor wir in die Daten geschaut haben) an und pr√ºfen dann, ob das, was wir in unserer Stichprobe beobachten, diese Nullhypothese l√§cherlich erscheinen l√§sst. Ist dies der Fall, verwerfen wir sie und nehmen stattdessen die alternative Hypothese an.\nBeispiel: Euer Unternehmen hat einen Online-Shop und m√∂chte ein neues Empfehlungssystem einf√ºhren, aber ihr seid euch nicht sicher, ob Kunden diese Empfehlungen hilfreich finden und mehr kaufen werden. Bevor ihr mit dem neuen System live geht, f√ºhrt ihr daher einen A/B-Test durch, bei dem ein Prozentsatz zuf√§llig ausgew√§hlter Nutzer die neuen Empfehlungen sieht, w√§hrend die anderen zur urspr√ºnglichen Version des Online-Shops weitergeleitet werden. Die Nullhypothese lautet, dass die neue Version nicht besser ist als das Original. Aber es stellt sich heraus, dass das durchschnittliche Verkaufsvolumen der Kunden, die die neuen Empfehlungen sehen, viel h√∂her ist als das der Kunden, die die urspr√ºngliche Website besuchen. Dieser Unterschied ist so gro√ü, dass es in einer Welt, in der die Nullhypothese wahr w√§re, √§u√üerst unwahrscheinlich w√§re, dass eine zuf√§llige Stichprobe uns diese Ergebnisse liefern w√ºrde. Wir verwerfen daher die Nullhypothese und gehen von der Alternativhypothese aus, dass die neuen Empfehlungen h√∂here Ums√§tze generieren.\nNeben strengen statistischen Tests gibt es auch einige Faustregeln, um zu bestimmen, ob Ver√§nderungen in den Daten unsere Aufmerksamkeit erfordern: Wenn eine einzelne Stichprobe drei Standardabweichungen (\\(\\sigma\\)) √ºber oder unter dem Mittelwert liegt oder sieben aufeinanderfolgende Punkte √ºber oder unter dem Durchschnittswert liegen, ist dies ein Grund f√ºr weitere Untersuchungen.\n\n\n\nEin Kontrollchart zeigt Messungen √ºber die Zeit, die um ihren Mittelwert schwanken, wobei interessante Punkte in Rot markiert sind.\n\n\n\nLies diesen Artikel wenn du mehr √ºber den Unterschied zwischen Analysten und Statistikern erfahren m√∂chtest und warum diese immer mit unterschiedlichen Teilen eines Datensatzes arbeiten sollten.\n\n\n\nF√ºr jede eingerichtete Alarmbedingung, also immer wenn klar ist, dass eine Korrekturma√ünahme erforderlich ist, sollten wir uns √ºberlegen, ob diese Ma√ünahme automatisiert werden kann und die automatisierte Aktion direkt zusammen mit dem Alarm ausl√∂sen (zum Beispiel wenn die Genauigkeit eines ML-Modells unter einen bestimmten Schwellwert f√§llt, k√∂nnten wir das Modell automatisch mit den neusten Daten nachtrainieren anstatt nur den Data Scientist zu benachrichtigen). Wenn dies nicht m√∂glich ist, zum Beispiel, weil nicht klar ist, was genau passiert ist und welche Ma√ünahme ergriffen werden sollte, ben√∂tigen wir eine tiefere Analyse.\nEin tieferes Eintauchen in die Daten kann uns helfen, Fragen wie ‚ÄúWarum haben wir dieses Ziel nicht erreicht und was k√∂nnen wir besser machen?‚Äù (oder, in selteneren F√§llen, ‚ÄúWarum haben wir dieses Ziel √ºbertroffen und wie k√∂nnen wir das wiederholen?‚Äù) zu beantworten, um zu entscheiden welche Korrekturma√ünahme ergriffen werden soll.\n\n\n\n\n\n\nVorsichtStelle Hypothesen aktiv infrage, um Best√§tigungsfehler zu vermeiden\n\n\n\nDurchsuche die Daten nicht nur nach Erkenntnissen, die das best√§tigen, was du dir schon vorher gedacht hast (Best√§tigungsfehler / Confirmation Bias)! Sei stattdessen offen und versuche aktiv, deine Hypothese zu widerlegen.\n\n\nSolch eine explorative Analyse ist oft ein ‚Äòquick and dirty‚Äô Prozess, bei dem wir viele Diagramme erstellen, um die Daten besser zu verstehen und um zu erkennen, woher der Unterschied zwischen dem, was wir erwartet haben, und dem, was wir in den Daten sehen, kommt, z.B. indem wir andere korrelierte Variablen untersuchen. Zufriedenstellende Antworten zu finden ist allerdings oft mehr Kunst als Wissenschaft.\n\n\n\n\n\n\nTippNutze die ML-Merkmalswichtigkeit zur Analysef√ºhrung\n\n\n\nWenn wir ein ML-Modell verwenden, um KPIs vorherzusagen, k√∂nnen wir dieses Modell und seine Vorhersagen interpretieren, um besser zu verstehen, welche Variablen die KPIs beeinflussen k√∂nnten. In dem wir zuerst die vom ML-Modell als wichtig erachteten Features untersuchen, k√∂nnen wir Zeit sparen, wenn unser Datensatz Hunderte von Variablen enth√§lt. Aber Achtung ‚Äì das Modell hat nur aus Korrelationen in den Daten gelernt; diese repr√§sentieren nicht unbedingt wahre kausale Zusammenh√§nge zwischen den Variablen.\n\n\n\n\nErkenntnisse kommunizieren\nDie Diagramme, die wir w√§hrend der explorativen Analyse erstellt haben, sollten nicht die Diagramme sein, die wir unserem Publikum zeigen, um unsere Erkenntnisse zu kommunizieren. Da unsere Zielgruppe mit den Daten viel weniger vertraut ist als wir und wahrscheinlich auch kein Interesse / keine Zeit hat, tiefer in die Daten einzutauchen, m√ºssen wir ihnen die Ergebnisse leichter zug√§nglich machen ‚Äì ein Prozess, der oft als erkl√§rende Analyse bezeichnet wird.\n\n\n\n\n\n\nWarnungGestalte Dashboards basierend auf den Zielen und Fragen deiner Zielgruppe\n\n\n\n‚ÄúEinfach alle Daten zeigen‚Äù und hoffen, dass das Publikum schon irgendwas daraus machen wird, ist oft der Anfang vom Ende vieler Dashboards. Es ist wichtig, dass du verstehst, welches Ziel dein Publikum erreichen m√∂chte und welche Fragen daf√ºr beantwortet werden m√ºssen.\n\n\n\nSchritt 1: W√§hle den richtigen Diagrammtyp\n\nLass dich von Visualisierungsbibliotheken inspirieren (z.B. hier oder hier), aber vermeide den Drang, ausgefallene Grafiken zu erstellen; g√§ngigen Visualisierungen machen es dem Publikum einfacher, die Informationen korrekt zu entschl√ºsseln\nVerwende keine 3D-Effekte!\nVermeide Torten- oder Donutdiagramme (Winkel sind schwer zu interpretieren)\nVerwende Liniendiagramme f√ºr Zeitreihendaten\nVerwende horizontale statt vertikaler Balkendiagramme f√ºr Zielgruppen, die von links nach rechts lesen\nBei Fl√§chen- und Balkendiagrammen sollte die y-Achse bei 0 beginnen\nBenutze evtl. ‚ÄòSmall Multiples‚Äô oder Sparklines, wenn ein einzelnes Diagramm zu vollgestopft wirkt\n\n\n\n\nLinks: Balkendiagramme (insbesondere in 3D) erschweren den Vergleich von Zahlen √ºber einen l√§ngeren Zeitraum. Rechts: Trends √ºber die Zeit lassen sich in Liniendiagrammen leichter erkennen. [Beispiel adaptiert von: Storytelling with Data von Cole Nussbaum Knaflic]\n\n\n\n\nSchritt 2: Unn√∂tiges weglassen / Daten-zu-Tinte-Verh√§ltnis maximieren\n\nRand entfernen\nGitterlinien entfernen\nDatenmarker entfernen\nAchsenbeschriftungen aufs Wesentliche reduzieren\nLinien direkt beschriften\n\n\n\n\nLass Unn√∂tiges weg! [Beispiel adaptiert von: Storytelling with Data von Cole Nussbaum Knaflic]\n\n\n\n\nSchritt 3: Aufmerksamkeit fokussieren\n\nBeginne mit grau, also schiebe erstmal alles in den Hintergrund\nVerwende pr√§attentive Attribute wie Farben strategisch um das wichtigste hervorzuheben\nVerwende Datenmarker und Labels sparsam\n\n\n\n\nBeginne mit grau und verwende pr√§attentive Attribute strategisch, um die Aufmerksamkeit des Publikums zu lenken. [Beispiel adaptiert von: Storytelling with Data von Cole Nussbaum Knaflic]\n\n\n\n\nSchritt 4: Daten zug√§nglich machen\n\nKontext hinzuf√ºgen: Welche Werte sind gut (Zielzustand), welche schlecht (Alarmschwelle)? Sollten die Daten mit einer anderen Variable vergleichen werden (z.B. gemessene Werte und Vorhersagen)?\nVerwende konsistente Farben, wenn Informationen √ºber mehrere Diagramme verteilt sind (z.B. Daten von einem Land immer in derselben Farbe darstellen)\nF√ºge erkl√§renden Text hinzu, um die wichtigsten Schlussfolgerungen und Handlungsempfehlungen herauszustellen (falls dies nicht m√∂glich ist, z.B. in Dashboards, in denen sich die Daten st√§ndig √§ndern, kann der Titel stattdessen die Frage enthalten, die das Diagramm beantworten soll, z.B. ‚ÄúFolgt unser Umsatz den Prognosen?‚Äù)\n\n\n\n\nErz√§hl eine Geschichte. [Beispiel adaptiert von: Storytelling with Data von Cole Nussbaum Knaflic]\n\n\n\nWeiterf√ºhrende Literatur\n\nShow Me the Numbers: Designing Tables and Graphs to Enlighten von Stephen Few\nBetter Data Visualizations: A Guide for Scholars, Researchers, and Wonks von Jonathan Schwabish\nEffective Data Storytelling: How to drive change with data, narrative, and visuals von Brent Dykes\nStorytelling with Data: A data visualization guide for business professionals von Cole Nussbaum Knaflic\nData Visualization: A successful design process von Andy Kirk\nVerschiedene Blogartikel von Cassie Kozyrkov",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Datenanalyse & Preprocessing</span>"
    ]
  },
  {
    "objectID": "02_data.html#sec-data-garbage",
    "href": "02_data.html#sec-data-garbage",
    "title": "Datenanalyse & Preprocessing",
    "section": "Garbage in, Garbage out!",
    "text": "Garbage in, Garbage out!\nVergiss nie: Daten sind unser Rohstoff, um mit ML etwas Wertvolles zu schaffen. Ist die Qualit√§t oder Quantit√§t der Daten nicht ausreichend, haben wir ein ‚ÄúGarbage in, Garbage out‚Äù-Szenario und egal welche Art von ausgefallenem ML-Algorithmus wir verwenden, wir werden kein zufriedenstellendes Ergebnis erreichen. Im Gegenteil, je aufw√§ndiger die Algorithmen (z.B. Deep Learning), desto mehr Daten werden ben√∂tigt.\nNachfolgend findest du eine Zusammenfassung einiger allgemeiner Risiken im Zusammenhang mit Daten, die die Anwendung von ML erschweren oder sogar unm√∂glich machen:\n\nRohdaten k√∂nnen sehr chaotisch sein:\n\nRelevante Daten sind auf mehrere Datenbanken/Excel-Tabellen verteilt, die zusammengef√ºhrt werden m√ºssen. Worst Case: Datenpunkte haben keine eindeutige ID, anhand derer sich die verschiedenen Eintr√§ge verkn√ºpfen lassen. Stattdessen muss man auf eine fehleranf√§llige Strategie zur√ºckgreifen, wie den Datenabgleich anhand von Zeitstempeln.\nManuell eingegebene Werte enthalten Fehler, z.B. falsch platzierte Dezimalkommas.\nFehlende Werte k√∂nnen nicht korrigiert werden. Worst Case: Fehlende Werte sind nicht zuf√§llig. Beispielsweise versagen Sensoren genau dann, wenn w√§hrend des Produktionsprozesses etwas schief geht. Oder im Rahmen einer Umfrage zum Einkommen verweigern reiche Personen im Vergleich zu armen oder mittelst√§ndischen Personen h√§ufiger die Antwort. Dies kann zu systematischen Verzerrungen im Datensatz f√ºhren.\nDer Datensatz besteht aus verschiedenen Datentypen (strukturiert und/oder unstrukturiert) mit unterschiedlichen Skalierungen.\nDer Prozess √§ndert sich im Laufe der Zeit, z.B. aufgrund externer Bedingungen wie dem Austausch eines Sensors oder einem anderen Wartungsereignis, was bedeutet, dass die √ºber verschiedene Zeitr√§ume gesammelten Daten nicht kompatibel sind. Worst Case: Diese externen Ver√§nderungen wurden nirgends dokumentiert und wir bemerken erst am Ende der Analyse, dass die verwendeten Daten unsere Annahmen verletzten.\n\n‚Üí Preprocessing von Daten dauert sehr lange.\n‚Üí Der resultierende Datensatz (nach der Bereinigung) ist viel kleiner als erwartet ‚Äì m√∂glicherweise zu klein, um eine sinnvolle Analyse durchzuf√ºhren.\n‚áí Bevor du mit ML anf√§ngst, √ºberlege erst, ob du die Datenerfassungspipeline und Infrastruktur verbessern kannst!\n\n\nNicht genug / nicht die richtigen Daten f√ºr ML:\n\nEin kleiner Datensatz und/oder zu wenig Variation, z.B. werden nur sehr wenige defekte Produkte produziert oder ein Prozess l√§uft die meiste Zeit im station√§ren Zustand, d.h. es gibt nur wenig oder keine Variation bei den Inputs.\n‚Üí Auswirkung verschiedener Eingangsgr√∂√üen auf die Zielvariable kann aus wenigen Beobachtungen nicht zuverl√§ssig abgesch√§tzt werden.\n‚áí F√ºhre gezielt Experimente durch, bei denen verschiedene Inputs systematisch variiert werden, um einen aussagekr√§ftigeren Datensatz zu generieren.\nDaten sind inkonsistent / unvollst√§ndig, also es gibt Datenpunkte mit gleichen Inputs aber unterschiedlichen Labels, z.B. zwei Produkte wurden unter den gleichen (gemessenen) Bedingungen produziert, eins ist in Ordnung, eins fehlerhaft.\nDies kann zwei Gr√ºnde haben:\n\nDie Labels sind sehr verrauscht, z.B. weil die menschlichen Annotatoren nicht dieselben klaren Regeln befolgten oder einige Beispiele mehrdeutig waren (z.B. ein QA-Experte sagt ein kleiner Kratzer ist noch in Ordnung, der andere sortiert das Produkt aus).\n‚áí Etablierung klarer Regeln nach welchen Kriterien Daten gelabelt werden sollen und Daten durch Neuannotation bereinigen. Dies kann einige Zeit dauern, lohnt sich aber! Siehe auch dieser tolle MLOps / data-centric AI Vortrag von Andrew Ng dar√ºber, wie ein kleiner sauberer Datensatz wertvoller sein kann als ein gro√üer verrauschter Datensatz.\nRelevante Input Features fehlen: Menschen k√∂nnen zwar relativ einfach beurteilen, ob alle relevanten Informationen in unstrukturierten Daten enthalten sind (z.B. Bilder: entweder sehen wir eine Katze oder nicht), strukturierte Daten haben dagegen oft zu viele verschiedene Variablen und komplexe Interaktionen, um sofort zu erkennen, ob alle relevanten Eingangsgr√∂√üen gemessen wurden.\n‚áí Sprich mit einem Fachexperten dar√ºber, welche zus√§tzlichen Features hilfreich sein k√∂nnten und nimm diese in den Datensatz mit auf. Worst Case: Es muss ein neuer Sensor in die Maschine eingebaut werden um diese Daten zu sammeln, d.h. alle in der Vergangenheit gesammelten Daten sind im Grunde nutzlos. ABER: Der Einsatz des richtigen Sensors kann das Problem immens vereinfachen und der Einbau lohnt sich!\n\n\n\nBei vielen Anwendungen ist unser erster Gedanke oft, die Eingabedaten mithilfe einer Kamera zu generieren, da wir Menschen haupts√§chlich auf unser visuelles System angewiesen sind, um viele Aufgaben zu l√∂sen. Auch wenn Bilderkennungsalgorithmen mittlerweile sehr ausgereift sind, kann die Verwendung eines solchen Setups anstelle eines spezialisierteren Sensors die L√∂sung komplizierter machen.\nWillst du √ºberreife Erdbeeren erkennen? Machs wie Amazon Fresh und verwende einen Nahinfrarotsensor (NIR) anstelle einer normalen Kamera. Dabei wird immer noch maschinelles Lernen verwendet um die resultierenden Daten zu analysieren, aber in den NIR-Bildern sind die vergammelten Teile der Fr√ºchte viel besser sichtbar als auf normalen Fotos.\nVersuchst du zu erkennen, ob eine T√ºr geschlossen ist? Mit einem einfachen Magneten und Detektor l√§sst sich diese Aufgabe ohne aufw√§ndige Analyse oder Trainingsdaten l√∂sen! (Du kennst bestimmt das Sprichwort: ‚ÄúWenn du einen Hammer hast, sieht alles aus wie ein Nagel‚Äù. ‚Üí Vergiss nicht, auch L√∂sungen au√üerhalb deiner ML-Toolbox in Betracht zu ziehen! ;-))\n\n‚Üí Wenn der Datensatz nicht entsprechend aufgewertet wird, wird kein ML-Modell eine gute Performance liefern!\n\n\n\n\n\n\n\nTippBeobachte die Datenerhebung, um Optimierungsm√∂glichkeiten zu erkennen\n\n\n\nBeobachte wenn m√∂glich wie die Daten erfasst werden, im Sinne von: Stehe tats√§chlich physisch da und beobachte, wie jemand die Werte in ein Programm eingibt oder wie die Maschine arbeitet, wenn die Sensoren etwas messen. Sicherlich werden dir einige Dinge auffallen, die man direkt bei der Datenerhebung optimieren k√∂nnte. Dies erspart in Zukunft viel Preprocessing Arbeit.\n\n\n\nBest Practice: Datenkatalog\nUm Datens√§tze leichter zug√§nglich zu machen, sollten diese dokumentiert werden. F√ºr strukturierte Datens√§tze sollte es f√ºr jede Variable Zusatzinformationen geben wie:\n\nName der Variable\nBeschreibung\nEinheit\nDatentyp (z.B. numerische oder kategorische Werte)\nDatum der ersten Messung (z.B. falls ein Sensor erst sp√§ter eingebaut wurde)\nNormaler/erwarteter Wertebereich (‚Üí ‚ÄúWenn die Variable unter diesem Schwellwert liegt, dann ist die Maschine ausgeschaltet und die Datenpunkte k√∂nnen ignoriert werden‚Äù)\nWie werden fehlende Werte aufgezeichnet, d.h. werden sie tats√§chlich als fehlende Werte aufgezeichnet oder stattdessen durch einen unrealistischen Wert ersetzt, was passieren kann, da einige Sensoren kein Signal f√ºr ‚ÄúNot a Number‚Äù (NaN) senden k√∂nnen oder die Datenbank es nicht zul√§sst, dass das Feld leer bleibt.\nAnmerkungen zu sonstigen Vorf√§llen oder Ereignissen, z.B. eine Fehlfunktion des Sensors w√§hrend eines bestimmten Zeitraums oder ein anderer Fehler, der zu falschen Daten gef√ºhrt hat. Diese sind sonst oft schwer zu erkennen, z.B. wenn jemand stattdessen manuell Werte eingibt oder kopiert hat, die auf den ersten Blick normal aussehen.\n\nWeitere Empfehlungen, was bei der Dokumentation von Datens√§tzen speziell f√ºr Machine Learning Anwendungen wichtig ist, findest du im Data Cards Playbook.\n\n\n\n\n\n\nHinweisDokumentiere Metadaten auf Probenebene, um Probleme zu erkennen\n\n\n\nNeben der Dokumentation von Datens√§tzen als Ganzes ist es auch sehr hilfreich, Metadaten f√ºr einzelne Proben zu speichern. Bei Bilddaten k√∂nnen dies beispielsweise der Zeitstempel der Bildaufnahme, die Geolokalisierung (oder wenn die Kamera in einer Fertigungsmaschine verbaut ist, dann die ID dieser Maschine), Informationen zu den Kameraeinstellungen etc. sein. Dies kann bei der Analyse von Modellvorhersagefehlern sehr hilfreich sein, da sich beispielsweise herausstellen kann, dass Bilder, die mit einer bestimmten Kameraeinstellung aufgenommen wurden, besonders schwer zu klassifizieren sind, was uns wiederum Hinweise liefert, wie wir den Datenerfassungsprozesses verbessern k√∂nnten.\n\n\n\n\nDaten als Asset\nMit den richtigen Prozessen (z.B. Etablierung von Rollen wie ‚ÄúData Owner‚Äù und ‚ÄúData Controller‚Äù, die f√ºr die Datenqualit√§t verantwortlich sind, und Aufbau einer konsistenten Dateninfrastruktur, inkl. eines Monitoring-Prozesses zur Validierung neuer Daten) ist es f√ºr eine Organisation m√∂glich, von ‚ÄúGarbage in, Garbage out‚Äù zu ‚ÄúDaten sind das neue √ñl‚Äù zu kommen:\n\n\n\n\n\n\n\nMit (Big) Data kommt gro√üe Verantwortung!\nEinige Daten erscheinen auf den ersten Blick manchmal nicht sehr wertvoll, k√∂nnen aber f√ºr andere (d.h. mit einem anderen Anwendungsfall) von gro√üem Nutzen sein!\n\n\n\nEin Fitness-Tracker-Startup hielt es f√ºr eine coole Idee, beliebte Joggingrouten basierend auf den von ihren Nutzern generierten Daten zu ver√∂ffentlichen. Da aber auch viele US-Soldaten den Tracker benutzten und h√§ufig um ihre Milit√§rst√ºtzpunkte joggten, hat dieses Startup dadurch versehentlich einen geheimen US-Armeest√ºtzpunkt in Afghanistan geoutet, der auf ihrer interaktiven Karte als heller Punkt in einem Gebiet auftauchte, wo sonst nur wenige andere Nutzer joggten. Auch wenn deine Daten erstmal harmlos erscheinen, denk bitte dar√ºber nach, was bei einer Ver√∂ffentlichung (auch in aggregierter, anonymisierter Form) schief gehen k√∂nnte!",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Datenanalyse & Preprocessing</span>"
    ]
  },
  {
    "objectID": "02_data.html#sec-preprocessing",
    "href": "02_data.html#sec-preprocessing",
    "title": "Datenanalyse & Preprocessing",
    "section": "Preprocessing",
    "text": "Preprocessing\nJetzt, da wir unsere Daten besser verstehen und sicher gestellt haben, dass sie (hoffentlich) von guter Qualit√§t sind, k√∂nnen wir sie f√ºr unsere Machine Learning Algorithmen aufbereiten.\n\nRohdaten k√∂nnen in vielen verschiedenen Formaten vorliegen, z.B. Sensormessungen, Pixelwerte, Text (z.B. HTML-Seite), SAP-Datenbank, ‚Ä¶\n‚Üí n Datenpunkte, gespeichert als Zeilen in einem Excel-Spreadsheet, als einzelne Dateien, usw.\n\n\n\n\n\n\nWichtigWas ist ein Datenpunkt?\n\n\n\nEs ist √§u√üerst wichtig sich dar√ºber im Klaren zu sein, was eigentlich ein Datenpunkt ist, d.h. wie die Inputs aussehen und welches Ergebnis das Modell f√ºr jede Probe/Beobachtung zur√ºckgegeben soll. Um das zu bestimmen, hilft es sich zu √ºberlegen, wie das ML-Modell sp√§ter in den Rest des Workflows integriert werden soll: Welche Daten werden im vorherigen Schritt erzeugt und k√∂nnen als Input f√ºr den ML-Teil verwendet werden, und was f√ºr einen Output braucht man f√ºr den darauffolgenden Schritt?\n\n\n\nPreprocessing\nTransformation und Anreicherung der Rohdaten vor der Anwendung von ML, zum Beispiel:\n\nFehlende oder falsch eingetragene Werte entfernen / korrigieren (z.B. falsch gesetztes Dezimalkomma)\nNull-Varianz-Features (d.h. Variablen mit immer gleichem Wert) und unsinnige Variablen (z.B. IDs) ausschlie√üen\nFeature Extraktion: Rohdaten in numerische Werte umwandeln (z.B. Text)\nFeature Engineering: Berechnen zus√§tzlicher/besserer Features aus den urspr√ºnglichen Variablen\n\n‚áí Feature Matrix \\(\\,X \\in \\mathbb{R}^{n\\times d}\\): n Datenpunkte; jeder repr√§sentiert als ein d-dimensionaler Vektor (d.h. mit d Features)\nVorhersage-Targets?\n‚Üí Label Vektor \\(\\,\\mathbf{y}\\): n-dimensionaler Vektor mit einem Target Wert (Label) pro Datenpunkt",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Datenanalyse & Preprocessing</span>"
    ]
  },
  {
    "objectID": "05_supervised_models.html",
    "href": "05_supervised_models.html",
    "title": "Deep Learning",
    "section": "",
    "text": "Neuronale Netze\n‚ÄúDeep Learning‚Äù beschreibt das Teilgebiet des maschinellen Lernens, das sich mit neuronalen Netzen besch√§ftigt.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Deep Learning</span>"
    ]
  },
  {
    "objectID": "05_supervised_models.html#neuronale-netze",
    "href": "05_supervised_models.html#neuronale-netze",
    "title": "Deep Learning",
    "section": "",
    "text": "Intuitive Erkl√§rung Neuronaler Netze\n\n[Adaptiert von: ‚ÄúAI for everyone‚Äù von Andrew Ng (coursera.org)]\n\nAngenommen, wir haben einen Online-Shop und versuchen vorherzusagen, wie viel wir von einem Produkt im n√§chsten Monat verkaufen werden. Der Preis, zu dem wir bereit sind, das Produkt anzubieten, beeinflusst offensichtlich die Nachfrage, da die Leute versuchen, ein gutes Gesch√§ft zu machen, d.h. je niedriger der Preis, desto h√∂her die Nachfrage. Es handelt sich um eine negative Korrelation, die durch ein lineares Modell beschrieben werden kann. Die Nachfrage ist jedoch nie kleiner als Null (d.h. wenn der Preis sehr hoch ist, werden die Kunden das Produkt nicht pl√∂tzlich zur√ºckgeben), also m√ºssen wir das Modell so anpassen, dass der vorhergesagte Output nie negativ ist. Dies erreichen wir durch eine Max-Funktion (in diesem Zusammenhang auch nichtlineare Aktivierungsfunktion genannt), die auf das Ergebnis des linearen Modells angewendet wird, sodass wenn das lineare Modell einen negativen Wert berechnet stattdessen 0 vorhergesagt wird.\n\n\n\nEin sehr einfaches lineares Modell mit einer Input und einer Output Variablen und einer nichtlinearen Aktivierungsfunktion (der Max-Funktion).\n\n\nDiese funktionale Beziehung kann auch als Kreis mit einem Input (Preis) und einem Output (Nachfrage) visualisiert werden, wobei die S-Kurve im Kreis anzeigt, dass auf das Ergebnis eine nichtlineare Aktivierungsfunktion angewendet wird. Wir werden dieses Symbol sp√§ter als einzelne Einheit oder ‚ÄúNeuron‚Äù eines neuronalen Netzes (NN) sehen.\nUm die Vorhersage zu verbessern, k√∂nnen wir das Modell erweitern und mehrere Input Features f√ºr die Vorhersage verwenden:\n\n\n\nEin einfaches lineares Modell mit mehreren Inputs, bei dem die Vorhersage als gewichtete Summe der Inputs berechnet wird, zusammen mit der Max-Funktion um negative Werte zu vermeiden.\n\n\nUm die Performance des Modells noch weiter zu verbessern, k√∂nnen wir aus den urspr√ºnglichen Inputs manuell informativere Features generieren, indem wir sie sinnvoll kombinieren (‚Üí Feature Engineering), bevor wir den Output berechnen:\n\n\n\nIn diesem Beispiel geht es um einen Online-Shop und die Kunden m√ºssen Versandkosten bezahlen, d.h. die tats√§chliche Erschwinglichkeit des Produkts ergibt sich aus der Summe des Produktpreises und den Versandkosten. Au√üerdem interessieren sich die Kunden f√ºr qualitativ hochwertige Produkte, doch die Produktwahrnehmung ergibt sich nicht nur aus der tats√§chlichen Rohstoffqualit√§t. Dass unser Produkt hochwertiger ist als andere wird auch durch eine entsprechende Marketingkampagne und einen hohen Preis vermittelt. Durch die Berechnung dieser zus√§tzlichen Zwischenfeatures kann der Preis somit in zweierlei Hinsicht zur endg√ºltigen Vorhersage beitragen: W√§hrend einerseits ein niedrigerer Preis f√ºr die Erschwinglichkeit des Produkts von Vorteil ist, f√ºhrt andererseits ein h√∂herer Preis zu der Wahrnehmung einer h√∂heren Qualit√§t.\n\n\nW√§hrend es in diesem Anschauungsbeispiel m√∂glich war, solche Features manuell zu konstruieren, ist das Vorteilhafte an neuronalen Netzen, dass sie genau das automatisch tun: Indem wir mehrere Zwischenschichten (Layers) verwenden, d.h. mehrere lineare Modelle (mit nichtlinearen Aktivierungsfunktionen) verbinden, werden immer komplexere Kombinationen der urspr√ºnglichen Input Features generiert, die die Performance des Modells verbessern k√∂nnen. Je mehr Layers das Netzwerk verwendet, d.h. je ‚Äútiefer‚Äù es ist, desto komplexer sind die resultierenden Feature Repr√§sentationen.\nDa verschiedene Problemstellungen und insbesondere verschiedene Arten von Input Daten von unterschiedlichen Feature Repr√§sentationen profitieren, gibt es verschiedene Arten neuronaler Netzarchitekturen, um diese aussagekr√§ftigeren Zwischenfeatures zu berechnen, z.B.\n\nFeed Forward Neural Networks (FFNNs) f√ºr ‚Äònormale‚Äô (z.B. strukturierte) Daten\nConvolutional Neural Networks (CNNs) f√ºr Bilder\nRecurrent Neural Networks (RNNs) f√ºr sequenzielle Daten wie Text oder Zeitreihen\n\n\n\nNN Architekturen\n√Ñhnlich wie dom√§nenspezifisches Feature Engineering zu erheblich verbesserten Modellvorhersagen beitragen kann, lohnt es sich gleicherma√üen, eine auf die jeweilige Aufgabe zugeschnittene neuronale Netzwerkarchitektur zu konstruieren.\n\nFeed Forward Neural Network (FFNN)\nDas FFNN ist die urspr√ºngliche und einfachste neuronale Netzwerkarchitektur, die auch im ersten Beispiel verwendet wurde. Allerdings bestehen diese Modelle in der Praxis normalerweise aus mehr Layers und Neuronen pro Layer:\n\n\n\nFeed Forward Neural Network (FFNN) Architektur: Der Input-Feature-Vektor \\(\\mathbf{x}\\), der einen Datenpunkt darstellt, wird mit der ersten Gewichtungsmatrix \\(W_1\\) multipliziert, um einen neuen Vektor zu erzeugen, der nach Anwendung der nichtlinearen Aktivierungsfunktion (z.B. der Max-Funktion wie im ersten Beispiel) zur ersten Hidden-Layer-Repr√§sentation \\(\\mathbf{x}'\\) wird. Dieser neue Vektor wird dann mit der zweiten Gewichtungsmatrix \\(W_2\\) multipliziert und wieder wird eine nichtlineare Aktivierungsfunktion angewandt, um die zweite Hidden-Layer-Repr√§sentation des Datenpunkts, \\(\\mathbf{x}''\\), zu erzeugen. Je nachdem, wie viele Schichten das Netzwerk hat (d.h. wie tief es ist), wiederholt sich dies nun mehrmals, bis schlie√ülich die letzte Schicht den vorhergesagten Output \\(\\mathbf{\\hat{y}}\\) berechnet. W√§hrend das Netzwerk trainiert wird, n√§hern sich diese vorhergesagten Outputs immer mehr den wahren Labels der Trainingsdaten an in dem die Gewichtsmatrizen entsprechend angepasst werden.\n\n\n\n\n\n\n\n\nHinweisProbier es selbst aus!\n\n\n\nDu kannst hier auch selbst mit einem kleinen neuronalen Netz herumspielen um z.B. zu schauen wie es sich verh√§lt wenn du mehr Neuronen oder Layers verwendest.\n\n\n\n\nConvolutional Neural Network (CNN)\nManuelles Feature Engineering f√ºr Computer Vision Aufgaben ist sehr schwierig. W√§hrend der Mensch m√ºhelos eine Vielzahl von Objekten in Bildern erkennt, ist es schwer zu beschreiben, warum wir erkennen was wir sehen, z.B. anhand welcher Merkmale wir eine Katze von einem kleinen Hund unterscheiden. Das Deep Learning hatte seinen ersten bahnbrechenden Erfolg auf diesem Gebiet, da neuronale Netze, insbesondere CNNs, es durch eine Hierarchie von Layern schaffen, sinnvolle Feature Repr√§sentationen aus visuellen Informationen zu lernen.\nConvolutional Neural Networks eignen sich sehr gut f√ºr die Verarbeitung visueller Informationen, da sie direkt mit 2D-Bildern arbeiten k√∂nnen und die Tatsache nutzen, dass Bilder viele lokale Informationen beinhalten (z.B. sind Augen, Nase und Mund lokalisierte Komponenten eines Gesichts).\n\n\n\nEine convolutional neuronale Netzarchitektur zur Gesichtserkennung: Die gelernten Gewichte des Netzes sind die unterhalb des Netzes angezeigten kleinen Filterpatches, die beispielsweise im ersten Schritt Kanten im Bild erkennen. Gegen Ende des Netzwerks werden die Feature Repr√§sentation zu einem Vektor zusammengefasst und als Input an ein FFNN (hier ‚ÄúFully Connected Layer‚Äù) gegeben, um die endg√ºltige Klassifizierung durchzuf√ºhren.\n\n\n\n\nAllgemeine Prinzipien & fortgeschrittene Architekturen\nBei der L√∂sung eines Problems mit einem NN muss man immer ber√ºcksichtigen, dass das Netzwerk sowohl die Input Daten verstehen als auch die gew√ºnschten Ausgaben generieren muss:\n\n\n\nWie wir oben beim CNN f√ºr Gesichtserkennung (Bildklassifizierung) gesehen haben, wird die vom CNN generierte Repr√§sentation irgendwann zusammengef√ºhrt und ein FFNN berechnet daraus die endg√ºltige Vorhersage f√ºr die Klassifikation. Genauso kann auch der letzte Hidden State eines RNN, der die in einem Satz enthaltenen Informationen repr√§sentiert, an ein FFNN √ºbergeben werden, um die finale Klassifikation zu generieren (z.B. f√ºr eine Sentimentanalyse). Einige Probleme fallen jedoch nicht in die Kategorie einfacher Supervised Learning Aufgaben (also Regression oder Klassifikation) und erfordern eine andere Art von Output. Bei der maschinellen √úbersetzung ist der Output beispielsweise ein in eine andere Sprache √ºbersetzter Satz. Dies kann durch die Kopplung zweier RNNs erreicht werden: Das erste ‚Äòversteht‚Äô den Satz in der Originalsprache und diese Repr√§sentation der Bedeutung des Satzes wird an ein zweites RNN √ºbergeben, das daraus Wort f√ºr Wort den √ºbersetzten Satz generiert. Ein weiteres Beispiel ist Image Captioning (d.h. das Generieren einer Bildbeschreibung, z.B. um das Online-Erlebnis f√ºr Menschen mit Sehbehinderung zu verbessern), wobei das Bild zuerst von einem CNN ‚Äòverstanden‚Äô wird und dann diese Repr√§sentation des Eingabebildes an ein RNN √ºbergeben wird, um den passenden Text zu erzeugen.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Deep Learning</span>"
    ]
  },
  {
    "objectID": "06_pitfalls.html",
    "href": "06_pitfalls.html",
    "title": "H√§ufige Fehler vermeiden",
    "section": "",
    "text": "[Fehler #1] Irref√ºhrende Modellevaluierung\nDas obige Zitat wird auch in diesem xkcd Comic sch√∂n veranschaulicht:\nEin Supervised Learning Modell versucht, den Zusammenhang zwischen Inputs und Outputs aus den gegebenen Datenpunkten abzuleiten. Was f√ºr ein Zusammenhang gelernt wird, wird vor allem durch den gew√§hlten Modelltyp und seinen internen Optimierungsalgorithmus bestimmt. Man kann (und sollte) jedoch einiges tun, um sicherzustellen, dass das Ergebnis nicht offensichtlich falsch ist.\nWas wollen wir?\nEin Modell, das ‚Ä¶\nIm Folgenden besprechen wir einige h√§ufige Fallstricke und wie wir sie vermeiden k√∂nnen.\nVorhersagemodelle m√ºssen evaluiert werden, d.h. ihre Performance muss mit einer geeigneten Evaluierungsmetrik quantifiziert werden. Dies ist notwendig, um realistisch abzusch√§tzen, wie n√ºtzlich ein Modell in der Praxis sein wird und mit wie vielen Vorhersagefehlern wir rechnen m√ºssen.\nDa man bei Supervised Learning Problemen die Ground Truth, also die echten Labels, kennt, kann man verschiedene Modelle objektiv bewerten und miteinander vergleichen.\nBeim Evaluieren eines Modells kann man allerdings leicht ein zu optimistisches Bild zeichnen, weshalb man die Ergebnisse immer kritisch hinterfragen und die Performance eines Modells mit der einer Baseline vergleichen sollte. Der einfachste Vergleich w√§re mit einem sehr dummen Modell, das immer den Mittelwert (‚Üí Regression) bzw. die h√§ufigste Klasse (‚Üí Klassifikation) vorhersagt.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>H√§ufige Fehler vermeiden</span>"
    ]
  },
  {
    "objectID": "06_pitfalls.html#sec-pitfall-evaluation",
    "href": "06_pitfalls.html#sec-pitfall-evaluation",
    "title": "H√§ufige Fehler vermeiden",
    "section": "",
    "text": "Ist das Modell f√ºr die Aufgabe geeignet?\nD.h. generiert das Modell zuverl√§ssige Vorhersagen f√ºr neue Datenpunkte?\n\nTeile die verf√ºgbaren Daten in einen Trainings- und einen Testteil auf, um absch√§tzen zu k√∂nnen, wie gut die Vorhersagen des Modells sein werden, wenn es sp√§ter auf neue Datenpunkte angewendet wird, auf denen es nicht trainiert wurde.\nQuantifiziere die G√ºte der Modellvorhersagen auf dem Testset mit einer geeigneten Evaluierungsmetrik (je nach Problemtyp).\n\n‚áí Sind manche Fehler schwerwiegender als andere (z.B. bei medizinischen Tests falsch positive vs.¬†falsch negative Ergebnisse)?\n‚áí Lege dich auf eine Metrik/KPI fest, anhand derer du unterschiedliche Modelle vergleichst und ausw√§hlst (evtl. unter Ber√ºcksichtigung zus√§tzlicher Einschr√§nkungen wie Laufzeit).\n\n\n\nEvaluierungsmetriken bei unausgeglichenen Klassenverteilungen\nDie Accuracy (Genauigkeit) ist ein sehr h√§ufig verwendetes Evaluierungsma√ü f√ºr Klassifikationsprobleme:\nAccuracy: Anteil der Proben, die richtig klassifiziert wurden.\nUnten sind die Entscheidungsgrenzen von zwei Modellen in einem Beispieldatensatz eingezeichnet, wobei die Farbe des Hintergrunds angibt, ob das Modell die blaue oder rote Klasse f√ºr einen Datenpunkt in diesem Bereich vorhersagt. Welches Modell h√§ltst du f√ºr sinnvoller?\n\n\n\n\n\nBei unausgeglichenen Klassenverteilungen, wie in diesem Fall mit viel mehr Datenpunkten aus der blauen im Vergleich zur roten Klasse, ist die Accuracy eines Modells, das einfach immer die h√§ufigste Klasse vorhersagt, schon sehr gro√ü. Eine Accuracy von 90% mag zwar beeindruckend klingen, wenn man den Stakeholdern des Projekts von der Performance seines Modells berichtet, bedeutet jedoch nicht automatisch, dass das Modell tats√§chlich in der Praxis n√ºtzlich ist, zumal uns bei realen Problemen oft die seltenere Klasse mehr interessiert, z.B. Menschen mit einer seltenen Krankheit oder Produkte, die einen Defekt aufweisen.\nEine aussagekr√§ftigere Evaluierungsmetrik f√ºr Klassifikationsmodelle ist die Balanced Accuracy, mit der wir zwischen einem Modell, das tats√§chlich etwas gelernt hat, und der ‚Äòdummen Baseline‚Äô unterscheiden k√∂nnen:\nBalanced Accuracy: Zuerst wird f√ºr jede Klasse einzeln der Anteil der richtig klassifizierten Stichproben berechnet und dann der Durchschnitt dieser Werte gebildet.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>H√§ufige Fehler vermeiden</span>"
    ]
  },
  {
    "objectID": "06_pitfalls.html#sec-pitfall-generalize",
    "href": "06_pitfalls.html#sec-pitfall-generalize",
    "title": "H√§ufige Fehler vermeiden",
    "section": "[Fehler #2] Modell generalisiert nicht",
    "text": "[Fehler #2] Modell generalisiert nicht\nWir wollen ein Modell, das den ‚ÄòInput ‚Üí Output‚Äô-Zusammenhang in den Daten erfasst und interpolieren kann, d.h. wir m√ºssen pr√ºfen:\nGeneriert das Modell zuverl√§ssige Vorhersagen f√ºr neue Datenpunkte aus derselben Verteilung wie die der Trainingsdaten?\nWenn ja, garantiert dies zwar noch nicht, dass das Modell tats√§chlich den echten kausalen Zusammenhang zwischen Inputs und Outputs gelernt hat und √ºber den Trainingsbereich hinaus extrapolieren kann (dazu kommen wir im n√§chsten Abschnitt). Zumindest generiert das Modell aber zuverl√§ssige Vorhersagen f√ºr neue Datenpunkte, die den Trainingsdaten √§hnlich sind. Ist dies nicht gegeben, ist das Modell nicht nur falsch, sondern auch nutzlos.\nAber warum macht ein Modell √ºberhaupt Fehler? Eine schlechte Performance auf dem Testset kann zwei Gr√ºnde haben: Overfitting oder Underfitting.\n\n\n\nWenn man bei den verschiedenen Modellen hier nur den Fehler auf den Testdaten betrachtet, k√∂nnte man schlussfolgern, dass die Modelle links (overfitting) und rechts (underfitting) gleicherma√üen falsch sind. Das stimmt zwar in gewisser Weise, aber der Testfehler allein sagt uns nicht, warum die Modelle falsch liegen oder wie wir ihre Performance verbessern k√∂nnen. Offensichtlich machen die beiden Modelle auf dem Testset aus v√∂llig unterschiedlichen Gr√ºnden Fehler: Das overfittete Modell hat die Trainingsdaten quasi auswendig gelernt und kann nicht auf neue Datenpunkte verallgemeinert werden, w√§hrend das underfittete Modell zu einfach ist, um den Zusammenhang zwischen den Inputs und Outputs √ºberhaupt abzubilden.\n\n\nDiese beiden F√§lle erfordern sehr unterschiedliche Ans√§tze, um die Modellperformance zu verbessern.\nDa die meisten Datens√§tze sehr viele Inputvariablen haben, kann man das Modell in der Regel nicht einfach wie oben aufmalen, um zu sehen, ob es over- oder underfittet. Stattdessen muss man sich den mit einer aussagekr√§ftigen Evaluierungsmetrik berechneten Fehler sowohl auf dem Trainings- als auch dem Testset anschauen um zu bestimmen, ob man es mit Overfitting oder Underfitting zu tun hat:\nOverfitting: super Trainingsperformance, inakzeptabel auf den Testdaten\nUnderfitting: schlechte Trainings- UND Testperformance\n\n\n\n\n\nJe nachdem, ob ein Modell over- oder underfittet, gibt es verschiedene M√∂glichkeiten die Performance zu verbessern. Eine perfekte Modellperformance ist jedoch unrealistisch, da manche Aufgaben einfach schwierig sind, zum Beispiel weil die Daten sehr verrauscht sind.\n\n\n\n\n\n\nTippFehleranalyse\n\n\n\nSchaue dir immer die Daten an! Gibt es ein Muster unter den falschen Vorhersagen, z.B. eine Diskrepanz zwischen der Performance f√ºr verschiedene Klassen?",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>H√§ufige Fehler vermeiden</span>"
    ]
  },
  {
    "objectID": "06_pitfalls.html#sec-pitfall-spurious",
    "href": "06_pitfalls.html#sec-pitfall-spurious",
    "title": "H√§ufige Fehler vermeiden",
    "section": "[Fehler #3] Modell missbraucht Scheinkorrelationen",
    "text": "[Fehler #3] Modell missbraucht Scheinkorrelationen\nSelbst wenn ein Modell in der Lage ist, richtige Vorhersagen f√ºr neue Datenpunkte zu generieren, die den Trainingsdaten √§hnlich sind, bedeutet dies nicht, dass das Modell tats√§chlich den wahren kausalen Zusammenhang zwischen den Inputs und Outputs gelernt hat!\n\n\n\n\n\n\nWarnungML-Modelle machen es sich oft leicht und schummeln!\n\n\n\nML-Modelle nutzen h√§ufig Scheinkorrelationen, statt die wahren kausalen Zusammenh√§nge zu lernen. Dies macht sie anf√§llig f√ºr Adverserial Attacks und Daten-Drifts, die das Modell zwingen, zu extrapolieren statt zu interpolieren.\n\n\n\nEine richtige Vorhersage wird nicht immer aus den richtigen Gr√ºnden gemacht!\nDie Grafik unten stammt aus einem Paper, in dem die Autoren festgestellt haben, dass ein vergleichsweise einfaches ML-Modell, das auf einem Standard-Bildklassifizierungsdatensatz trainiert wurde, f√ºr alle zehn Klassen im Datensatz schlecht abschnitt ‚Äì bis auf die Klasse ‚ÄòPferd‚Äô! Als sie den Datensatz genauer untersuchten und analysierten, warum das Modell eine bestimmte Klasse vorhersagt, d.h. welche Bildmerkmale in der Vorhersage verwendet wurden (angezeigt als Heatmap auf der rechten Seite), machten sie folgende Feststellung: Die meisten Bilder von Pferden im Datensatz stammten vom selben Fotografen und enthielten alle einen charakteristischen Copyright-Vermerk in der linken unteren Ecke.\n\n\n\nLapuschkin, Sebastian, et al.¬†‚ÄúAnalyzing classifiers: Fisher vectors and deep neural networks.‚Äù IEEE Conference on Computer Vision and Pattern Recognition. 2016.\n\n\nAnhand dieses Artefaktes konnte das Modell mit hoher Genauigkeit Pferdebilder in diesem Datensatz identifizieren ‚Äì und zwar sowohl im Trainings- als auch im Testset, das auch Bilder desselben Fotografen enthielt. Trotzdem hat das Modell nat√ºrlich nicht gelernt, was ein Pferd eigentlich ausmacht, und es kann nicht extrapolieren und andere Fotos von Pferden ohne diesen Copyright-Hinweis korrekt identifizieren. Andersrum k√∂nnte man nun auch ein Bild von einem anderen Tier mit einem solchen Copyright-Vermerk versehen und das Modell w√ºrde darauf dann irrt√ºmlich ein Pferd erkennen. Man kann das Modell so also absichtlich austricksen, was man auch als ‚ÄúAdverserial Attack‚Äù bezeichnet.\n\nDies ist bei weitem nicht das einzige Beispiel, bei dem ein Modell ‚Äúgeschummelt‚Äù hat, indem es Scheinkorrelationen in den Trainingsdaten ausnutzte. Ein weiteres beliebtes Beispiel: Ein Datensatz mit Bildern von Hunden und W√∂lfen, bei dem alle W√∂lfe auf verschneitem Hintergrund und die Hunde auf Gras oder anderen nicht-wei√üen Hintergr√ºnden fotografiert wurden. Modelle, die auf so einem Datensatz trainiert werden, k√∂nnen eine gute Vorhersagegenauigkeit aufweisen, ohne dass sie die wahren kausalen Zusammenhang zwischen den Features und Labels erkannt haben.\nUm solche Pannen rechtzeitig zu erkennen, ist es wichtig, das Modell zu interpretieren und seine Vorhersagen zu erkl√§ren (wie im oben genannten Paper), um zu sehen, ob das Modell zur Vorhersage die Features verwendet, die wir (oder ein Dom√§nenexperte) erwartet h√§tten.\n\n\nAdversarial Attacks: ML-Modelle absichtlich t√§uschen\nBei einem ‚Äòfeindlichen Angriff‚Äô auf ein ML-Modell werden die Inputdaten subtil ver√§ndert, sodass ein Mensch diese √Ñnderungen nicht bemerkt und immer noch zum richtigen Ergebnis kommt, aber das Modell seine Vorhersage √§ndert.\nW√§hrend zum Beispiel ein ML-Modell das ‚ÄòStop‚Äô-Schild auf dem linken Bild leicht erkennen kann, wird das Schild rechts aufgrund der strategisch platzierten, unscheinbar aussehenden Aufkleber (die ein Mensch einfach ignorieren w√ºrde) mit einem Geschwindigkeitsbegrenzungsschild verwechselt:\n\n\n\n\n\nDer Grund daf√ºr ist, dass das Modell nicht die wahren Merkmale gelernt hat, anhand derer Menschen ein Stoppschild als solches identifizieren, z.B. die achteckige Form und die vier wei√üen Buchstaben ‚ÄòSTOP‚Äô vor rotem Hintergrund. Stattdessen verl√§sst sich das Modell auf bedeutungslose Korrelationen, um das Stoppschild von anderen Schildern zu unterscheiden.\nDa ein Convolutional Neural Network (CNN), die neuronale Netzarchitektur, die typischerweise f√ºr Bildklassifizierungsaufgaben verwendet wird, sich sehr auf lokale Muster fokussiert, l√§sst es sich leicht t√§uschen. Dies geschieht, indem man die globale Form von Objekten, welche Menschen zur Identifikation verwenden, intakt l√§sst, und die Bilder mit bestimmten Texturen oder anderen Hochfrequenzmustern √ºberlagert, wodurch das Modell eine andere Klasse vorhersagt.\n\n\nGenAI & Adversarial Prompts\nWegen ihrer Komplexit√§t ist es besonders schwierig, den Output von generativen KI-Modellen (GenAI) wie ChatGPT zu kontrollieren. Diese Modelle k√∂nnen zwar in ‚ÄúHuman-in-the-Loop‚Äù Szenarien sehr n√ºtzlich sein (z.B. um eine E-Mail oder Code-Schnipsel zu schreiben, die dann nochmal von einem Menschen √ºberpr√ºft werden), doch es ist schwer, die notwendigen Sicherheitsvorkehrungen zu treffen, damit der Chatbot nicht missbraucht werden kann.\nDer ChatGPT-basierte Kundensupport-Chat eines Chevrolet-Autoh√§ndlers ist nur ein Beispiel von vielen fr√ºhen GenAI Anwendungen, die bestenfalls gemischte Ergebnisse lieferten:\n\n\n\nScreenshot: https://twitter.com/ChrisJBakke/status/1736533308849443121 (12.1.2024)\n\n\n\n\nWie man robuste Kausalmodelle, die den wahren ‚ÄòInput ‚Üí Output‚Äô-Zusammenhang in den Daten erfassen, findet, wird nach wie vor aktiv erforscht und ist weitaus schwieriger als ein Modell zu finden, das ‚Äúnur‚Äù verallgemeinert und gute Vorhersagen f√ºr die Testdaten generiert.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>H√§ufige Fehler vermeiden</span>"
    ]
  },
  {
    "objectID": "06_pitfalls.html#sec-pitfall-biased",
    "href": "06_pitfalls.html#sec-pitfall-biased",
    "title": "H√§ufige Fehler vermeiden",
    "section": "[Fehler #4] Modell diskriminiert",
    "text": "[Fehler #4] Modell diskriminiert\nEin Modell, welches echte kausale Zusammenh√§nge zwischen den Variablen aufgegriffen hat, generiert zwar robustere Vorhersagen, doch es kann auch kausale Zusammenh√§nge in den historischen Daten geben, die ein Modell besser nicht lernen sollte. Wenn in der Vergangenheit Menschen aufgrund ihres Geschlechts oder ihrer Hautfarbe diskriminiert wurden, kann sich dies auch in den Trainingsdaten widerspiegeln und wir m√ºssen zus√§tzliche Ma√ünahmen ergreifen, damit diese Muster nicht in unserem Modell weiterbestehen ‚Äì obwohl es in der Vergangenheit vielleicht echte kausale Zusammenh√§nge waren.\n\nSystematisch verzerrte Daten f√ºhren zu (stark) verzerrten Modellen\nIm Folgenden sind einige Beispiele aufgef√ºhrt, bei denen Menschen mit den besten Absichten ein ML-Modell entwickelt haben, das problematische Dinge aus realen Daten gelernt hat.\n\n\n\n\nWas als Forschungsprojekt begann, um herauszufinden, wie Menschen mit einem KI-basierten Chatbot interagieren, endete f√ºr Microsoft als PR-Albtraum. Der Chatbot ‚ÄòTay‚Äô sollte aus den an sie geschriebenen Nachrichten lernen. Aber da die Entwickler offenbar mehr √ºber ihre ML-Modelle als √ºber menschliches Verhalten im Internet nachdachten, wiederholte Tay vor allem rassistische und sexistische Aussagen, die andere ihr gegen√ºber twitterten.\n\n\n\n\n\n\n\nDa viele auf Twitter gepostete Bilder gr√∂√üer sind als der verf√ºgbare Platz f√ºr das Vorschaubild, wollte Twitter ‚Äúden relevantesten Teil‚Äù eines Bildes f√ºr die Vorschau mit einem ML-Modell ausw√§hlen. Da sie dieses Modell leider auf einem Datensatz trainierten, der mehr Bilder von Menschen mit wei√üer als dunkler Hautfarbe enthielt, wurde das Modell rassistisch und w√§hlte beispielsweise bei einem Bild von Barack Obama und einem zuf√§lligen unwichtigen wei√üen Politiker immer den wei√üen Politiker f√ºr das Vorschaubild. Des weiteren fiel auf, dass diese Zuschneide-Algorithmen h√§ufiger Gesichter als Vorschaubilder f√ºr M√§nner und den K√∂rper (insbesondere ‚Äì wer h√§tte es gedacht ‚Äì Br√ºste) als Vorschaubilder f√ºr Frauen ausw√§hlten.\n\n\n\n\n\n\n\nDie meisten Computer Vision Modelle werden auf dem ImageNet-Datensatz (vor-)trainiert, der √ºber 14 Millionen handgelabelte Bilder enth√§lt, die in mehr als 20.000 Kategorien organisiert sind. Da diese Bilder jedoch aus dem Internet stammen und mehr Menschen aus Industriel√§ndern als aus Entwicklungsl√§ndern dazu neigen, Bilder online zu stellen, sind beispielsweise g√§ngige Haushaltsgegenst√§nde aus reicheren L√§ndern stark √ºberrepr√§sentiert. Als Folge verwechseln diese Modelle z.B. Seifenst√ºcke, wie sie in einem √§rmeren Land verwendet werden, mit Lebensmitteln (z.B. k√∂nnte man argumentieren, dass diese tats√§chlich eine gewisse √Ñhnlichkeit haben mit einem Teller mit Essen in einem Sterne-Restaurant).\nde Vries, Terrance, et al.¬†‚ÄúDoes object recognition work for everyone?‚Äù IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. 2019.\n\n\n\nDie oben genannten Probleme traten alle auf, weil die Daten nicht gleichm√§√üig verteilt waren:\n\nTay hat viel mehr rassistische und hasserf√ºllte Kommentare und Tweets gesehen als neutrale oder wertsch√§tzende √Ñu√üerungen.\nDer Bilddatensatz, auf dem Twitter sein Modell trainierte, enthielt mehr Bilder von wei√üen als von nicht-wei√üen Personen.\nBei einer zuf√§lligen Stichprobe von Fotos aus dem Internet wurden diese Bilder meist von Menschen aus Industriel√§ndern hochgeladen, d.h. Bilder, die den Status Quo in Entwicklungsl√§ndern zeigen, sind unterrepr√§sentiert.\n\nNoch problematischer als eine blo√üe Unterrepr√§sentation bestimmter Untergruppen (verzerrte Eingabeverteilung) ist ein Muster der systematischen Diskriminierung dieser Untergruppen in historischen Daten (diskriminierende Verschiebung der zugewiesenen Labels).\n\n\n\n\nIn vielen Datens√§tzen, die zum Trainieren von Modellen f√ºr die Vergabe von Kreditscores oder zur Bestimmung von Zinss√§tzen f√ºr Hypotheken oder Kredite verwendet werden, ist oft eine Menge expliziter Diskriminierung kodiert. Da diese Anwendungsbereiche einen direkten und starken Einfluss auf das Leben der Menschen haben, muss man hier besonders vorsichtig sein. Beispielsweise sollte man √ºberpr√ºfen, ob ein Modell f√ºr einen Mann und eine Frau den gleichen Score vorhersagt, wenn alle Merkmale mit Ausnahme des Geschlechts bei einem Datenpunkt √ºbereinstimmen.\n\n\n\nZusammenfassend: Ein verzerrtes Modell kann sich auf zwei Arten negativ auf die Nutzer auswirken:\n\nUnverh√§ltnism√§√üige Produktausf√§lle aufgrund unterrepr√§sentierter Stichproben. Beispielsweise funktionieren Spracherkennungsmodelle f√ºr Frauen oft weniger zuverl√§ssig, weil sie mit mehr Daten von M√§nnern trainiert wurden (z.B. transkribierte politische Reden).\nSchaden durch Benachteiligung / Verweigerung von Chancen aufgrund von in historischen Daten kodierten Stereotypen. Beispielsweise m√ºssen Frauen h√∂here Kreditzinsen zahlen als M√§nner oder im Ausland geborene Personen gelten als weniger qualifiziert f√ºr eine Stelle, wenn ihre Lebensl√§ufe von einem automatisierten Screening-Tool bewertet werden.\n\n\n\n\n\n\n\nVorsichtVerst√§rkung von Vorurteilen durch fehlerhafte Nachtrainingsdaten\n\n\n\nWenn man Modelle mit Daten neu trainiert, die von Vorhersagen eines verzerrten Vorg√§ngermodells beeinflusst wurden, k√∂nnen bestehende Vorurteile noch verst√§rkt werden. Wenn beispielsweise ein Lebenslauf-Screeningtool ein h√§ufiges Merkmal (z.B. ‚Äúhat die Stanford University besucht‚Äù) bei aktuellen Mitarbeitern erkennt, k√∂nnte es konsequent Lebensl√§ufe mit diesem Merkmal empfehlen. Daraus resultiert, dass noch mehr Leute mit diesem Merkmal zu Vorstellungsgespr√§chen eingeladen und eingestellt werden, was die Dominanz dieses Merkmals in nachfolgenden Modellen, die auf diesen Mitarbeiterprofilen trainiert werden, weiter verst√§rkt.\n\n\n\n\nAuf dem Weg zu fairen Modellen\nBevor wir diese Probleme beheben k√∂nnen, m√ºssen wir uns ihrer erstmal bewusst werden. Daher ist es wichtig, die Performance eines Modells immer f√ºr jede (bekannte) Untergruppe in den Daten einzeln zu bewerten, um sicherzustellen, dass die Vorhersagefehler des Modells zuf√§llig sind und das Modell nicht f√ºr einige Untergruppen (z.B. Frauen) systematisch schlechter funktioniert.\nAu√üerdem ist grunds√§tzlich Vorsicht geboten, wenn wir Variablen in das Modell aufnehmen, die Attribute wie Geschlecht oder Herkunft kodieren. Zum Beispiel wird die Performance eines Modells zur Diagnose von Herzinfarkten durch die Einbeziehung von ‚ÄòGeschlecht‚Äô als Merkmal h√∂chstwahrscheinlich verbessert, da M√§nner und Frauen bei einem Herzinfarkt unterschiedliche Symptome zeigen. Andererseits sollte ein Modell, das jemandem eine Kreditw√ºrdigkeit zuweist, bei dieser Entscheidung das Geschlecht der Person eher nicht ber√ºcksichtigen, da ansonsten die in historischen Daten kodierten Stereotypen weiterleben.\nDas Geschlecht oder die Hautfarbe einer Person kann jedoch auch mit anderen Variablen wie beispielsweise Einkommen oder Wohngegend korreliert sein, sodass selbst Features, die auf den ersten Blick harmlos erscheinen, problematische Informationen an das Modell weitergeben k√∂nnen. In solchen F√§llen sind zus√§tzliche Ma√ünahmen n√∂tig, um zu vermeiden, dass das Modell diskriminiert.\n\nWeitere Negativbeispiele findest du auf der Seite AI Incidence Database und in\n\n\n\n\n\n\nBuch Empfehlung:\nWeapons of Math Destruction von Cathy O‚ÄôNeil (2016)",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>H√§ufige Fehler vermeiden</span>"
    ]
  },
  {
    "objectID": "06_pitfalls.html#sec-pitfall-drifts",
    "href": "06_pitfalls.html#sec-pitfall-drifts",
    "title": "H√§ufige Fehler vermeiden",
    "section": "[Fehler #5] Daten & Konzept Drifts",
    "text": "[Fehler #5] Daten & Konzept Drifts\nWir d√ºrfen nie vergessen, dass sich die Welt permanent ver√§ndert und Modelle regelm√§√üig mit neuen Daten nachtrainiert werden m√ºssen. Nur so k√∂nnen sie sich an diese ge√§nderten Umst√§nde anpassen.\n\n\n\n\n\n\nVorsichtML versagt leise!\n\n\n\nAuch wenn alle Vorhersagen falsch sind, st√ºrzt das Programm nicht einfach mit einer Fehlermeldung ab.\n‚Üí Wir brauchen ein konstantes Monitoring, um Ver√§nderungen zu erkennen, die zu einer Verschlechterung der Modellperformance f√ºhren!\n\n\nEins der gr√∂√üten Probleme in der Praxis: Daten und Konzept-Drifts:\nDie Vorhersagegenauigkeit eines Modells l√§sst schnell nach, wenn die Daten im Produktivbetrieb von den Trainingsdaten abweichen. Dabei unterscheiden wir zwischen:\n\nDaten-Drift: Verteilung der gemessenen Werte einer oder mehrerer Variablen ver√§ndert sich. Dies kann entweder die Inputs \\(X\\) betreffen, dann nennt sich das Covariate Shift oder die Outputs \\(y\\), dann sprechen wir von Label Shift.\nKonzept-Drift: Input/Output Zusammenhang \\(X \\to y\\) √§ndert sich, d.h. exakt die gleichen Inputs \\(X\\) resultieren pl√∂tzlich in einem anderen Output \\(y\\).\n\nIn beiden F√§llen √§ndert sich etwas, das f√ºr unsere ML Anwendung wichtig ist, in der Welt. Wenn unsere gesammelten Daten diese Ver√§nderung abbilden, spricht man von Daten-Drift. Wenn wir diese Ver√§nderung nicht in unseren Inputdaten sehen k√∂nnen, handelt es sich um einen Konzept-Drift.\nBeispiel: Anhand der Produktionsbedingungen inkl. der Gr√∂√üe des produzierten Teils (\\(X\\)) m√∂chten wir vorhersagen ob das jeweilige Produkt in Ordnung oder Ausschuss ist (\\(y\\)):\n\nDaten-Drift: Der Hersteller produzierte fr√ºher nur kleine Teile, nun aber auch gr√∂√üere Teile.\nKonzept-Drift: W√§hrend fr√ºher 10% Ausschuss produziert wurden, wird nach einer Reparatur der Maschine bei gleichen Produktionsbedingungen (\\(X\\)) nur noch 5% Ausschuss (\\(y\\)) produziert.\n\n\n\n\n\n\n\nTippCovariate Shifts k√∂nnen trotz stabilem Konzept zu Label Shifts f√ºhren\n\n\n\nCovarite Shifts k√∂nnen, ohne dass es einen Konzept-Drift gibt, zu Label Shifts f√ºhren, wenn die Inputvariable kausal mit der Outputvariable verbunden ist. Zum Beispiel wurde ein Modell, das Krebs (\\(y\\)) bei Patienten basierend auf dem Alter (\\(x\\)) vorhersagt, mit einem Datensatz trainiert, der gr√∂√ütenteils aus √§lteren Menschen besteht, die naturgem√§√ü auch h√§ufiger an Krebs erkranken. In der Praxis wird das Modell dann auf Patienten jeden Alters angewendet (Covariate Shift), also auch auf mehr junge Menschen, die seltener an Krebs erkranken (Label Shift).\n\n\n\nGr√ºnde f√ºr Drifts & Vorbeugende Ma√ünahmen\nDaten- und Konzeptdrifts entstehen sowohl durch die Art wie die Daten gesammelt werden, als auch durch externe Ereignisse au√üerhalb unserer Kontrolle.\n\n\n\n\n\n\nHinweisGraduelle und pl√∂tzliche Ver√§nderungen\n\n\n\nDiese Ver√§nderungen k√∂nnen entweder graduell sein (z.B. Sprachen √§ndern sich schrittweise wenn neue W√∂rter gepr√§gt werden; ein Kameraobjektiv staubt mit der Zeit ein), oder sie k√∂nnen als pl√∂tzlicher Schock auftreten (z.B. jemand reinigt das Kameraobjektiv; als die COVID-19-Pandemie ausbrach, wechselten pl√∂tzlich viele Menschen zum Online-Shopping, wodurch Systeme zur Erkennung von Kreditkartenbetrug erstmal irrt√ºmlich Alarm schlugen).\n\n\nGe√§ndertes Datenschema\nViele Probleme entstehen intern und k√∂nnten vermieden werden, zum Beispiel:\n\nDie Benutzeroberfl√§che zur Datensammlung √§ndert sich, zum Beispiel wurde eine Gr√∂√üe zuvor in Metern erfasst und wird jetzt in Zentimetern erfasst.\nDie Sensor-Konfiguration √§ndert sich, beispielsweise wird in einer neuen Version eines Ger√§ts ein anderer Sensor verwendet, der jedoch weiterhin Werte unter dem gleichen Variablennamen wie der alte Sensor aufzeichnet.\nDie als Inputs f√ºr das Modell verwendeten Features √§ndern sich, zum Beispiel werden zus√§tzliche erstellte Features eingef√ºhrt, jedoch wurde die Feature-Transformations-Pipeline nur im Trainingscode ge√§ndert, noch nicht im Produktionscode.\n\n‚áí In diesen F√§llen sollte idealerweise ein Fehler geworfen werden, zum Beispiel k√∂nnten wir einige Tests vor der Anwendung des Modells einbauen, um sicherzustellen, dass wir die erwartete Anzahl von Features erhalten, deren Datentypen (z.B. Text oder Zahlen) wie erwartet sind und die Werte grob im erwarteten Bereich f√ºr das jeweilige Feature liegen. Dar√ºber hinaus m√ºssen andere Teams im Unternehmen dar√ºber informiert werden, dass ein ML-Modell auf ihren Daten basiert, damit sie das Data-Science-Team rechtzeitig √ºber √Ñnderungen informieren k√∂nnen.\nDaten-Drifts\nDaten-Drifts treten auf, wenn unser Modell Vorhersagen f√ºr Stichproben treffen muss, die sich von den Trainingsdaten unterscheiden. Das kann zum Beispiel daran liegen, dass bestimmte Bereiche der Trainingsdom√§ne unterrepr√§sentiert waren. Im Extremfall k√∂nnte das Modell sogar gezwungen sein, √ºber die Trainingsdom√§ne hinaus zu extrapolieren. Dies k√∂nnte beispielsweise durch folgende Gr√ºnde verursacht werden:\n\nVer√§nderte Stichprobenauswahl, zum Beispiel wenn das Unternehmen k√ºrzlich in ein anderes Land expandiert ist oder nach einer gezielten Marketingkampagne die Website von einer neuen Nutzergruppe besucht wird.\nFeindseliges Verhalten, zum Beispiel wenn Spammer st√§ndig ihre Nachrichten anzupassen, um Spam-Filter zu umgehen. Vor zehn Jahren h√§tte ein Mensch eine Spam-Nachricht von heute auch als Spam erkannt (die Bedeutung von Spam hat sich also nicht ge√§ndert), aber diese ausgefeilteren Nachrichten waren damals nicht im Trainingsdatensatz enthalten. Das macht es f√ºr ML-Modelle schwierig, diese Muster zu erkennen.\n\n‚áí Daten-Drifts k√∂nnen als Gelegenheit betrachtet werden, unseren Trainingsdatensatz zu erweitern und das Modell mit mehr Daten von unterrepr√§sentierten Untergruppen neu zu trainieren. Wie jedoch im vorherigen Abschnitt zu modellbasierter Diskriminierung erl√§utert wurde, bedeutet dies oft, dass diese unterrepr√§sentierten Untergruppen zun√§chst mit einem weniger effektiven Modell arbeiten m√ºssen, beispielsweise eine Spracherkennungsfunktion, die bei Frauen schlechter funktioniert als bei M√§nnern. Daher ist es wichtig, Untergruppen zu identifizieren, bei denen das Modell m√∂glicherweise schlechtere Ergebnisse liefert, idealerweise mehr Daten aus diesen Gruppen zu sammeln oder zumindest beim Modelltraining und -evaluierung diesen Datenpunkten gr√∂√üere Beachtung zu schenken.\nKonzept-Drifts\nKonzept-Drifts treten auf, wenn externe Ver√§nderungen oder Ereignisse eintreten, die wir nicht in unseren Daten erfasst haben oder die die Bedeutung unserer Daten ver√§ndern. Das bedeutet, dass genau dieselben Input Features pl√∂tzlich zu unterschiedlichen Outputs f√ºhren. Ein Grund kann sein, dass uns eine Variable fehlt, die einen direkten Einfluss auf den Output hat, zum Beispiel:\n\nUnser Prozess reagiert auf Temperatur und Luftfeuchtigkeit, aber wir haben nur die Temperatur aufgezeichnet und nicht die Luftfeuchtigkeit. Wenn sich also die Luftfeuchtigkeit √§ndert, f√ºhren dieselben Temperaturwerte zu unterschiedlichen Outputs. ‚áí Luftfeuchtigkeit zus√§tzlich als Input Feature im Modell aufnehmen.\nSaisonale Trends f√ºhren zu Ver√§nderungen in der Beliebtheit von Sommer- gegen√ºber Winterkleidung. ‚áí Monat / Au√üentemperatur als zus√§tzliches Input Feature hinzuf√ºgen.\nBesondere Ereignisse, wie zum Beispiel wenn ein Prominenter unser Produkt in den sozialen Medien erw√§hnt oder Menschen aufgrund von Lockdowns w√§hrend einer Pandemie ihr Verhalten √§ndern. ‚áí Obwohl es schwer sein kann, diese Ereignisse im Voraus zu prognostizieren, k√∂nnen wir, wenn sie eintreten, ein zus√§tzliches Feature wie ‚Äòw√§hrend des Lockdowns‚Äô aufnehmen, um die in diesem Zeitraum gesammelten Daten von den √ºbrigen zu unterscheiden.\nDegenerative Feedbackschleifen, d.h., die Existenz des Modells √§ndert das Verhalten der Benutzer, zum Beispiel veranlasst ein Empfehlungssystem Benutzer dazu, auf Videos zu klicken, nur weil sie empfohlen wurden. ‚áí Als zus√§tzliches Feature aufnehmen, ob das Video empfohlen wurde oder nicht, um herauszufinden, wie viel von ‚ÄúBenutzer hat auf Element geklickt‚Äù auf die Empfehlung zur√ºckzuf√ºhren ist und wie viel auf das nat√ºrliche Verhalten des Benutzers.\n\nZus√§tzlich k√∂nnen Konzept-Drifts durch Ereignisse verursacht werden, die die Bedeutung der aufgezeichneten Daten √§ndern, zum Beispiel:\n\nInflation: 1 Euro im Jahr 1990 hatte einen h√∂heren Wert als 1 Euro heute. ‚áí Daten Inflationsbereinigen oder die Inflationsrate als zus√§tzliches Input Feature aufnehmen.\nEin in Wasser getauchter Temperatursensor sammelt Kalkablagerungen, und nach einer Weile ist die Temperaturmessung nicht mehr genau. Zum Beispiel misst ein sauberer Sensor bei einer tats√§chlichen Temperatur von 90 Grad die exakten 90 Grad, aber nachdem er einige Schichten Kalk angesammelt hat, misst er unter denselben Bedingungen nur noch 89 Grad. W√§hrend unser Output von der wahren Temperatur beeinflusst wird, haben wir nur Zugriff auf die Sensormessung f√ºr die Temperatur, die auch durch den Zustand des Sensors selbst bestimmt wird. ‚áí Versuche, die Kalkablagerung zu sch√§tzen, zum Beispiel basierend auf der Anzahl der Tage seit der letzten Reinigung des Sensors (was auch bedeutet, dass solche Wartungsereignisse irgendwo erfasst werden m√ºssen!).\n\n\n\n\nKausaldiagramm, das zeigt, wie unser beobachteter Input \\(x\\) (Temperaturmessung) und Output \\(y\\) durch versteckte Variablen beeinflusst werden (auf die wir keinen direkten Zugriff haben). Diese versteckten Variablen sind der Zustand des Temperatursensors (d.h. wie viel Kalk sich angesammelt hat), die tats√§chliche Temperatur und die Luftfeuchtigkeit (f√ºr die wir noch keinen Sensor installiert haben). Wenn der Sensorzustand und die Luftfeuchtigkeit konstant bleiben, k√∂nnen wir den Output aus der Temperaturmessung vorhersagen. Wenn sich jedoch einer dieser Werte √§ndert, treten Konzept-Drifts auf. Daher sollten wir versuchen, Sch√§tzungen dieser versteckten Variablen in unser Modell aufzunehmen, um diese Ver√§nderungen zu ber√ºcksichtigen.\n\n\n‚áí Vor dem Training eines Modells sollten die Daten untersucht werden, um F√§lle zu identifizieren, bei denen identische Inputs unterschiedliche Outputs ergeben. Wenn m√∂glich, sollten zus√§tzliche Input Features aufgenommen werden, um diese Variationen zu ber√ºcksichtigen. Eine schlechte Performance des Modells auf dem Testdatensatz deutet h√§ufig darauf hin, dass relevante Inputs fehlen, was die Anf√§lligkeit f√ºr zuk√ºnftige Konzept-Drifts erh√∂ht. Selbst wenn die richtigen Variablen verwendet werden, um einen Konzept-Drift zu erfassen, kann h√§ufiges Nachtrainieren der Modelle dennoch notwendig sein. Zum Beispiel k√∂nnen unterschiedliche Zust√§nde des Konzepts ungleichm√§√üig in den Trainingsdaten vorhanden sein, was zu Daten-Drifts f√ºhren kann (z.B. mehr Daten, die im Winter gesammelt wurden als in den fr√ºhen Sommermonaten). Wenn es nicht m√∂glich ist, Variablen einzubeziehen, die den Konzept-Drift abbilden, k√∂nnte es notwendig sein, Datenpunkte aus dem urspr√ºnglichen Trainingsdatensatz zu entfernen, die nicht der neuen Input/Output-Beziehung entsprechen, bevor das Modell erneut trainiert wird.\n\n\n\n\n\n\nTippTrainiere Modelle regelm√§√üig nach\n\n\n\nDer beste Weg, Daten und Konzept-Drifts entgegenzuwirken, besteht darin, das Modell h√§ufig mit neuen Daten zu trainieren. Dies kann entweder nach einem fixen Zeitplan erfolgen (z.B. jedes Wochenende, je nachdem, wie schnell sich die Daten √§ndern) oder wenn das Monitoringsystem Alarm schl√§gt, weil es Drifts in den Inputs oder eine verschlechterte Modellperformance festgestellt hat.\n\n\n\n\nRisiken mindern durch Human-in-the-Loop\nIn den meisten F√§llen sind Fehler von ML-Modellen nicht harmlos. Manche Anwendungen, wie Produktempfehlungen, sind relativ risikoarm: Selbst falsche Outputs √§rgern Nutzer meist nur leicht. F√ºr die Mehrheit der anderen Use Cases ist es jedoch am besten, einen Menschen im Loop zu behalten. Menschen k√∂nnen den Prozess aktiv steuern ‚Äì beispielsweise indem sie Modelloutputs als Entscheidungsunterst√ºtzung nutzen, wenn sie Lagerbest√§nde auf Basis von Absatzprognosen planen ‚Äì oder nur selektiv eingreifen, etwa indem sie Ergebnisse √ºberpr√ºfen, wenn etwas verd√§chtig aussieht, regelm√§√üig einen Spam-Ordner kontrollieren oder folgenreiche Entscheidungen validieren, wenn das Modell unsicher ist. Dieser Kontrollmechanismus funktioniert jedoch nur, wenn Menschen die ML-Outputs tats√§chlich pr√ºfen und ihnen nicht blind vertrauen!",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>H√§ufige Fehler vermeiden</span>"
    ]
  },
  {
    "objectID": "08_conclusion.html",
    "href": "08_conclusion.html",
    "title": "Fazit",
    "section": "",
    "text": "Hype vs.¬†Realit√§t\nNachdem wir nun viel √ºber die Theorie des maschinellen Lernens (ML) gesprochen haben, ist es Zeit f√ºr einen Realit√§tscheck.\nIn der Einleitung haben wir viele Beispiele gesehen, die zum ML-Hype beigetragen haben. Doch beim Einsatz von ML beispielsweise in der Fertigungs- oder Prozessindustrie sieht die Realit√§t oft ganz anders aus und nicht jede Idee funktioniert wie erhofft:\nWenn du jetzt neugierig geworden bist und mehr dar√ºber erfahren m√∂chtest, wie die verschiedenen ML-Algorithmen im Detail funktionieren, wirf einen Blick in die Vollversion dieses Buches!",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Fazit</span>"
    ]
  },
  {
    "objectID": "08_conclusion.html#sec-ai-transformation",
    "href": "08_conclusion.html#sec-ai-transformation",
    "title": "Fazit",
    "section": "KI Transformation eines Unternehmens",
    "text": "KI Transformation eines Unternehmens\nDer ber√ºhmte ML-Forscher Andrew Ng hat einen f√ºnfstufigen Prozess vorgeschlagen, um ein Unternehmen in ein datengesteuertes Unternehmen zu verwandeln, welches in der Lage ist, KI produktiv zur Wertsch√∂pfung einzusetzen.\n\nF√ºnf Schritte f√ºr eine erfolgreiche KI-Transformation nach Andrew Ng\n\n\n\n\nDurchf√ºhrung von Pilotprojekten, um in Schwung zu kommen\nAufbau eines internen KI-Teams und der Dateninfrastruktur\nAngebot eines breiten KI-Trainings (f√ºr alle Mitarbeiter)\nEntwicklung einer KI- und Datenstrategie\nAusbau der internen und externen Kommunikation\n\nEmpfohlene Materialien:\n‚Üí ‚ÄúAI for everyone‚Äù Coursera Kurs\n‚Üí AI Transformation Playbook\n\n\n\n\n\nProf.¬†Dr.¬†Andrew Ng\nCo-Founder Google Brain\nVice President Baidu\nCo-Founder Coursera\nProfessor @ Stanford University\n\n\n\n\n\n\n\n[Schritt 1] Beginne mit kleinen Pilotprojekten, um das Potenzial und die Herausforderungen bei der Verwendung von ML zu verstehen\nML-Projekte sind anders als herk√∂mmliche Softwareprojekte, bei denen man normalerweise zumindest wei√ü, dass eine L√∂sung existiert, und man muss nur einen effizienten Weg finden diese umzusetzen. Stattdessen ist ML abh√§ngig von den verf√ºgbaren Daten. Auch wenn es theoretisch m√∂glich w√§re, ein Problem mit ML zu l√∂sen, k√∂nnte dies an der Datenqualit√§t oder -quantit√§t scheitern. Bevor man eine unternehmens√ºbergreifende KI-Initiative umsetzt, ist es daher ratsam, mit mehreren kleineren Pilotprojekten zu starten, um ein besseres Gef√ºhl daf√ºr zu bekommen, was es bedeutet wenn man sich bei der L√∂sung seiner Probleme auf eine KI verl√§sst.\nBei der Auswahl eines Pilotprojekts ist der Return on Investment (ROI) des Projekts nicht der wichtigste Faktor, sondern hier stehen die bei der Umsetzung gesammelten Erfahrungen mit ML im Vordergrund. Es ist jedoch wichtig, ein Projekt zu w√§hlen, das technisch machbar ist. Es sollten also bereits ML-Algorithmen f√ºr diese Problemstellung existieren, sodass keine jahrelange Forschung n√∂tig ist, um eine eigene ausgefallene neuronale Netzwerkarchitektur zu entwickeln. Weiterhin sollte man √ºber gen√ºgend hochwertige Daten verf√ºgen, um z√ºgig loszulegen zu k√∂nnen, damit man nicht Monate nur mit der Datenvorverarbeitung verbringt, weil z.B. Daten aus verschiedenen Quellen einer fragmentierten Dateninfrastruktur kombiniert werden m√ºssen.\nFehlende KI-Resourcen kann man in diesem Schritt mit externen Berater:innen ausgleichen, die die ML-Expertise bereitstellen, w√§hrend man selbst das Dom√§nenwissen f√ºr den Erfolg des Pilotprojekts beisteuert.\n\n\n[Schritt 2] Richte ein zentralisiertes KI-Team und eine Dateninfrastruktur ein, um gr√∂√üere Projekte effizient und effektiv durchzuf√ºhren\nWir haben bereits gesehen, dass wir in der Praxis an der Schnittstelle von Theorie, Programmierung und Fachwissen arbeiten, also Data Science brauchen. Es ist jedoch unwahrscheinlich, dass man eine einzelne Person findet, die in allen drei Bereichen wirklich kompetent ist. Stattdessen haben die Menschen immer einen gewissen Fokus, weshalb wir hier drei unterschiedliche Rollen vorschlagen, die auch sehr gut zu den drei Hauptschritten f√ºr die erfolgreiche Durchf√ºhrung eines ML-Projekts passen:\n\n\n\nW√§hrend Data Strategists in ihren jeweiligen Abteilungen geeignete Probleme identifizieren, die von ML profitieren w√ºrden, k√∂nnen Data Scientists experimentieren und prototypische L√∂sungen f√ºr diese Probleme entwickeln, welche dann von Data & ML Engineers produktiv in den Einsatz gebracht werden.\n\n\nIdealerweise sind Data Scientists und Engineers in einem eigenen separaten Team (dem ‚ÄúKI-Team‚Äù) und arbeiten an Projekten aus unterschiedlichen Abteilungen wie bei einer internen Beratung:\n\n\n\n[Adaptiert von: ‚ÄúAI for everyone‚Äù von Andrew Ng (coursera.org)]\n\n\nDies hat mehrere Vorteile:\n\nData Scientists k√∂nnen mit anderen ML-Expert:innen L√∂sungen diskutieren ‚Üí viele Probleme aus unterschiedlichen Gesch√§ftsbereichen ben√∂tigen √§hnliche Algorithmen.\nDaten aus dem gesamten Unternehmen k√∂nnen f√ºr eine ganzheitliche Analyse kombiniert werden.\nDie Finanzierung ist unabh√§ngig von einzelnen Gesch√§ftsbereichen, z.B. erforderlich f√ºr die Vorabinvestitionen in eine Dateninfrastruktur und zus√§tzliche Weiterbildungsma√ünahmen um mit neuer ML-Forschung Schritt zu halten.\n\nWie wir in der Einleitung besprochen haben, werden in einem ML-Projekt etwa 90% der Zeit mit Data Wrangling und Preprocessing verbracht. Daher sollte das KI-Team besonders am Anfang mehr Data Engineers als Data Scientists haben, damit diese eine solide Dateninfrastruktur aufbauen k√∂nnen, die den Data Scientists sp√§ter viel Zeit und Kopfschmerzen erspart.\n\n\n[Schritt 3] Schule andere Mitarbeiter, um ML-Probleme zu erkennen und eine Daten-Kultur zu etablieren\nW√§hrend Data Scientists die von ihnen verwendeten Algorithmen im Detail verstehen m√ºssen, sollten andere Mitarbeiter (insbesondere Data Strategists und Abteilungsleiter:innen) ein grundlegendes Verst√§ndnis davon haben, wozu ML f√§hig ist und wozu nicht, damit sie m√∂gliche ML-Probleme in ihrem Bereich identifizieren und an das KI-Team weitergeben k√∂nnen.\n\n\n\nIch habe Schulungen auf verschiedenen Niveaus f√ºr alle Zielgruppen konzipiert.\n\n\n\n\n[Schritt 4] Entwickle eine schl√ºssige Strategie mit langfristigen Zielen, die zu einem Wettbewerbsvorteil f√ºhrt\nDie Entwicklung einer Strategie mag der erste Impuls einer F√ºhrungskraft sein, wenn sie mit einem neuen Thema wie KI konfrontiert wird. Da sich KI-Probleme jedoch so stark von anderen Projektarten unterscheiden, lohnt es sich wirklich, zuerst Erfahrung mit diesem Thema zu sammeln (also mit Schritt 1 zu beginnen!). Nachdem einige Pilotprojekte erfolgreich abgeschlossen und die R√§der in Gang gesetzt sind, um ein KI-Team zu bilden sowie die anderen Mitarbeiter zu schulen, gibt es hier ein paar Dinge, die man beim Entwickeln einer unternehmensweiten KI-Strategie beachten sollte:\n\nErstelle strategische Datenassets, die f√ºr eure Konkurrenz schwer zu replizieren sind:\n\nLangfristige Planung: Welche Daten k√∂nnten in Zukunft wertvoll sein? ‚Üí Fange jetzt an, sie zu sammeln!\nVorabinvestitionen: Welche Infrastruktur und Prozesse sind erforderlich, um die Daten den richtigen Personen zug√§nglich zu machen?\nWie k√∂nnen Daten aus verschiedenen Abteilungen kombiniert werden, damit das KI-Team ‚Äúdie Punkte verbinden‚Äù kann und dadurch einen einzigartigen Wettbewerbsvorteil schaffen kann?\nWelche M√∂glichkeiten existieren in Bezug auf eine strategische Datenakquise, z.B. in Form von ‚Äúkostenlosen‚Äù Produkten, bei denen Nutzer mit ihren Daten bezahlen (wie bei Google, Facebook, etc.)?\n\nErstelle KI-gest√ºtzte Anwendungen, die ein Alleinstellungsmerkmal f√ºr eure Produkte sind:\n\nVersuche nicht, eine Standardl√∂sung zu bauen, die man auch leicht von einem externen Anbieter einkaufen k√∂nnte. Kombiniere ML stattdessen mit eurem einzigartigen Fachwissen und Daten, um neue Funktionen f√ºr bestehenden Produkte zu entwickeln. Somit gewinnen sie f√ºr Kunden an Attraktivit√§t und es k√∂nnen neue Marktbereiche erschlossen werden.\nWie k√∂nnt ihr einen positiven Kreislauf etablieren, in dem eine KI mehr Nutzer anzieht, welche wiederum mehr Daten generieren, mit denen die KI verbessert werden kann, um so weitere Nutzer anzuziehen?\n\n\n\n\n\n\n\n\n\n[Schritt 5] Kommuniziert euren Erfolg\nNach erfolgreicher Implementierung von KI im Unternehmen solltet ihr euren Erfolg nat√ºrlich auch kommunizieren. Dazu geh√∂ren neben internen und externen Pressemitteilungen zum Beispiel auch Stellenangebote. Zeigen diese eure KI Kompetenzen, statt eine Reihe von Buzzwords aufzulisten, ziehen sie automatisch qualifiziertere Kandidat:innen an.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Fazit</span>"
    ]
  }
]