<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Avoiding Common Pitfalls – A Practitioner's Guide to Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./08_conclusion.html" rel="next">
<link href="./05_supervised_models.html" rel="prev">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-37b241f53b32a5ad598e4053e71b073f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./06_pitfalls.html"><span class="chapter-title">Avoiding Common Pitfalls</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">A Practitioner’s Guide to Machine Learning</a> 
        <div class="sidebar-tools-main">
    <a href="./A-Practitioner-s-Guide-to-Machine-Learning.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01a_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01b_basics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">The Basics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_data.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Data Analysis &amp; Preprocessing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_supervised_models.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Deep Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_pitfalls.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Avoiding Common Pitfalls</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_conclusion.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Conclusion</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-pitfall-evaluation" id="toc-sec-pitfall-evaluation" class="nav-link active" data-scroll-target="#sec-pitfall-evaluation">[Pitfall #1] Deceptive model evaluation</a></li>
  <li><a href="#sec-pitfall-generalize" id="toc-sec-pitfall-generalize" class="nav-link" data-scroll-target="#sec-pitfall-generalize">[Pitfall #2] Model does not generalize</a></li>
  <li><a href="#sec-pitfall-spurious" id="toc-sec-pitfall-spurious" class="nav-link" data-scroll-target="#sec-pitfall-spurious">[Pitfall #3] Model abuses spurious correlations</a></li>
  <li><a href="#sec-pitfall-biased" id="toc-sec-pitfall-biased" class="nav-link" data-scroll-target="#sec-pitfall-biased">[Pitfall #4] Model discriminates</a></li>
  <li><a href="#sec-pitfall-drifts" id="toc-sec-pitfall-drifts" class="nav-link" data-scroll-target="#sec-pitfall-drifts">[Pitfall #5] Data &amp; Concept Drifts</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-pitfalls" class="quarto-section-identifier"><span class="chapter-title">Avoiding Common Pitfalls</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>All models are wrong, but some are useful.<br>
– <em>George E. P. Box</em></p>
</blockquote>
<p>The above quote is also nicely exemplified by <a href="https://xkcd.com/2048/">this xkcd comic</a>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_causality/xkcd_curve_fitting.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:50.0%"></p>
</figure>
</div>
<p>A supervised learning model tries to infer the relationship between some inputs and outputs from the given exemplary data points. What kind of relation will be found is largely determined by the chosen model type and its internal optimization algorithm, however, there is a lot we can (and should) do to make sure what the algorithm comes up with is not blatantly wrong.</p>
<p><strong>What do we want?</strong><br>
A model that …</p>
<ul>
<li>… makes accurate predictions</li>
<li>… for new data points</li>
<li>… for the right reasons</li>
<li>… even when the world keeps on changing.</li>
</ul>
<p>In the following, we’ll discuss several common pitfalls and how to avoid them.</p>
<section id="sec-pitfall-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="sec-pitfall-evaluation">[Pitfall #1] Deceptive model evaluation</h2>
<p>Predictive models need to be evaluated, i.e., their performance needs to be quantified with an appropriate evaluation metric to get a realistic estimate of how useful a model will be in practice and how many mistakes we have to expect from it.</p>
<p>Since in supervised learning problems we know the ground truth, we can objectively evaluate different models and benchmark them against each other.</p>
<section id="is-this-a-good-model-for-the-task" class="level4 custom-gray-block">
<h4 class="anchored" data-anchor-id="is-this-a-good-model-for-the-task">Is this a good model for the task?</h4>
<p>I.e., does the model generate <em>reliable predictions</em> for <em>new data points</em>?</p>
<ul>
<li>Split the data into training and test sets to be able to get a reliable estimate of how the model will later perform when applied to new data points that it wasn’t trained on.</li>
<li>Quantify the quality of the model’s predictions on the test set with a suitable evaluation metric (depending on the problem type).</li>
</ul>
<p>⇒ Are some mistakes worse than others (e.g., consider false positives vs.&nbsp;false negatives in medical tests)?<br>
⇒ Always choose <em>a single metric/KPI</em> to optimize (maybe: additional constraints like runtime).</p>
</section>
<p>However, it can be quite easy to paint an overly optimistic picture here, therefore we always need to be critical and, for example, <strong>compare the performance of a model to that of a baseline</strong>. The simplest comparison would be to a “stupid” model that only predicts the mean (→ regression) or most frequent class (→ classification).</p>
<section id="evaluation-metrics-in-the-face-of-unbalanced-class-distributions" class="level4 custom-gray-block">
<h4 class="anchored" data-anchor-id="evaluation-metrics-in-the-face-of-unbalanced-class-distributions">Evaluation metrics in the face of unbalanced class distributions</h4>
<p>The accuracy is a very commonly used evaluation metric for classification problems:<br>
<strong>Accuracy:</strong> Fraction of samples that were classified correctly.</p>
<p>Below we see the decision boundaries of two models on a toy dataset, where the background color indicates whether the model predicts the blue or red class for a data point in this area. Which model do you think is more useful?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_evaluation/balanced_acc4a.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
<p>With unbalanced class distributions, e.g., in this case a lot more samples from the blue compared to the red class, the accuracy of a model that simply always predicts the most frequent class can be quite large. But while a 90% accuracy might sound impressive when we report the performance of a model to the project’s stakeholders, this does not necessarily mean that the model is actually useful, especially since in real world problems the undersampled class is often the one we care about most, e.g., people with a rare disease or products that have a defect.</p>
<p>Instead, the balanced accuracy is often the more informative measure when evaluating classification models and can help us to distinguish between a model that has actually learned something and the ‘stupid baseline’:<br>
<strong>Balanced Accuracy:</strong> First the fraction of correctly classified samples is computed for each class individually and then these values are averaged.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_evaluation/balanced_acc4b.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
</section>
</section>
<section id="sec-pitfall-generalize" class="level2">
<h2 class="anchored" data-anchor-id="sec-pitfall-generalize">[Pitfall #2] Model does not generalize</h2>
<p>We want a model that captures the ‘input → output’ relationship in the data and is capable of interpolating, i.e., we need to check:<br>
<strong>Does the model generate reliable predictions for new data points from the same distribution as the training set?</strong></p>
<p>While this does not ensure that the model has actually learned any true causal relationship between inputs and outputs and can extrapolate beyond the training domain (we’ll discuss this in the next section), at least we can be reasonably sure that the model will generate reliable predictions for data points similar to those used for training the model. If this isn’t given, the model is not only wrong, it’s also useless.</p>
<p>So, why does a model make mistakes on new data points? A poor performance on the test set can have two reasons: overfitting or underfitting.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_evaluation/overunderfitting.png" class="img-fluid figure-img" style="width:85.0%"></p>
<figcaption>If we only looked at the test errors for the different models shown here, we could conclude that the model on the left (overfitting) and the one on the right (underfitting) are equally wrong. While this is true in some sense, the test error alone does not tell us <em>why</em> the models are wrong or how we could improve their performance. As we can see, the two models make mistakes on the test set for completely different reasons: The model that overfits, memorized the training samples and is not able to generalize to new data points, while the model that underfits is too simple to capture the relationship between the inputs and outputs in general.</figcaption>
</figure>
</div>
<p>These two scenarios require vastly different approaches to improve the model’s performance.</p>
<p>Since most datasets have lots of input variables, we can’t just plot the model like we did above to see if it is over- or underfitting. Instead we need to compute the model’s prediction error with a meaningful evaluation metric for both the training and the test set and compare the two to see if we’re dealing with over- or underfitting:</p>
<p><strong>Overfitting:</strong> great training performance, bad on test set<br>
<strong>Underfitting:</strong> poor training AND test performance</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_evaluation/overunderfitting_errors_simple4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:65.0%"></p>
</figure>
</div>
<p>Depending on whether a model over- or underfits, different measures that can be taken to improve its performance. However, it is unrealistic to expect a model to have a perfect performance, as some tasks are just hard, for example, because the data is very noisy.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always look at the data! Is there a pattern among wrong predictions, e.g., is there a discrepancy between the performance for different classes?</p>
</div>
</div>
</section>
<section id="sec-pitfall-spurious" class="level2">
<h2 class="anchored" data-anchor-id="sec-pitfall-spurious">[Pitfall #3] Model abuses spurious correlations</h2>
<p>Even when a model is capable of generating correct predictions for new data points from the same distribution as the training set, this does not mean that the model actually picked up on the true causal relationship between the inputs and outputs!</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>ML models love to cheat &amp; take shortcuts! They will often pick up on <a href="https://www.tylervigen.com/spurious-correlations">spurious correlations</a> instead of learning the true causal relationships. This makes them vulnerable to adversarial attacks and data/domain shifts, which force the model to extrapolate instead of interpolate.</p>
</div>
</div>
<section id="a-correct-prediction-is-not-always-made-for-the-right-reasons" class="level4 custom-gray-block">
<h4 class="anchored" data-anchor-id="a-correct-prediction-is-not-always-made-for-the-right-reasons">A correct prediction is not always made for the right reasons!</h4>
<p>The graphic below is taken from a paper where the authors noticed that a fairly simple ML model (not a neural network) trained on a standard image classification dataset performed poorly for all ten classes in the dataset except one, horses. When they examined the dataset more closely and analyzed <em>why</em> the model predicted a certain class, i.e., which image features were used in the prediction (displayed as the heatmap on the right), they noticed that most of the pictures of horses in the dataset were taken by the same photographer and they all had a characteristic copyright notice in the lower left corner.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_explainability/analyzing_classifiers.png" class="img-fluid figure-img" style="width:80.0%"></p>
<figcaption>Lapuschkin, Sebastian, et al.&nbsp;“Analyzing classifiers: Fisher vectors and deep neural networks.” <em>IEEE Conference on Computer Vision and Pattern Recognition.</em> 2016.</figcaption>
</figure>
</div>
<p>By relying on this artifact, the model could identify what it perceives as “horses” in this dataset with high accuracy – both in the training and the test set, which includes pictures from the same photographer. However, of course the model failed to learn what actually defines a horse and would not be able to extrapolate and achieve the same accuracy on other horse pictures without this copyright notice. Or, equally problematic, one could add such a copyright notice to a picture of another animal and suddenly the model would mistakenly classify this as a horse, too. This means, it is possible to purposefully trick the model, which is also called an “adversarial attack”.</p>
</section>
<p>This is by far not the only example where a model has “cheated” by exploiting spurious correlations in the training set. Another popular example: A dataset with images of dogs and wolves, where all wolves were photographed on snowy backgrounds and the dogs on grass or other non-white backgrounds. Models trained on such a dataset can show a good predictive performance without having learned the true causal relationship between the features and labels.</p>
<p>To catch these kinds of mishaps, it is important to</p>
<ol type="1">
<li>critically examine the test set and hopefully notice any problematic patterns that could result in an overly optimistic performance estimate, and</li>
<li><a href="#sec-interpretability"><strong>interpret the model and explain its predictions</strong></a> to see if it has focused on the features you (or a subject matter expert) would have expected (as they did in the paper above).</li>
</ol>
<div class="custom-gray-block">
<section id="adversarial-attacks-fooling-ml-models-on-purpose" class="level4">
<h4 class="anchored" data-anchor-id="adversarial-attacks-fooling-ml-models-on-purpose">Adversarial Attacks: Fooling ML models on purpose</h4>
<p>An adversarial attack on an ML model is performed by asking the model to make a prediction for an input that was modified in such a way that a human is unaware of the change and would still arrive at a correct result, but the ML model changes its prediction to something else.</p>
<p>For example, while an ML model can easily recognize the ‘Stop’ sign from the image on the left, the sign on the right is mistaken as a speed limit sign due to the strategically placed, inconspicuous stickers, which humans would just ignore:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_explainability/adversarial_attack2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:55.0%"></p>
</figure>
</div>
<p>This happened because the model didn’t pick up on the true reasons humans identify a Stop sign as such, e.g., the octagonal form and the four white letters spelling ‘STOP’ on a red background. Instead it relied on less meaningful correlations to distinguish it from other traffic signs.<br>
Convolutional neural networks (CNN), the type of neural net typically used for image classification tasks, rely a lot on local patterns. This is why they are often easily <a href="https://www.sciencemag.org/news/2018/07/turtle-or-rifle-hackers-easily-fool-ais-seeing-wrong-thing">fooled</a> by leaving the global shape of objects, which humans rely on for identification, intact and overlaying the images with specific textures or other high-frequency patterns to trick the model into predicting a different class.</p>
</section>
<section id="genai-adversarial-prompts" class="level4">
<h4 class="anchored" data-anchor-id="genai-adversarial-prompts">GenAI &amp; Adversarial Prompts</h4>
<p>Due to their complexity, it is particularly difficult to control the output of generative AI (GenAI) models such as ChatGPT. While they can be a useful tool in human-in-the-loop scenarios (e.g., to draft an email or write code snippets that are then checked by a human before they see the light of day), it is difficult to put the necessary guardrails in place to ensure the chatbot can’t be abused in the wild.</p>
<p>A Chevrolet car dealer that tried to use ChatGPT in their customer support chat is just one of many examples where early GenAI applications yielded mixed results at best:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_explainability/adversarial_chatgpt.png" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption>Screenshot: https://twitter.com/ChrisJBakke/status/1736533308849443121 (12.1.2024)</figcaption>
</figure>
</div>
</section>
</div>
<p>Finding robust causal models that capture the true ‘input → output’ relationship in the data is still <a href="https://bdtechtalks.com/2021/03/15/machine-learning-causality/">an active research area</a> and a lot harder than learning a model that “only” generalizes well to the test set.</p>
</section>
<section id="sec-pitfall-biased" class="level2">
<h2 class="anchored" data-anchor-id="sec-pitfall-biased">[Pitfall #4] Model discriminates</h2>
<p>As we ponder the true causal relations between variables in the data, we also need to consider whether there are some causal relationships encoded in the historical data that we <em>don’t</em> want a model to pick up on. For example, discrimination based on gender or ethnicity can leak into the training data and we need to take extra measures to make sure that these patterns, although they might have been true causal relationships in the past, are not present in our model now.</p>
<section id="biased-data-leads-to-strongly-biased-models" class="level4">
<h4 class="anchored" data-anchor-id="biased-data-leads-to-strongly-biased-models">Biased data leads to (strongly) biased models</h4>
<p>Below are some examples where people with the best of intentions have set up an ML model that has learned problematic things from real world data.</p>
<div class="custom-gray-block">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_data_issues/bias_microsoft_tay.png" class="img-fluid figure-img" style="width:55.0%"></p>
<figcaption>What started as a research project to see how humans would interact with an AI-based chatbot, ended as a PR-nightmare for Microsoft. The chatbot was supposed to learn from the messages written to it, but since the developers apparently thought more about their natural language models instead of human behavior on the internet, Tay mainly repeated all the racist, sexists things others tweeted.</figcaption>
</figure>
</div>
</div>
<div class="custom-gray-block">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_data_issues/bias_twitter_imagecrop.png" class="img-fluid figure-img" style="width:55.0%"></p>
<figcaption>Since many of the images posted on Twitter are larger than the available space for the preview image, Twitter decided to train a model to select “the most relevant part” of an image to be displayed as a preview. Unfortunately, as they had trained this model on a dataset with more pictures of white people than people of color, the model became racist and, for example, given a picture of Barack Obama and some random unimportant white politician, it always selected the white politician for the preview image. Similarly, such cropping algorithms were also reported to more often select faces as preview images for men and the body (specifically, you’ve guessed it, boobs) as preview images for women.</figcaption>
</figure>
</div>
</div>
<div class="custom-gray-block">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_data_issues/bias_household_lowerincome.png" class="img-fluid figure-img" style="width:65.0%"></p>
<figcaption>Most computer vision models are (pre-)trained on the ImageNet dataset, which contains over 14 million hand-annotated pictures, organized in more than 20k categories. However, since these pictures are sourced from the internet and more people from developed instead of developing nations tend to post pictures online, the variety of common household items, for example, is highly skewed towards products found in richer countries. Subsequently, these models mistake, e.g., bars of soap found in a poorer country as food (e.g., one could argue that these do indeed bear some resemblance to a plate of food that might be found in a fancy restaurant).<br>
de Vries, Terrance, et al.&nbsp;“Does object recognition work for everyone?” <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops.</em> 2019.</figcaption>
</figure>
</div>
</div>
<p>The above problems all arose because the data was not sampled uniformly:</p>
<ul>
<li>Tay has seen many more racist and hateful comments and tweets than ‘normal’ ones.</li>
<li>In historical texts, women were underrepresented in professions such as doctors, engineers, carpenters, etc.</li>
<li>The image dataset Twitter trained its model on included more pictures of white people compared to people of color.</li>
<li>Similarly, given a random collection of photos from the internet, these images will have mostly been uploaded by people from developed countries, i.e., pictures displaying the status quo in developing nations are underrepresented.</li>
</ul>
<p>Even more problematic than a mere underrepresentation of certain subgroups (i.e., a skewed input distribution) is a pattern of systematic discrimination against them in historical data (i.e., a discriminatory shift in the assigned labels).</p>
<div class="custom-gray-block">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_data_issues/bias_apple_card.png" class="img-fluid figure-img" style="width:55.0%"></p>
<figcaption>A lot of explicit discrimination is often encoded in datasets used to train models for assigning credit scores or determine interest rates for mortgages or loans. Since these application areas have a direct and severe influence on humans’ lives, here we have to be especially careful and, for example, check that the model predicts the same score for a man and a woman if all the features of a data point are equal except those encoding a person’s gender.</figcaption>
</figure>
</div>
</div>
<p><u>To summarize:</u> A biased model can negatively affect users in two ways:</p>
<ul>
<li>Disproportionate product failures, due to skewed sampling. For example, speech recognition models are often less accurate for women, because they were trained on more data collected from men (e.g., transcribed political speeches).</li>
<li>Harm by disadvantage / opportunity denial, due to stereotypes encoded in historical data. For example, women are assigned higher credit interest rates than men or people born in foreign countries are deemed less qualified for a job when their resumes are assessed by an automated screening tool.</li>
</ul>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Retraining models on data shaped by predictions from a biased predecessor model can intensify existing biases. For instance, if a resume screening tool recognizes a common trait (e.g., “attended Stanford University”) among current employees, it may consistently recommend resumes with this trait. Consequently, more individuals with this characteristic will be invited for interviews and hired, further reinforcing the dominance of the trait in subsequent models trained on these employee profiles.</p>
</div>
</div>
</section>
<section id="towards-fair-models" class="level4">
<h4 class="anchored" data-anchor-id="towards-fair-models">Towards fair models</h4>
<p>The first step to mitigating these problems is to become aware of them. Therefore, it is important to always assess the model’s performance for each (known) subgroup individually to verify that the prediction errors of the model are random and the model is not systematically worse for some subgroups.</p>
<p>We should also <strong>be careful when including variables in the model that encode attributes such as gender or ethnicity</strong>. For example, the performance of a model that diagnoses heart attacks will most likely be improved by including ‘gender’ as a feature, since men and women present different symptoms when they have a heart attack. On the other hand, a model that assigns someone a credit score should probably not rely on the gender of the person for this decision, since, even though this might have been the case in the historical data because the humans that generated the data relied on their own stereotypes, women should not get a lower score just because they are female.</p>
<p>However, a person’s gender or ethnicity, for example, is often correlated with other variables such as income or neighborhood, so even inconspicuous features can still leak problematic information to the model and require some extra steps to ensure the model does not discriminate.</p>
<div class="custom-gray-block">
<p>For other examples of what not to do, check out the <a href="https://incidentdatabase.ai/">AI Incidence Database</a> and</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[ 20, 80 ]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: center;">
<p><img src="../images/08_ml_in_practice/book_weapons_2016.jpg" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 80.0%;justify-content: flex-start;">
<p>Book recommendation:<br>
<strong>Weapons of Math Destruction</strong> by Cathy O’Neil (2016)</p>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="sec-pitfall-drifts" class="level2">
<h2 class="anchored" data-anchor-id="sec-pitfall-drifts">[Pitfall #5] Data &amp; Concept Drifts</h2>
<p>We must never forget that the world keeps on changing and that models need to be updated regularly with new data to be able to adapt to these changing circumstances!</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>ML fails silently!</strong> I.e., even if all predictions are wrong, the program does not simply crash with some error message.<br>
→ Need constant monitoring to detect changes that lead to a deteriorating performance!</p>
</div>
</div>
<p><u>One of the biggest problems in practice: Data and Concept Drifts:</u><br>
The model performance quickly decays when the distribution of the <strong>data used for training</strong> <span class="math inline">\(P_{train}(X, y)\)</span> is <strong>different from the data the model encounters when deployed in production</strong> <span class="math inline">\(P_{prod}(X, y)\)</span>, where <span class="math inline">\(P(X, y) = P(y|X)P(X) = P(X|y)P(y)\)</span>.<br>
Such a discrepancy can be due to</p>
<ul>
<li><strong><em>Data drift:</em></strong> the distribution of one or more variables changes. This is called a <em>covariate shift</em> if the distribution of input features <span class="math inline">\(X\)</span> changes, i.e., <span class="math inline">\(P_{train}(X) \neq P_{prod}(X)\)</span>, and a <em>label shift</em> if the distribution of the target variable <span class="math inline">\(y\)</span> changes.</li>
<li><strong><em>Concept drift:</em></strong> input/output relationship <span class="math inline">\(X \to y\)</span> changes, i.e., <span class="math inline">\(P_{train}(y|X) \neq P_{prod}(y|X)\)</span>. This means with exactly the same inputs <span class="math inline">\(X\)</span> we now get a different output <span class="math inline">\(y\)</span> than before the drift.</li>
</ul>
<p>In both cases, something important for our machine learning task changes in the world. If our collected data reflects this change, it is called data drift. If we can’t see this change in our input data, we’re dealing with a concept drift.</p>
<p><u>Example:</u> From the production settings incl.&nbsp;the size of a produced part (<span class="math inline">\(X\)</span>) we want to predict whether the part is scrap or okay (<span class="math inline">\(y\)</span>):</p>
<ul>
<li><em>Data drift:</em> The company used to manufacture only small parts, now they also produce larger parts.</li>
<li><em>Concept drift:</em> The company used to produce 10% scrap parts, but after some maintenance on the machine, the same production settings (<span class="math inline">\(X\)</span>) now result in only 5% scrap (<span class="math inline">\(y\)</span>).</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Covariate shifts, without concept drift, can lead to label shifts when the input variable is causally related to the target. For example, a model predicting cancer (<span class="math inline">\(y\)</span>) in patients based on age (<span class="math inline">\(x\)</span>) was trained on a dataset consisting of mostly older people, who naturally also have a higher cancer incidence. In production, the model is used on patients of all ages (<em>covariate shift</em>), i.e., including more young people that have cancer less frequently (<em>label shift</em>).</p>
</div>
</div>
<section id="drift-origins-mitigation-strategies" class="level4">
<h4 class="anchored" data-anchor-id="drift-origins-mitigation-strategies">Drift Origins &amp; Mitigation Strategies</h4>
<p>There are various reasons for data and concepts drifts, both related to how the data is collected as well as external events outside our control.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>These drifts can either be <strong>gradual</strong> (e.g., languages change gradually as new words are coined; a camera lens gets covered with dust over time), or they can come as a <strong>sudden shock</strong> (e.g., someone cleans the camera lens; when the COVID-19 pandemic hit, suddenly a lot of people switched to online shopping, which tripped up the credit card fraud detection systems).</p>
</div>
</div>
<p><strong><em>Changed data schema</em></strong></p>
<p>Many problems are created in-house and could be avoided, for example</p>
<ul>
<li>the user interface used to collect the data changes, e.g., a height was previously recorded in meters, now in cm</li>
<li>the sensor configuration changed, e.g., in a new version of a device, a different sensor is used, but still logs values under the same variable name as the old sensor</li>
<li>the features used as input for the model are changed, e.g., to include additional engineered features, but the feature transformation pipeline was only changed in the training code, not yet in the production code.</li>
</ul>
<p>⇒ These cases should ideally result in an error, e.g., we could include some <strong>checks before applying the model</strong> to make sure we received the expected number of features, their data types (e.g., text or numbers) is as expected, and the values are roughly in the expected range for the respective feature. Furthermore, other teams in the company need to be made aware that an ML model is relying on their data so they can notify the data science team ahead of time in case of changes.</p>
<p><strong><em>Data drifts</em></strong></p>
<p>Data drifts occur when our model has to make predictions for samples that are different from the data it encountered during training, e.g., because certain regimes of the training domain were undersampled, or in the extreme case the model might even be forced to extrapolate beyond the training domain, for example, due to</p>
<ul>
<li><strong>changed sample selection</strong>, e.g., the business recently expanded to a different country or after a targeted marketing campaign the website is now visited by a new user group</li>
<li><strong>adversarial behavior</strong>, e.g., spammers continuously adapt their messages in an effort to circumvent spam filters (i.e., ten years ago a human would have also recognized a spam message from today as spam (i.e., the meaning of what is or isn’t spam didn’t change), but these more sophisticated messages weren’t included in the training set yet, making it hard for ML models to pick up on these patterns)</li>
</ul>
<p>⇒ Data drifts can be seen as an opportunity to extend our training set and <strong>retrain the model with more data from underrepresented subgroups</strong>. Yet, as highlighted in the earlier section on model-based discrimination, this often implies that these undersampled subgroups could initially experience a less effective model, such as a speech recognition function performing less accurately for women than for men. Therefore, it’s crucial to identify subgroups where the model might exhibit poor performance, ideally gathering more data from these groups or, at the very least, giving greater consideration to these samples during model training and evaluation.</p>
<p><strong><em>Concept drifts</em></strong></p>
<p>Concept drifts happen when external changes or events occur that we did not record in our data or that change the meaning of our data. This means that the exact same input features suddenly result in a different output. One reason can be that we’re <strong>missing a variable that has a direct influence on the target</strong>, for example</p>
<ul>
<li>our process is sensitive to temperature and humidity, but we only recorded the temperature not the humidity, so as the humidity changes, the same temperature values result in different output values ⇒ additionally include humidity as an input feature in the model</li>
<li>seasonal trends result in changes in the popularity of summer vs.&nbsp;winder clothes ⇒ include month / outside temperature as an additional input feature</li>
<li>special events, e.g., a celebrity mentioned our product on social media or people changed their behavior because of the lockdown during a pandemic ⇒ while it can be hard to predict these events in advance, when they happen we could include an additional feature, e.g., ‘during lockdown’, to distinguish data collected during this time period from the rest of the data</li>
<li>degenerate feedback loops, i.e., the existence of the model changes users’ behavior, e.g., a recommender system causes users to click on videos just because they were recommended ⇒ include as an additional feature whether the video was recommended or not to learn how much of “user clicked on item” was due to the item being recommended and how much was due to the user’s natural behavior</li>
</ul>
<p>Another cause of concept drifts are events that <strong>change the meaning of the recorded data</strong>, for example</p>
<ul>
<li>inflation: 1 Euro in 1990 was worth more than 1 Euro now ⇒ adjust the data for inflation or include the inflation rate as an additional input feature</li>
<li>a temperature sensor immersed in water amasses limescale and after a while the temperature reading is not accurate anymore, e.g., if the true temperature is 90 degrees, a clean senor measures the true 90 degrees, but after it has accumulated some layers of limescale, it only measures 89 degrees under the same circumstances. While our output is influenced by the true temperature, we only have access to the sensor reading for the temperature, which is additionally influenced by the state of the sensor itself ⇒ try to estimate the amount of accumulated limescale, e.g., based on the number of days since the sensor was cleaned the last time (which also means that these kinds of maintenance events need to be recorded somewhere!)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/06_data_issues/concept_drift.png" class="img-fluid figure-img" style="width:40.0%"></p>
<figcaption>Causal diagram showing how our observed input <span class="math inline">\(x\)</span> (temperature measurement) and output <span class="math inline">\(y\)</span> are related through and influenced by hidden variables (which we can not access directly), namely, the state of the temperature sensor (i.e., how much limescale has accumulated), the actual temperature, and the humidity (for which we have not installed a sensor yet). If the sensor state and humidity stay constant, we are able to predict the output from the temperature measurement, however, if either of these values change, we experience a concept drift. Therefore, we should try to include estimates of these hidden variables in our model to account for these changes.</figcaption>
</figure>
</div>
<p>⇒ Before training a model, examine the data to <strong>identify instances where identical inputs yield different outputs</strong>. If possible, <strong>include additional input features to account for these variations</strong>. Subpar model performance on the test set often indicates missing relevant inputs, heightening vulnerability to future concept drifts. Even when the correct variables are incorporated to capture a concept drift, frequent model retraining may still be necessary. For instance, different states of the concept might be sampled unevenly, leading to data drifts (e.g., more data collected during winter than in the early summer months). If it is not possible to include variables that account for the concept drift, it might be necessary to <strong>remove samples from the original training set that do not conform to the novel input/output relation before retraining the model</strong>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>The best way to counteract data and concept drifts is to frequently <strong>retrain the model</strong> on new data. This can either happen on a schedule (e.g., every weekend, depending on how quickly the data changes) or when your monitoring system raises an alert because it detected drifts in the inputs or a deteriorating model performance.</p>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script type="text/javascript"> // go once over all images and transform the percentage width into pixels relative to original body size
  const bodyWidth = parseFloat(getComputedStyle(document.documentElement).getPropertyValue('--custom-body-width')); // Get CSS variable
  document.querySelectorAll('.quarto-figure img').forEach((img) => {
    if (img.getAttribute('style')) {
      const styleWidth = img.getAttribute('style').match(/width:\s*([\d.]+)%/); // Extract percentage
      if (styleWidth) {
        const percentage = parseFloat(styleWidth[1]) / 100;
        img.style.width = `${bodyWidth * percentage}px`; // Apply calculated width
      }
    }
  });
</script>

<style type="text/css">
#footer {
  font-size: 80%; /* Makes the font 70% smaller */
  border-top: 1px solid #ccc; /* Adds a horizontal line above the footer */
  padding-top: 10px; /* Adds some spacing above the footer content */
}
</style>

<!-- FOOTER  -->
<div id="footer" class="outer">
  <footer class="inner">
    <p><b>Book/Course Feedback: </b> <a href="https://forms.gle/Ccv5h5zQxwPjWtCS7" target="_blank" rel="nofollow">Full Feedback Survey</a> or <a href="https://forms.gle/qK8T5ALzgpiZaxd49" target="_blank" rel="nofollow">Short Comment</a><br></p>

    <p>Find me on <a href="https://github.com/cod3licious/" target="_blank" rel="nofollow">GitHub</a> and <a href="https://www.linkedin.com/in/franziska-horn/" target="_blank" rel="nofollow">LinkedIn</a><br>
      <a href="https://franziskahorn.de/">Home</a> ~ <a href="mailto:hey@franziskahorn.de?Subject=Book%20Feedback" target="_blank" rel="nofollow">Contact</a> ~ <a href="https://franziskahorn.de/impressum.html">Impressum</a></p>

      <!-- CC license -->
   <p xmlns:cc="http://creativecommons.org/ns#">This work is licensed under <a href="https://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:16px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" alt=""><img style="height:16px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" alt=""></a></p>
  </footer>
</div>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./05_supervised_models.html" class="pagination-link" aria-label="Deep Learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Deep Learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./08_conclusion.html" class="pagination-link" aria-label="Conclusion">
        <span class="nav-page-text"><span class="chapter-title">Conclusion</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>