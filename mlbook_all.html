<!DOCTYPE html>
<html lang="en">
<head>
<!-- with https://favicon.io/favicon-generator/  : Fira Code font -->
<link rel="apple-touch-icon" sizes="180x180" href="../assets/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../assets/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../assets/favicon/favicon-16x16.png">
<link rel="manifest" href="./assets/favicon/site.webmanifest">
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.16">
<meta name="author" content="Dr. Franziska Horn">
<meta name="copyright" content="Dr. Franziska Horn">
<title>A Practitioner&#8217;s Guide to Machine Learning</title>
<style>
@import url(https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css);
@import url(https://fonts.googleapis.com/css2?family=Source+Sans+Pro);
@import url(https://fonts.googleapis.com/css2?family=Inconsolata);
/* normalize.css v2.1.1 | MIT License | git.io/normalize */
/* ========================================================================== HTML5 display definitions ========================================================================== */
/** Correct `block` display not defined in IE 8/9. */
article, aside, details, figcaption, figure, footer, header, hgroup, main, nav, section, summary { display: block; }

/** Correct `inline-block` display not defined in IE 8/9. */
audio, canvas, video { display: inline-block; }

/** Prevent modern browsers from displaying `audio` without controls. Remove excess height in iOS 5 devices. */
audio:not([controls]) { display: none; height: 0; }

/** Address styling not present in IE 8/9. */
[hidden] { display: none; }

/* ========================================================================== Base ========================================================================== */
/** 1. Prevent system color scheme's background color being used in Firefox, IE, and Opera. 2. Prevent system color scheme's text color being used in Firefox, IE, and Opera. 3. Set default font family to sans-serif. 4. Prevent iOS text size adjust after orientation change, without disabling user zoom. */
html { background: #fff; /* 1 */ color: #000; /* 2 */ font-family: "Source Sans Pro", sans-serif; /* 3 */ -ms-text-size-adjust: 100%; /* 4 */ -webkit-text-size-adjust: 100%; /* 4 */ }

/** Remove default margin. */
body { margin: 0; }

/* ========================================================================== Links ========================================================================== */
/** Address `outline` inconsistency between Chrome and other browsers. */
a:focus { outline: thin dotted; }

/** Improve readability when focused and also mouse hovered in all browsers. */
a:active, a:hover { outline: 0; }

/* ========================================================================== Typography ========================================================================== */
/** Address variable `h1` font-size and margin within `section` and `article` contexts in Firefox 4+, Safari 5, and Chrome. */
h1 { font-size: 2em; margin: 0.67em 0; }

/** Address styling not present in IE 8/9, Safari 5, and Chrome. */
abbr[title] { border-bottom: 1px dotted; }

/** Address style set to `bolder` in Firefox 4+, Safari 5, and Chrome. */
b, strong { font-weight: bold; }

/** Address styling not present in Safari 5 and Chrome. */
dfn { font-style: italic; }

/** Address differences between Firefox and other browsers. */
hr { -moz-box-sizing: content-box; box-sizing: content-box; height: 0; }

/** Address styling not present in IE 8/9. */
mark { background: #ff0; color: #000; }

/** Correct font family set oddly in Safari 5 and Chrome. */
code, kbd, pre, samp { font-family: "Inconsolata", monospace, serif; font-size: 1em; }

/** Improve readability of pre-formatted text in all browsers. */
pre { white-space: pre-wrap; }

/** Set consistent quote types. */
q { quotes: "\201C" "\201D" "\2018" "\2019"; }

/** Address inconsistent and variable font size in all browsers. */
small { font-size: 80%; }

/** Prevent `sub` and `sup` affecting `line-height` in all browsers. */
sub, sup { font-size: 75%; line-height: 0; position: relative; vertical-align: baseline; }

sup { top: -0.5em; }

sub { bottom: -0.25em; }

/* ========================================================================== Embedded content ========================================================================== */
/** Remove border when inside `a` element in IE 8/9. */
img { border: 0; }

/** Correct overflow displayed oddly in IE 9. */
svg:not(:root) { overflow: hidden; }

/* ========================================================================== Figures ========================================================================== */
/** Address margin not present in IE 8/9 and Safari 5. */
figure { margin: 0; }

/* ========================================================================== Forms ========================================================================== */
/** Define consistent border, margin, and padding. */
fieldset { border: 1px solid #c0c0c0; margin: 0 2px; padding: 0.35em 0.625em 0.75em; }

/** 1. Correct `color` not being inherited in IE 8/9. 2. Remove padding so people aren't caught out if they zero out fieldsets. */
legend { border: 0; /* 1 */ padding: 0; /* 2 */ }

/** 1. Correct font family not being inherited in all browsers. 2. Correct font size not being inherited in all browsers. 3. Address margins set differently in Firefox 4+, Safari 5, and Chrome. */
button, input, select, textarea { font-family: inherit; /* 1 */ font-size: 100%; /* 2 */ margin: 0; /* 3 */ }

/** Address Firefox 4+ setting `line-height` on `input` using `!important` in the UA stylesheet. */
button, input { line-height: normal; }

/** Address inconsistent `text-transform` inheritance for `button` and `select`. All other form control elements do not inherit `text-transform` values. Correct `button` style inheritance in Chrome, Safari 5+, and IE 8+. Correct `select` style inheritance in Firefox 4+ and Opera. */
button, select { text-transform: none; }

/** 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio` and `video` controls. 2. Correct inability to style clickable `input` types in iOS. 3. Improve usability and consistency of cursor style between image-type `input` and others. */
button, html input[type="button"], input[type="reset"], input[type="submit"] { -webkit-appearance: button; /* 2 */ cursor: pointer; /* 3 */ }

/** Re-set default cursor for disabled elements. */
button[disabled], html input[disabled] { cursor: default; }

/** 1. Address box sizing set to `content-box` in IE 8/9. 2. Remove excess padding in IE 8/9. */
input[type="checkbox"], input[type="radio"] { box-sizing: border-box; /* 1 */ padding: 0; /* 2 */ }

/** 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome. 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome (include `-moz` to future-proof). */
input[type="search"] { -webkit-appearance: textfield; /* 1 */ -moz-box-sizing: content-box; -webkit-box-sizing: content-box; /* 2 */ box-sizing: content-box; }

/** Remove inner padding and search cancel button in Safari 5 and Chrome on OS X. */
input[type="search"]::-webkit-search-cancel-button, input[type="search"]::-webkit-search-decoration { -webkit-appearance: none; }

/** Remove inner padding and border in Firefox 4+. */
button::-moz-focus-inner, input::-moz-focus-inner { border: 0; padding: 0; }

/** 1. Remove default vertical scrollbar in IE 8/9. 2. Improve readability and alignment in all browsers. */
textarea { overflow: auto; /* 1 */ vertical-align: top; /* 2 */ }

/* ========================================================================== Tables ========================================================================== */
/** Remove most spacing between table cells. */
table { border-collapse: collapse; border-spacing: 0; }

*, *:before, *:after { -moz-box-sizing: border-box; -webkit-box-sizing: border-box; box-sizing: border-box; }

html, body { font-size: 100%; }

body { background: white; color: #222222; padding: 0; margin: 0; font-family: "Source Sans Pro", sans-serif; font-weight: normal; font-style: normal; line-height: 1.4; position: relative; cursor: auto; }

a:hover { cursor: pointer; }

a:focus { outline: none; }

img, object, embed { max-width: 100%; height: auto; }

object, embed { height: 100%; }

img { -ms-interpolation-mode: bicubic; }

#map_canvas img, #map_canvas embed, #map_canvas object, .map_canvas img, .map_canvas embed, .map_canvas object { max-width: none !important; }

.left { float: left !important; }

.right { float: right !important; }

.text-left { text-align: left !important; }

.text-right { text-align: right !important; }

.text-center { text-align: center !important; }

.text-justify { text-align: justify !important; text-align-last: center; padding: 0em 2em 0; line-height: 1.15;}

.hide { display: none; }

.antialiased, body { -webkit-font-smoothing: antialiased; }

img { display: inline-block; vertical-align: middle; }

textarea { height: auto; min-height: 50px; }

select { width: 100%; }

p.lead, .paragraph.lead > p, #preamble > .sectionbody > .paragraph:first-of-type p { font-size: 1.21875em; line-height: 1.4; }

.subheader, #content #toctitle, .admonitionblock td.content > .title, .exampleblock > .title, .imageblock > .title { text-align: inherit; }, .videoblock > .title, .listingblock > .title, .literalblock > .title, .openblock > .title, .paragraph > .title, .quoteblock > .title, .sidebarblock > .title, .tableblock > .title, .verseblock > .title, .dlist > .title, .olist > .title, .ulist > .title, .qlist > .title, .hdlist > .title, .tableblock > caption { line-height: 1; color: #6f6f6f; font-weight: 300; margin-top: 0.2em; margin-bottom: 0.5em; }

/* Typography resets */
div, dl, dt, dd, ul, ol, li, h1, h2, h3, #toctitle, .sidebarblock > .content > .title, h4, h5, h6, pre, form, p, blockquote, th, td { margin: 0; padding: 0; direction: ltr; }

/* Default Link Styles */
a { color: #2ba6cb; text-decoration: none; line-height: inherit; }
a:hover, a:focus { color: #2795b6; }
a img { border: none; }

/* Default paragraph styles */
p { font-family: inherit; font-weight: normal; font-size: 1em; line-height: 1.4; margin-bottom: 1.25em; text-rendering: optimizeLegibility; }
p aside { font-size: 0.875em; line-height: 1.4; font-style: italic; }

/* Default header styles */
h1, h2, h3, #toctitle, .sidebarblock > .content > .title, h4, h5, h6 { font-family: "Source Sans Pro", sans-serif; font-weight: bold; font-style: normal; color: #222222; text-rendering: optimizeLegibility; margin-top: 1em; margin-bottom: 0.5em; line-height: 1.4; }
h1 small, h2 small, h3 small, #toctitle small, .sidebarblock > .content > .title small, h4 small, h5 small, h6 small { font-size: 60%; color: #6f6f6f; line-height: 0; }

h1 { font-size: 2.125em; }

h2 { font-size: 1.6875em; }

h3, #toctitle, .sidebarblock > .content > .title { font-size: 1.375em; }

h4 { font-size: 1.125em; }

h5 { font-size: 1.125em; }

h6 { font-size: 1em; }

hr { border: solid #dddddd; border-width: 1px 0 0; clear: both; margin: 1.25em 0 1.1875em; height: 0; }

/* Helpful Typography Defaults */
em, i { font-style: italic; line-height: inherit; }

strong, b { font-weight: bold; line-height: inherit; }

small { font-size: 60%; line-height: inherit; }

code { font-family: "Inconsolata", Consolas, "Liberation Mono", Courier, monospace; font-weight: bold; color: #7f0a0c; }

/* Lists */
ul, ol, dl { font-size: 1em; line-height: 1.4; margin-bottom: 1.25em; list-style-position: outside; font-family: inherit; }

ul, ol { margin-left: 1.5em; }

/* Unordered Lists */
ul li ul, ul li ol { margin-left: 1.25em; margin-bottom: 0; font-size: 1em; /* Override nested font-size change */ }
ul.square li ul, ul.circle li ul, ul.disc li ul { list-style: inherit; }
ul.square { list-style-type: square; }
ul.circle { list-style-type: circle; }
ul.disc { list-style-type: disc; }
ul.no-bullet { list-style: none; }

/* Ordered Lists */
ol li ul, ol li ol { margin-left: 1.25em; margin-bottom: 0; }

/* Definition Lists */
dl dt { margin-bottom: 0.3125em; font-weight: bold; }
dl dd { margin-bottom: 1.25em; }

/* Abbreviations */
abbr, acronym { text-transform: uppercase; font-size: 90%; color: #222222; border-bottom: 1px dotted #dddddd; cursor: help; }

abbr { text-transform: none; }

/* Blockquotes */
blockquote { margin: 0 0 1.25em; padding: 0.5625em 1.25em 0 1.1875em; border-left: 1px solid #dddddd; }
blockquote cite { display: block; font-size: 0.8125em; color: #555555; }
blockquote cite:before { content: "\2014 \0020"; }
blockquote cite a, blockquote cite a:visited { color: #555555; }

blockquote, blockquote p { line-height: 1.4; color: #6f6f6f; }

/* Microformats */
.vcard { display: inline-block; margin: 0 0 1.25em 0; border: 1px solid #dddddd; padding: 0.625em 0.75em; }
.vcard li { margin: 0; display: block; }
.vcard .fn { font-weight: bold; font-size: 0.9375em; }

.vevent .summary { font-weight: bold; }
.vevent abbr { cursor: auto; text-decoration: none; font-weight: bold; border: none; padding: 0 0.0625em; }

@media only screen and (min-width: 768px) { h1, h2, h3, #toctitle, .sidebarblock > .content > .title, h4, h5, h6 { line-height: 1.4; }
  h1 { font-size: 2.75em; }
  h2 { font-size: 2.3125em; }
  h3, #toctitle, .sidebarblock > .content > .title { font-size: 1.6875em; }
  h4 { font-size: 1.4375em; } }
/* Print styles.  Inlined to avoid required HTTP connection: www.phpied.com/delay-loading-your-print-css/ Credit to Paul Irish and HTML5 Boilerplate (html5boilerplate.com)
*/
.print-only { display: none !important; }

@media print { * { background: transparent !important; color: #000 !important; /* Black prints faster: h5bp.com/s */ box-shadow: none !important; text-shadow: none !important; }
  a, a:visited { text-decoration: underline; }
  a[href]:after { content: " (" attr(href) ")"; }
  abbr[title]:after { content: " (" attr(title) ")"; }
  .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after { content: ""; }
  pre, blockquote { border: 1px solid #999; page-break-inside: avoid; }
  thead { display: table-header-group; /* h5bp.com/t */ }
  tr, img { page-break-inside: avoid; }
  img { max-width: 100% !important; }
  @page { margin: 0.5cm; }
  p, h2, h3, #toctitle, .sidebarblock > .content > .title { orphans: 3; widows: 3; }
  h2, h3, #toctitle, .sidebarblock > .content > .title { page-break-after: avoid; }
  .hide-on-print { display: none !important; }
  .print-only { display: block !important; }
  .hide-for-print { display: none !important; }
  .show-for-print { display: inherit !important; } }
/* Tables */
table { background: white; margin-bottom: 1.25em; border: solid 1px #dddddd; }
table thead, table tfoot { background: whitesmoke; font-weight: bold; }
table thead tr th, table thead tr td, table tfoot tr th, table tfoot tr td { padding: 0.5em 0.625em 0.625em; font-size: inherit; color: #222222; text-align: left; }
table tr th, table tr td { padding: 0.5625em 0.625em; font-size: inherit; color: #222222; }
table tr.even, table tr.alt, table tr:nth-of-type(even) { background: #f9f9f9; }
table thead tr th, table tfoot tr th, table tbody tr td, table tr td, table tfoot tr td { display: table-cell; line-height: 1.4; }

.clearfix:before, .clearfix:after, .float-group:before, .float-group:after { content: " "; display: table; }
.clearfix:after, .float-group:after { clear: both; }

*:not(pre) > code { font-size: inherit; padding: 0; white-space: nowrap; background-color: inherit; border: 0 solid #dddddd; -webkit-border-radius: 0; border-radius: 0; text-shadow: none; }

pre, pre > code { line-height: 1.4; color: black; font-family: "Inconsolata", monospace, serif; font-weight: normal; }

kbd.keyseq { color: #555555; }

kbd:not(.keyseq) { display: inline-block; color: #222222; font-size: 0.75em; line-height: 1.4; background-color: #F7F7F7; border: 1px solid #ccc; -webkit-border-radius: 3px; border-radius: 3px; -webkit-box-shadow: 0 1px 0 rgba(0, 0, 0, 0.2), 0 0 0 2px white inset; box-shadow: 0 1px 0 rgba(0, 0, 0, 0.2), 0 0 0 2px white inset; margin: -0.15em 0.15em 0 0.15em; padding: 0.2em 0.6em 0.2em 0.5em; vertical-align: middle; white-space: nowrap; }

kbd kbd:first-child { margin-left: 0; }

kbd kbd:last-child { margin-right: 0; }

.menuseq, .menu { color: #090909; }

#header, #content, #footnotes, #footer { width: 100%; margin-left: auto; margin-right: auto; margin-top: 0; margin-bottom: 0; max-width: 62.5em; *zoom: 1; position: relative; padding-left: 0.9375em; padding-right: 0.9375em; }
#header:before, #header:after, #content:before, #content:after, #footnotes:before, #footnotes:after, #footer:before, #footer:after { content: " "; display: table; }
#header:after, #content:after, #footnotes:after, #footer:after { clear: both; }

#header { margin-bottom: 2.5em; }
#header > h1 { color: black; font-weight: bold; border-bottom: 1px solid #dddddd; margin-bottom: -28px; padding-bottom: 32px; }
#header span { color: #6f6f6f; }
#header #revnumber { text-transform: capitalize; }
#header br { display: none; }
#header br + span { padding-left: 3px; }
#header br + span:before { content: "\2013 \0020"; }
#header br + span.author { padding-left: 0; }
#header br + span.author:before { content: ", "; }

#toc { border-bottom: 1px solid #dddddd; padding-bottom: 1.25em; }
#toc > ul { margin-left: 0.25em; }
#toc ul.sectlevel0 > li > a { font-style: italic; }
#toc ul.sectlevel0 ul.sectlevel1 { margin-left: 0; margin-top: 0.5em; margin-bottom: 0.5em; }
#toc ul { list-style-type: none; }

#toctitle { color: #6f6f6f; }

@media only screen and (min-width: 1280px) { body.toc2 { padding-left: 20em; }
  #toc.toc2 { position: fixed; width: 20em; left: 0; top: 0; border-right: 1px solid #dddddd; border-bottom: 0; z-index: 1000; padding: 1em; height: 100%; overflow: auto; }
  #toc.toc2 #toctitle { margin-top: 0; }
  #toc.toc2 > ul { font-size: .95em; }
  #toc.toc2 ul ul { margin-left: 0; padding-left: 1.25em; }
  #toc.toc2 ul.sectlevel0 ul.sectlevel1 { padding-left: 0; margin-top: 0.5em; margin-bottom: 0.5em; }
  body.toc2.toc-right { padding-left: 0; padding-right: 20em; }
  body.toc2.toc-right #toc.toc2 { border-right: 0; border-left: 1px solid #dddddd; left: auto; right: 0; } }
#content #toc { border-style: solid; border-width: 1px; border-color: #d9d9d9; margin-bottom: 1.25em; padding: 1.25em; background: #f2f2f2; border-width: 0; -webkit-border-radius: 0; border-radius: 0; }
#content #toc > :first-child { margin-top: 0; }
#content #toc > :last-child { margin-bottom: 0; }
#content #toc a { text-decoration: none; }

#content #toctitle { font-weight: bold; font-family: "Source Sans Pro", sans-serif; font-size: 1em; padding-left: 0.125em; }

#footer { max-width: 100%; background-color: #222222; padding: 1.25em; }

#footer-text { color: #dddddd; line-height: 1.4; }

.sect1 { padding-bottom: 1.25em; }

.sect1 + .sect1 { border-top: 1px solid #dddddd; }

#content h1 > a.anchor, h2 > a.anchor, h3 > a.anchor, #toctitle > a.anchor, .sidebarblock > .content > .title > a.anchor, h4 > a.anchor, h5 > a.anchor, h6 > a.anchor { position: absolute; width: 1em; margin-left: -1em; display: block; text-decoration: none; visibility: hidden; text-align: center; font-weight: normal; }
#content h1 > a.anchor:before, h2 > a.anchor:before, h3 > a.anchor:before, #toctitle > a.anchor:before, .sidebarblock > .content > .title > a.anchor:before, h4 > a.anchor:before, h5 > a.anchor:before, h6 > a.anchor:before { content: '\00A7'; font-size: .85em; vertical-align: text-top; display: block; margin-top: 0.05em; }
#content h1:hover > a.anchor, #content h1 > a.anchor:hover, h2:hover > a.anchor, h2 > a.anchor:hover, h3:hover > a.anchor, #toctitle:hover > a.anchor, .sidebarblock > .content > .title:hover > a.anchor, h3 > a.anchor:hover, #toctitle > a.anchor:hover, .sidebarblock > .content > .title > a.anchor:hover, h4:hover > a.anchor, h4 > a.anchor:hover, h5:hover > a.anchor, h5 > a.anchor:hover, h6:hover > a.anchor, h6 > a.anchor:hover { visibility: visible; }
#content h1 > a.link, h2 > a.link, h3 > a.link, #toctitle > a.link, .sidebarblock > .content > .title > a.link, h4 > a.link, h5 > a.link, h6 > a.link { color: #222222; text-decoration: none; }
#content h1 > a.link:hover, h2 > a.link:hover, h3 > a.link:hover, #toctitle > a.link:hover, .sidebarblock > .content > .title > a.link:hover, h4 > a.link:hover, h5 > a.link:hover, h6 > a.link:hover { color: #151515; }

.imageblock, .literalblock, .listingblock, .verseblock, .videoblock { margin-bottom: 1.25em; }

.imageblock.bordered img { border: 0px solid black; box-shadow: 5px 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19); }

.admonitionblock td.content > .title, .exampleblock > .title, .imageblock > .title { text-align: inherit; }, .videoblock > .title, .listingblock > .title, .literalblock > .title, .openblock > .title, .paragraph > .title, .quoteblock > .title, .sidebarblock > .title, .tableblock > .title, .verseblock > .title, .dlist > .title, .olist > .title, .ulist > .title, .qlist > .title, .hdlist > .title { text-align: left; font-weight: bold; }

.tableblock > caption { text-align: left; font-weight: bold; white-space: nowrap; overflow: visible; max-width: 0; }

table.tableblock #preamble > .sectionbody > .paragraph:first-of-type p { font-size: inherit; }

.admonitionblock > table { border: 0; background: none; width: 100%; }
.admonitionblock > table td.icon { text-align: center; width: 80px; }
.admonitionblock > table td.icon img { max-width: none; }
.admonitionblock > table td.icon .title { font-weight: bold; text-transform: uppercase; }
.admonitionblock > table td.content { padding-left: 1.125em; padding-right: 1.25em; border-left: 1px solid #dddddd; color: #6f6f6f; }
.admonitionblock > table td.content > :last-child > :last-child { margin-bottom: 0; }

.exampleblock > .content { border-style: solid; border-width: 1px; border-color: #e6e6e6; margin-bottom: 1.25em; padding: 1.25em; background: white; -webkit-border-radius: 0; border-radius: 0; }
.exampleblock > .content > :first-child { margin-top: 0; }
.exampleblock > .content > :last-child { margin-bottom: 0; }
.exampleblock > .content h1, .exampleblock > .content h2, .exampleblock > .content h3, .exampleblock > .content #toctitle, .sidebarblock.exampleblock > .content > .title, .exampleblock > .content h4, .exampleblock > .content h5, .exampleblock > .content h6, .exampleblock > .content p { color: #333333; }
.exampleblock > .content h1, .exampleblock > .content h2, .exampleblock > .content h3, .exampleblock > .content #toctitle, .sidebarblock.exampleblock > .content > .title, .exampleblock > .content h4, .exampleblock > .content h5, .exampleblock > .content h6 { line-height: 1.4; margin-bottom: 0.625em; }
.exampleblock > .content h1.subheader, .exampleblock > .content h2.subheader, .exampleblock > .content h3.subheader, .exampleblock > .content .subheader#toctitle, .sidebarblock.exampleblock > .content > .subheader.title, .exampleblock > .content h4.subheader, .exampleblock > .content h5.subheader, .exampleblock > .content h6.subheader { line-height: 1.4; }

.exampleblock.result > .content { -webkit-box-shadow: 0 1px 8px #d9d9d9; box-shadow: 0 1px 8px #d9d9d9; }

.sidebarblock { border-style: solid; border-width: 1px; border-color: #d9d9d9; margin-bottom: 1.25em; padding: 1.25em; background: #f2f2f2; -webkit-border-radius: 0; border-radius: 0; }
.sidebarblock > :first-child { margin-top: 0; }
.sidebarblock > :last-child { margin-bottom: 0; }
.sidebarblock h1, .sidebarblock h2, .sidebarblock h3, .sidebarblock #toctitle, .sidebarblock > .content > .title, .sidebarblock h4, .sidebarblock h5, .sidebarblock h6, .sidebarblock p { color: #333333; }
.sidebarblock h1, .sidebarblock h2, .sidebarblock h3, .sidebarblock #toctitle, .sidebarblock > .content > .title, .sidebarblock h4, .sidebarblock h5, .sidebarblock h6 { line-height: 1.4; margin-bottom: 0.625em; }
.sidebarblock h1.subheader, .sidebarblock h2.subheader, .sidebarblock h3.subheader, .sidebarblock .subheader#toctitle, .sidebarblock > .content > .subheader.title, .sidebarblock h4.subheader, .sidebarblock h5.subheader, .sidebarblock h6.subheader { line-height: 1.4; }
.sidebarblock > .content > .title { color: #6f6f6f; margin-top: 0; line-height: 1.4; }

.exampleblock > .content > :last-child > :last-child, .exampleblock > .content .olist > ol > li:last-child > :last-child, .exampleblock > .content .ulist > ul > li:last-child > :last-child, .exampleblock > .content .qlist > ol > li:last-child > :last-child, .sidebarblock > .content > :last-child > :last-child, .sidebarblock > .content .olist > ol > li:last-child > :last-child, .sidebarblock > .content .ulist > ul > li:last-child > :last-child, .sidebarblock > .content .qlist > ol > li:last-child > :last-child { margin-bottom: 0; }

.literalblock > .content pre, .listingblock > .content pre { background: #eeeeee; border-width: 1px; border-style: solid; border-color: #cccccc; -webkit-border-radius: 0; border-radius: 0; padding: 0.8em 0.8em 0.65em 0.8em; word-wrap: break-word; }
.literalblock > .content pre.nowrap, .listingblock > .content pre.nowrap { overflow-x: auto; white-space: pre; word-wrap: normal; }
.literalblock > .content pre > code, .listingblock > .content pre > code { display: block; }
@media only screen { .literalblock > .content pre, .listingblock > .content pre { font-size: 0.72em; } }
@media only screen and (min-width: 768px) { .literalblock > .content pre, .listingblock > .content pre { font-size: 0.81em; } }
@media only screen and (min-width: 1280px) { .literalblock > .content pre, .listingblock > .content pre { font-size: 0.9em; } }

.listingblock > .content { position: relative; }

.listingblock:hover code[class*=" language-"]:before { text-transform: uppercase; font-size: 0.9em; color: #999; position: absolute; top: 0.375em; right: 0.375em; }

.listingblock:hover code.asciidoc:before { content: "asciidoc"; }
.listingblock:hover code.clojure:before { content: "clojure"; }
.listingblock:hover code.css:before { content: "css"; }
.listingblock:hover code.groovy:before { content: "groovy"; }
.listingblock:hover code.html:before { content: "html"; }
.listingblock:hover code.java:before { content: "java"; }
.listingblock:hover code.javascript:before { content: "javascript"; }
.listingblock:hover code.python:before { content: "python"; }
.listingblock:hover code.ruby:before { content: "ruby"; }
.listingblock:hover code.scss:before { content: "scss"; }
.listingblock:hover code.xml:before { content: "xml"; }
.listingblock:hover code.yaml:before { content: "yaml"; }

.listingblock.terminal pre .command:before { content: attr(data-prompt); padding-right: 0.5em; color: #999; }

.listingblock.terminal pre .command:not([data-prompt]):before { content: '$'; }

table.pyhltable { border: 0; margin-bottom: 0; }

table.pyhltable td { vertical-align: top; padding-top: 0; padding-bottom: 0; }

table.pyhltable td.code { padding-left: .75em; padding-right: 0; }

.highlight.pygments .lineno, table.pyhltable td:not(.code) { color: #999; padding-left: 0; padding-right: .5em; border-right: 1px solid #dddddd; }

.highlight.pygments .lineno { display: inline-block; margin-right: .25em; }

table.pyhltable .linenodiv { background-color: transparent !important; padding-right: 0 !important; }

.quoteblock { margin: 0 0 1.25em; padding: 0.5625em 1.25em 0 1.1875em; border-left: 1px solid #dddddd; }
.quoteblock blockquote { margin: 0 0 1.25em 0; padding: 0 0 0.5625em 0; border: 0; }
.quoteblock blockquote > .paragraph:last-child p { margin-bottom: 0; }
.quoteblock .attribution { margin-top: -.25em; padding-bottom: 0.5625em; font-size: 0.8125em; color: #555555; }
.quoteblock .attribution br { display: none; }
.quoteblock .attribution cite { display: block; margin-bottom: 0.625em; }

table thead th, table tfoot th { font-weight: bold; }

table.tableblock.grid-all { border-collapse: separate; border-spacing: 1px; -webkit-border-radius: 0; border-radius: 0; border-top: 1px solid #dddddd; border-bottom: 1px solid #dddddd; }

table.tableblock.frame-topbot, table.tableblock.frame-none { border-left: 0; border-right: 0; }

table.tableblock.frame-sides, table.tableblock.frame-none { border-top: 0; border-bottom: 0; }

table.tableblock td .paragraph:last-child p, table.tableblock td > p:last-child { margin-bottom: 0; }

th.tableblock.halign-left, td.tableblock.halign-left { text-align: left; }

th.tableblock.halign-right, td.tableblock.halign-right { text-align: right; }

th.tableblock.halign-center, td.tableblock.halign-center { text-align: center; }

th.tableblock.valign-top, td.tableblock.valign-top { vertical-align: top; }

th.tableblock.valign-bottom, td.tableblock.valign-bottom { vertical-align: bottom; }

th.tableblock.valign-middle, td.tableblock.valign-middle { vertical-align: middle; }

p.tableblock.header { color: #222222; font-weight: bold; }

td > div.verse { white-space: pre; }

ol { margin-left: 1.75em; }

ul li ol { margin-left: 1.5em; }

dl dd { margin-left: 1.125em; }

dl dd:last-child, dl dd:last-child > :last-child { margin-bottom: 0; }

ol > li p, ul > li p, ul dd, ol dd, .olist .olist, .ulist .ulist, .ulist .olist, .olist .ulist { margin-bottom: 0.6em; }

ul.unstyled, ol.unnumbered, ul.checklist, ul.none { list-style-type: none; }

ul.unstyled, ol.unnumbered, ul.checklist { margin-left: 0.625em; }

ul.checklist li > p:first-child > i[class^="icon-check"]:first-child, ul.checklist li > p:first-child > input[type="checkbox"]:first-child { margin-right: 0.25em; }

ul.checklist li > p:first-child > input[type="checkbox"]:first-child { position: relative; top: 1px; }

ul.inline { margin: 0 auto 0.625em auto; margin-left: -1.375em; margin-right: 0; padding: 0; list-style: none; overflow: hidden; }
ul.inline > li { list-style: none; float: left; margin-left: 1.375em; display: block; }
ul.inline > li > * { display: block; }

.unstyled dl dt { font-weight: normal; font-style: normal; }

ol.arabic { list-style-type: decimal; }

ol.decimal { list-style-type: decimal-leading-zero; }

ol.loweralpha { list-style-type: lower-alpha; }

ol.upperalpha { list-style-type: upper-alpha; }

ol.lowerroman { list-style-type: lower-roman; }

ol.upperroman { list-style-type: upper-roman; }

ol.lowergreek { list-style-type: lower-greek; }

.hdlist > table, .colist > table { border: 0; background: none; }
.hdlist > table > tbody > tr, .colist > table > tbody > tr { background: none; }

td.hdlist1 { padding-right: .8em; font-weight: bold; }

td.hdlist1, td.hdlist2 { vertical-align: top; }

.literalblock + .colist, .listingblock + .colist { margin-top: -0.5em; }

.colist > table tr > td:first-of-type { padding: 0 .8em; line-height: 1.4; }
.colist > table tr > td:last-of-type { padding: 0.25em 0; }

.qanda > ol > li > p > em:only-child { color: #2795b6; }

.thumb, .th { line-height: 0; display: inline-block; border: solid 4px white; -webkit-box-shadow: 0 0 0 1px #dddddd; box-shadow: 0 0 0 1px #dddddd; }

.imageblock.left, .imageblock[style*="float: left"] { margin: 0.25em 0.625em 1.25em 0; }
.imageblock.right, .imageblock[style*="float: right"] { margin: 0.25em 0 1.25em 0.625em; }
.imageblock > .title { margin-bottom: 0; text-align: justify; text-align-last: center; padding: 0.5em 2em 0; line-height: 1.15;}
.imageblock.thumb, .imageblock.th { border-width: 6px; }
.imageblock.thumb > .title, .imageblock.th > .title { padding: 0 0.125em; }

.image.left, .image.right { margin-top: 0.25em; margin-bottom: 0.25em; display: inline-block; line-height: 0; }
.image.left { margin-right: 0.625em; }
.image.right { margin-left: 0.625em; }

a.image { text-decoration: none; }

span.footnote, span.footnoteref { vertical-align: super; font-size: 0.875em; }
span.footnote a, span.footnoteref a { text-decoration: none; }

#footnotes { padding-top: 0.75em; padding-bottom: 0.75em; margin-bottom: 0.625em; }
#footnotes hr { width: 20%; min-width: 6.25em; margin: -.25em 0 .75em 0; border-width: 1px 0 0 0; }
#footnotes .footnote { padding: 0 0.375em; line-height: 1.4; font-size: 0.875em; margin-left: 1.2em; text-indent: -1.2em; margin-bottom: .2em; }
#footnotes .footnote a:first-of-type { font-weight: bold; text-decoration: none; }
#footnotes .footnote:last-of-type { margin-bottom: 0; }

#content #footnotes { margin-top: -0.625em; margin-bottom: 0; padding: 0.75em 0; }

.gist .file-data > table { border: none; background: #fff; width: 100%; margin-bottom: 0; }
.gist .file-data > table td.line-data { width: 99%; }

div.unbreakable { page-break-inside: avoid; }

.big { font-size: larger; }

.small { font-size: smaller; line-height: 1;}

.underline { text-decoration: underline; }

.overline { text-decoration: overline; }

.line-through { text-decoration: line-through; }

.aqua { color: #00bfbf; }

.aqua-background { background-color: #00fafa; }

.black { color: black; }

.black-background { background-color: black; }

.blue { color: #0000bf; }

.blue-background { background-color: #0000fa; }

.fuchsia { color: #bf00bf; }

.fuchsia-background { background-color: #fa00fa; }

.gray { color: #606060; }

.gray-background { background-color: #7d7d7d; }

.green { color: #006000; }

.green-background { background-color: #007d00; }

.lime { color: #00bf00; }

.lime-background { background-color: #00fa00; }

.maroon { color: #600000; }

.maroon-background { background-color: #7d0000; }

.navy { color: #000060; }

.navy-background { background-color: #00007d; }

.olive { color: #606000; }

.olive-background { background-color: #7d7d00; }

.purple { color: #600060; }

.purple-background { background-color: #7d007d; }

.red { color: #bf0000; }

.red-background { background-color: #fa0000; }

.silver { color: #909090; }

.silver-background { background-color: #bcbcbc; }

.teal { color: #006060; }

.teal-background { background-color: #007d7d; }

.white { color: #bfbfbf; }

.white-background { background-color: #fafafa; }

.yellow { color: #bfbf00; }

.yellow-background { background-color: #fafa00; }

span.icon > [class^="icon-"], span.icon > [class*=" icon-"] { cursor: default; }

.admonitionblock td.icon [class^="icon-"]:before { font-size: 2.5em; text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.5); cursor: default; }
.admonitionblock td.icon .icon-note:before { content: "\f05a"; color: #2ba6cb; color: #207c98; }
.admonitionblock td.icon .icon-tip:before { content: "\f0eb"; text-shadow: 1px 1px 2px rgba(155, 155, 0, 0.8); color: #111; }
.admonitionblock td.icon .icon-warning:before { content: "\f071"; color: #bf6900; }
.admonitionblock td.icon .icon-caution:before { content: "\f06d"; color: #bf3400; }
.admonitionblock td.icon .icon-important:before { content: "\f06a"; color: #bf0000; }

.conum { display: inline-block; color: white !important; background-color: #222222; -webkit-border-radius: 100px; border-radius: 100px; text-align: center; width: 20px; height: 20px; font-size: 12px; font-weight: bold; line-height: 20px; font-family: "Source Sans Pro", Arial, sans-serif; font-style: normal; position: relative; top: -2px; letter-spacing: -1px; }
.conum * { color: white !important; }
.conum + b { display: none; }
.conum:after { content: attr(data-value); }
.conum:not([data-value]):empty { display: none; }


.video-container {
  position: relative;
  width: 100%;
  padding-bottom: 56.25%;
}
.video {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border: 0;
}

</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
/* Stylesheet for CodeRay to match GitHub theme | MIT License | http://foundation.zurb.com */
pre.CodeRay{background:#f7f7f8}
.CodeRay .line-numbers{border-right:1px solid currentColor;opacity:.35;padding:0 .5em 0 0}
.CodeRay span.line-numbers{display:inline-block;margin-right:.75em}
.CodeRay .line-numbers strong{color:#000}
table.CodeRay{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.CodeRay td{vertical-align:top;line-height:inherit}
table.CodeRay td.line-numbers{text-align:right}
table.CodeRay td.code{padding:0 0 0 .75em}
.CodeRay .debug{color:#fff !important;background:#000080 !important}
.CodeRay .annotation{color:#007}
.CodeRay .attribute-name{color:#000080}
.CodeRay .attribute-value{color:#700}
.CodeRay .binary{color:#509}
.CodeRay .comment{color:#998;font-style:italic}
.CodeRay .char{color:#04d}
.CodeRay .char .content{color:#04d}
.CodeRay .char .delimiter{color:#039}
.CodeRay .class{color:#458;font-weight:bold}
.CodeRay .complex{color:#a08}
.CodeRay .constant,.CodeRay .predefined-constant{color:#008080}
.CodeRay .color{color:#099}
.CodeRay .class-variable{color:#369}
.CodeRay .decorator{color:#b0b}
.CodeRay .definition{color:#099}
.CodeRay .delimiter{color:#000}
.CodeRay .doc{color:#970}
.CodeRay .doctype{color:#34b}
.CodeRay .doc-string{color:#d42}
.CodeRay .escape{color:#666}
.CodeRay .entity{color:#800}
.CodeRay .error{color:#808}
.CodeRay .exception{color:inherit}
.CodeRay .filename{color:#099}
.CodeRay .function{color:#900;font-weight:bold}
.CodeRay .global-variable{color:#008080}
.CodeRay .hex{color:#058}
.CodeRay .integer,.CodeRay .float{color:#099}
.CodeRay .include{color:#555}
.CodeRay .inline{color:#000}
.CodeRay .inline .inline{background:#ccc}
.CodeRay .inline .inline .inline{background:#bbb}
.CodeRay .inline .inline-delimiter{color:#d14}
.CodeRay .inline-delimiter{color:#d14}
.CodeRay .important{color:#555;font-weight:bold}
.CodeRay .interpreted{color:#b2b}
.CodeRay .instance-variable{color:#008080}
.CodeRay .label{color:#970}
.CodeRay .local-variable{color:#963}
.CodeRay .octal{color:#40e}
.CodeRay .predefined{color:#369}
.CodeRay .preprocessor{color:#579}
.CodeRay .pseudo-class{color:#555}
.CodeRay .directive{font-weight:bold}
.CodeRay .type{font-weight:bold}
.CodeRay .predefined-type{color:inherit}
.CodeRay .reserved,.CodeRay .keyword {color:#000;font-weight:bold}
.CodeRay .key{color:#808}
.CodeRay .key .delimiter{color:#606}
.CodeRay .key .char{color:#80f}
.CodeRay .value{color:#088}
.CodeRay .regexp .delimiter{color:#808}
.CodeRay .regexp .content{color:#808}
.CodeRay .regexp .modifier{color:#808}
.CodeRay .regexp .char{color:#d14}
.CodeRay .regexp .function{color:#404;font-weight:bold}
.CodeRay .string{color:#d20}
.CodeRay .string .string .string{background:#ffd0d0}
.CodeRay .string .content{color:#d14}
.CodeRay .string .char{color:#d14}
.CodeRay .string .delimiter{color:#d14}
.CodeRay .shell{color:#d14}
.CodeRay .shell .delimiter{color:#d14}
.CodeRay .symbol{color:#990073}
.CodeRay .symbol .content{color:#a60}
.CodeRay .symbol .delimiter{color:#630}
.CodeRay .tag{color:#008080}
.CodeRay .tag-special{color:#d70}
.CodeRay .variable{color:#036}
.CodeRay .insert{background:#afa}
.CodeRay .delete{background:#faa}
.CodeRay .change{color:#aaf;background:#007}
.CodeRay .head{color:#f8f;background:#505}
.CodeRay .insert .insert{color:#080}
.CodeRay .delete .delete{color:#800}
.CodeRay .change .change{color:#66f}
.CodeRay .head .head{color:#f4f}
</style>
</head>
<body class="book toc2 toc-left">
<div id="header">
<h1>A Practitioner&#8217;s Guide to Machine Learning</h1>
<div class="details">
<span id="author" class="author">Dr. Franziska Horn</span><br>
<span id="email" class="email"><a href="mailto:hey@franziskahorn.de">hey@franziskahorn.de</a></span><br>
<span id="revnumber">version 1.1,</span>
<span id="revdate">2021-10-28</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_introduction">Introduction</a>
<ul class="sectlevel2">
<li><a href="#_ml_is_everywhere">ML is everywhere!</a></li>
<li><a href="#_ml_history_why_now">ML history: Why now?</a></li>
<li><a href="#_what_is_ml">What is ML?</a></li>
<li><a href="#_how_do_machines_learn">How do machines &#8220;learn&#8221;?</a></li>
<li><a href="#_when_should_you_use_ml">When should you use ML?</a></li>
<li><a href="#_solving_problems_with_ml_workflow">Solving problems with ML: Workflow</a></li>
</ul>
</li>
<li><a href="#_ml_with_python">ML with Python</a></li>
<li><a href="#_data_preprocessing">Data &amp; Preprocessing</a>
<ul class="sectlevel2">
<li><a href="#_what_constitutes_1_data_point">What constitutes 1 data point?</a></li>
<li><a href="#_feature_extraction">Feature Extraction</a></li>
<li><a href="#_feature_engineering_transformations">Feature Engineering &amp; Transformations</a></li>
<li><a href="#_computing_similarities">Computing Similarities</a></li>
<li><a href="#_garbage_in_garbage_out">Garbage in, garbage out!</a></li>
</ul>
</li>
<li><a href="#_ml_solutions_overview">ML Solutions: Overview</a>
<ul class="sectlevel2">
<li><a href="#_taxonomy_of_ml_problems_solutions">Taxonomy of ML problems &amp; solutions</a></li>
</ul>
</li>
<li><a href="#_unsupervised_learning">Unsupervised Learning</a>
<ul class="sectlevel2">
<li><a href="#_dimensionality_reduction">Dimensionality Reduction</a></li>
<li><a href="#_outlier_anomaly_detection">Outlier / Anomaly Detection</a></li>
<li><a href="#_clustering">Clustering</a></li>
</ul>
</li>
<li><a href="#_supervised_learning_basics">Supervised Learning Basics</a>
<ul class="sectlevel2">
<li><a href="#_different_types_of_models">Different types of models</a></li>
<li><a href="#_model_evaluation">Model Evaluation</a></li>
</ul>
</li>
<li><a href="#_supervised_learning_models">Supervised Learning Models</a>
<ul class="sectlevel2">
<li><a href="#_linear_models">Linear Models</a></li>
<li><a href="#_decision_trees">Decision Trees</a></li>
<li><a href="#_ensemble_methods">Ensemble Methods</a></li>
<li><a href="#_k_nearest_neighbors_knn">k-Nearest Neighbors (kNN)</a></li>
<li><a href="#_kernel_methods">Kernel Methods</a></li>
</ul>
</li>
<li><a href="#_deep_learning_more">Deep Learning &amp; more</a>
<ul class="sectlevel2">
<li><a href="#_information_retrieval_similarity_search">Information Retrieval (Similarity Search)</a></li>
<li><a href="#_deep_learning_neural_networks">Deep Learning (Neural Networks)</a></li>
<li><a href="#_time_series_forecasting">Time Series Forecasting</a></li>
<li><a href="#_recommender_systems_pairwise_data">Recommender Systems (Pairwise Data)</a></li>
</ul>
</li>
<li><a href="#_avoiding_common_pitfalls">Avoiding Common Pitfalls</a>
<ul class="sectlevel2">
<li><a href="#_interpolation_does_the_model_generalize">Interpolation: Does the model generalize?</a></li>
<li><a href="#_extrapolation_correlation_vs_causation">Extrapolation: Correlation vs. Causation</a></li>
<li><a href="#_explainability_interpretable_ml">Explainability &amp; Interpretable ML</a></li>
</ul>
</li>
<li><a href="#_reinforcement_learning">Reinforcement Learning</a></li>
<li><a href="#_conclusion">Conclusion</a>
<ul class="sectlevel2">
<li><a href="#_ai_transformation_of_a_company">AI Transformation of a Company</a></li>
<li><a href="#_additional_resources">Additional Resources</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p><strong>Why read this book?</strong></p>
</div>
<div class="paragraph">
<p>There are a lot of machine learning (ML) resources out there, many of them either targeted at students or researchers and therefore rather heavy on the mathematical theory, or others in the form of tutorials, focusing on the concrete implementation and application of some ML algorithm to a specific problem. This book tries to find a middle ground between both the theoretical background (which I have studied in depth while completing my PhD in machine learning at the TU Berlin, Germany) and the practical applications, i.e., how to use these algorithms to actually solve different problems (as I have been doing in the last few years as an independent data science consultant for various firms). This book originated from my experience holding dozens of machine learning seminars and workshops in front of audiences with varying levels of technical and mathematical background.</p>
</div>
<div class="imageblock text-center bordered">
<div class="content">
<img src="images/cover/ML_2021.jpeg" alt="cover" width="340">
</div>
<div class="title"><span class="small">Book cover, featuring a drawing of part of a Siphonophorae (a kind of jellyfish) by Ernst Haeckel from his book &#8220;Kunstformen der Natur&#8221; (1900, Tafel 37; source: www.BioLib.de).</span></div>
</div>
<div class="paragraph">
<p><strong>Questions this book aims to answer:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>Which problems can machine learning (ML) solve?</p>
</li>
<li>
<p>How does ML solve these problems, i.e., how do the algorithms work (in theory)?</p>
</li>
<li>
<p>How do you actually get this to work in practice and avoid common pitfalls?</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This book does <strong>not</strong> explain the latest fancy neural network model that achieves state-of-the-art performance on some specific task. Rather it is meant to provide a general intuition for the ideas behind different machine learning algorithms to establish a solid framework that helps you better understand and integrate into a bigger picture what you later read about these specific approaches.</p>
</div>
<div class="paragraph">
<p>The Introduction and Conclusion are written for all audiences, i.e., readers generally interested in ML, who want to understand what is behind the hype and where ML can (or should not) be used. The other chapters are mainly targeted towards ML practitioners and assume the reader is familiar with elementary concepts of linear algebra (see also this <a href="https://github.com/cod3licious/python_tutorial/blob/master/math_basics.pdf">overview on the mathematical notation</a> used in the book).</p>
</div>
<div class="paragraph">
<p>While the book focuses on the general principles behind the different models, there are also references included to specific Python libraries (mostly scikit-learn) where the respective algorithms are implemented and tips for how to use them. To get an even deeper understanding of how to apply the different algorithms, I recommend that you try to solve some <a href="https://github.com/cod3licious/ml_exercises">exercises</a> covering different ML use cases.</p>
</div>
<div class="paragraph">
<p><em><strong>This is still a draft version!</strong></em> Please write me an email or <a href="https://github.com/cod3licious/ml_exercises/issues">open an issue on GitHub</a> if you have any suggestions for how this book could be improved!</p>
</div>
<div class="paragraph">
<p>In case you want to save the book as a PDF (or print it&#8201;&#8212;&#8201;but think about the environment!), you can also find a full-text version on a single page <a href="https://franziskahorn.de/mlbook_all.html">here</a>.</p>
</div>
<div class="paragraph">
<p>If you have any questions or want to discuss your solutions to the exercises (or anything else data science related), feel free to schedule an <a href="https://franziskahorn.de/consulting.html">individual coaching session</a> with me!</p>
</div>
<div class="paragraph">
<p>Enjoy! :-)</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Acknowledgments</dt>
<dd>
<p>I would like to thank <a href="https://www.linkedin.com/in/antje-relitz-3680a9107/">Antje Relitz</a> for her feedback &amp; contributions to the original workshop materials and Karin Zink for her help with some of the graphics (incl. the book cover).</p>
</dd>
<dt class="hdlist1">How to cite</dt>
</dl>
</div>
<div class="literalblock">
<div class="content">
<pre>@misc{horn2021mlpractitioner,
  author = {Horn, Franziska},
  title = {A Practitioner's Guide to Machine Learning},
  year = {2021},
  url = {https://franziskahorn.de/mlbook/},
}</pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_introduction">Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This chapter provides a general introduction into what machine learning (ML) actually is and where it can&#8201;&#8212;&#8201;or should not&#8201;&#8212;&#8201;be used.</p>
</div>
<div class="sect2">
<h3 id="_ml_is_everywhere">ML is everywhere!</h3>
<div class="paragraph">
<p>Machine learning is already used all around us to make our lives more convenient:</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Face recognition</strong></p>
</div>
<div class="paragraph">
<p>Face recognition technology is one of the earliest notable examples of machine learning and computer vision that can nowadays be found in every digital camera and smartphone.
While the algorithms implemented in a camera application are fairly simple and only detect the presence of faces in general to make sure you look your best when the picture is taken, more sophisticated algorithms are also being used by governments and law enforcement in more and more countries to match a detected face to a known person in their biometric databases, for example, to identify criminals. So&#8230;&#8203;smile!?</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_facerec.jpg" alt="face recognition" width="540">
</div>
<div class="title"><span class="small">https://thesocietypages.org/socimages/2008/12/15/nikon-s60-auto-focuses-on-voyeurs-savages-ghosts/ (15.12.2008)</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Object recognition (e.g., for self-driving cars)</strong></p>
</div>
<div class="paragraph">
<p>Another example from the area of computer vision is object recognition or image segmentation in general. This is, for example, used in self-driving cars to make sure they are aware of street signs and pedestrians.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_cars.jpg" alt="object recognition" width="640">
</div>
<div class="title"><span class="small">https://medium.com/intro-to-artificial-intelligence/c01eb6eaf9d (16.06.2018)</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Analysis of medical images</strong></p>
</div>
<div class="paragraph">
<p>The last example on image data comes from the application area of medicine: Below you see two images of retinas, i.e., photos taken of the back of someone&#8217;s eye, based on which it is possible to diagnose a common complication of diabetes that can result in blindness if left untreated.</p>
</div>
<div class="paragraph">
<p>The diagnostic algorithm that researchers at Google had developed to identify the markers of the disease in these images has reached the same level of accuracy as human experts in the field (Google had even assembled a team of top specialists to discuss the hardest cases again to get consistent labels for all images, which gave their model an additional performance boost). Since the equipment to take these images is fairly cheap, this means that with this ML model, expert diagnostic decisions can now be made available to those that might otherwise not have had the means to consult a top specialist.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_medical.png" alt="medical images" width="640">
</div>
<div class="title"><span class="small">https://ai.googleblog.com/2016/11/deep-learning-for-detection-of-diabetic.html (29.11.2016)</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Conversational agents (i.e. speech recognition&#8230;&#8203;)</strong></p>
</div>
<div class="paragraph">
<p>Leaving the field of computer vision, now an example from the area of natural language processing (NLP): Conversational agents, like Siri or Alexa, are waiting for commands in many people&#8217;s homes. While the answers they give are mostly still scripted by humans (as in the screenshot below), the real challenge is to understand what the person had actually said in the first place. Speech recognition, i.e., automatically transcribing spoken language into text, is a rather difficult problem, for example, since people speak with different accents and there can be additional background noises.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_siri.png" alt="speech recogniton" width="640">
</div>
<div class="title"><span class="small">screenshot: Siri on macOS (13.12.2018)</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Machine translation</strong></p>
</div>
<div class="paragraph">
<p>Again from the field of NLP: machine translation, i.e., automatically translating text from one language into another. If you have used Google Translate (shown as an example in the screenshot below) after it was first released in 2006, you were probably often quite disappointed with the results, as the translated sentences read more like the words were just looked up one after another in a dictionary (= statistical machine translation). However, this changed when Google made the switch to a neural network model to generate the translations 10 years later in 2016: now the translated texts are actually readable and usually require only minor manual corrections, if any.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_translation.png" alt="translation" width="640">
</div>
<div class="title"><span class="small">screenshot https://translate.google.com/ (13.12.2018)</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Recommender systems</strong></p>
</div>
<div class="paragraph">
<p>Another area where ML is used are recommender systems, e.g., on e-commerce platforms and social media, which (ideally) provide the user with helpful search results and suggestions (and thereby make money for the respective companies), like in the screenshot below from Amazon or used by Netflix, YouTube &amp; co to keep you glued to your screen. While sometimes the provided suggestions might help you find exactly what you were looking for, especially platforms with uncurated content such as YouTube have also been criticized for fostering, e.g., conspiracy theories through these personalized recommendations. Since this kind of content kept users especially engaged, it was recommended a lot and thereby drove the users further down some rabbit hole instead of also providing perspectives outside one&#8217;s own information bubble. But on the upside, the research on recommender systems has also sparked developments in other areas of science, such as methods that recommend drug molecules that fit to the proteins playing a key role in certain diseases to accelerate the search for a cure.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_recsys1.png" alt="recommender systems 1" width="640">
</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_recsys2.png" alt="recommender systems 2" width="640">
</div>
<div class="title"><span class="small">screenshot https://www.amazon.com/ (12.12.2018)</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Neural networks getting creative</strong></p>
</div>
<div class="paragraph">
<p>Lots of fun applications use neural networks to create new content, i.e., perform creative tasks that were previously thought exclusive to humans. For example, an AI has written a slightly confusing yet hilarious <a href="https://arstechnica.com/gaming/2021/05/an-ai-wrote-this-movie-and-its-strangely-moving/">script for a movie</a> (which was then actually produced!). And you&#8217;ve probably also seen some examples of <a href="https://pytorch.org/tutorials/advanced/neural_style_tutorial.html">&#8220;Neural Style Transfer&#8221;</a> before, a technique that can, for example, be used to make your social media profile picture look like a van Gogh painting. Finally, neural networks are also used to create beautiful videos that combine and transform images to accompany music, like in the video shown below:</p>
</div>
<div class="video-container">
    <iframe class="video" src="https://www.youtube.com/embed/85l961MmY8Y" allowfullscreen></iframe>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Better than humans: Alpha Go</strong></p>
</div>
<div class="paragraph">
<p>In 2016, DeepMind, a startup subsequently acquired by Google, presented AlphaGo, the first computer program to beat a human Go master. This was a huge milestone for the AI research community, as Go, with a 19 x 19 playing field, is a lot more complex than chess (8 x 8 field and more restrictive movement patterns), and even the most optimistic AI researchers had not expected that a computer could win against a Go master before 2020. The algorithms used in AlphaGo are from the subfield of reinforcement learning, which we will discuss in more detail at the end of the book.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_alphago.jpg" alt="alpha go" width="440">
</div>
<div class="title"><span class="small">https://www.nature.com/nature/volumes/529/issues/7587 (28.01.2016)</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Protein folding - solving a 50-year-old challenge</strong></p>
</div>
<div class="paragraph">
<p>Another major success story from DeepMind came in 2020, when they presented their AlphaFold model, which is now as accurate as traditional simulation models in estimating the 3D structure of proteins from their raw amino acid sequence. Knowing this 3D structure is important for drug development to determine which drug molecules can bind to a certain protein and therefore identify target structures that should be investigated further to find cures for diseases where the specific protein plays a key role. While exact simulation models existed for a long time to estimate a protein&#8217;s 3D structure, these were very slow and it often took several days to compute the folding for a single protein. With the new neural network models, the same computation can now be done in a matter of minutes or even seconds, thereby vastly accelerating drug development.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_alphafold.png" alt="alpha fold" width="640">
</div>
<div class="title"><span class="small">https://deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery (15.01.2020)</span></div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ml_history_why_now">ML history: Why now?</h3>
<div class="paragraph">
<p>Why is there such an uprise in ML now?
Not only in our everyday lives has ML become omnipresent, but also the number of research paper published each year has increased exponentially over the last few years:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/ML_history2.png" alt="history1" width="740">
</div>
<div class="title"><span class="small">Data Source: https://www.webofknowledge.com/</span></div>
</div>
<div class="paragraph">
<p>However, interestingly, this is not due to an abundance of groundbreaking theoretical accomplishments in the last few years (indicated as purple diamonds in the plot), but rather many of the algorithms used today were actually developed as far back as the late 50s / early 60s (e.g., the perceptron is the earliest version of a neural network model, which are behind all the examples shown above). Indeed, the most important neural network architectures, recurrent neural networks (RNN) and convolutional neural networks (CNN), which provide the foundation for state-of-the-art language and image processing respectively, were developed in the early 80s and 90s, but back then, we simply didn&#8217;t have the computational resources available to use them on anything more than small toy datasets.</p>
</div>
<div class="paragraph">
<p>Instead, the rise in ML publications correlates more closely with the number of transistors on CPUs (i.e., the regular processors in normal computers) and GPUs (graphics cards, which parallelize the kinds of computations needed to train neural network models efficiently):</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/ML_history4.png" alt="history2" width="740">
</div>
<div class="title"><span class="small">Data Source: https://en.wikipedia.org/wiki/Transistor_count</span></div>
</div>
<div class="paragraph">
<p>Additionally, the release of many open source libraries, such as scikit-learn (for traditional ML models) and theano, tensorflow, and (py)torch (for the implementation of neural networks), has further facilitated the use of ML algorithms in many different fields.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
While these libraries somewhat democratize the use of ML, unfortunately, this also brings with it the downside that ML is now often applied by many who might not fully understand the theoretical underpinnings of these algorithms or the assumptions they make about the data that they are being applied to. This can, in the best case, result in models that don&#8217;t show the expected performance and subsequently maybe some (misplaced) disappointment in ML, and, in the worst case, lead to models that discriminate against certain parts of the population, e.g., credit scoring algorithms used by banks that systematically give women loans at higher interest rates than men due to biases encoded in the historic data used to train the models. We&#8217;ll discuss these kinds of issues in more detail in the chapter on avoiding common pitfalls.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>An additional factor driving the spread of ML besides compute power is the availability of (digital) data. Companies like Google, Amazon, and Facebook have had a head start here, as their business model was built around data from the start, but other companies are starting to catch up. While traditional ML models do not benefit much from all this available data, large neural network models with many degrees of freedom can now show their full potential by learning from basically all the texts and images posted every day on the Internet:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/ML_why_now_data5.png" alt="datagrowth" width="640">
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>But we’re still <em>very far</em> from Artificial <strong>General</strong> Intelligence (AGI)!</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01a_intro/01_killer_robot_style.jpg" alt="agi" width="240">
</div>
</div>
<div class="paragraph">
<p>An AGI is defined as a computer program that, just like a human, excels at a wide variety of different tasks at once and can learn to master new skills by itself.</p>
</div>
<div class="paragraph">
<p>However, what is used in practice instead is <strong>Artificial <em>Narrow</em> Intelligence</strong> (ANI): models <strong>explicitly programmed to solve a specific task(s)</strong>, e.g., translate texts from one language to another, but they <strong>can&#8217;t generalize (on their own) to different tasks</strong>, i.e., the machine translation model will not tomorrow decide that it now also wants to recognize faces in images. Of course, one can pack several individual ANIs into one big program that solves multiple different tasks, but this collection of ANIs is still not able to learn (on its own) any new skills beyond these capabilities. Many AI researchers currently believe that we might never produce a true human-like AGI.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_what_is_ml">What is ML?</h3>
<div class="paragraph">
<p>OK, so machine learning is already transforming all of our lives and you should probably know something about it. So now what exactly is ML?</p>
</div>
<div class="paragraph">
<p>First of all, ML is an area of research in the field of theoretical computer science, i.e., at the intersection of math/statistics and computer science:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/venn1.png" alt="image" width="340">
</div>
</div>
<div class="paragraph">
<p>More specifically, <strong>machine learning</strong> is an <strong>umbrella term for algorithms that recognize patterns and learn rules from data</strong>.</p>
</div>
<div class="paragraph">
<p>Simply speaking, an algorithm can be thought of as a specific strategy or recipe for solving a certain kind of problem. For example, there exist effective algorithms to find the shortest paths between two cities (e.g., what Google Maps uses when you ask for directions) or to solve scheduling problems (which task should be done first and which task after that to finish all tasks before their respective deadlines and satisfy dependencies between the tasks). Machine learning deals with the subset of algorithms that detect and make use of statistical regularities in a dataset to obtain specific results.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">ML algorithms = tools to generate value from data</dt>
<dd>
<p>Analogous to the tools used in a traditional production process to build something, you can think of ML algorithms as tools to generate value from data:</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/ml_carpentry_analogy2.png" alt="image" width="840">
</div>
</div>
<div class="paragraph">
<p>In order to successfully apply ML, you should ask yourself some important questions:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>What could be valuable? (For example, this could be insights that you generate by analyzing the data or a software module, such as a face recognition algorithm, that adds a new feature to your product.)</p>
</li>
<li>
<p>What raw inputs are needed to create it? (For example, just like you can&#8217;t create a wooden chair using only fabric and metal or a few twigs you found in the forest, depending on what you want to achieve with ML, you also need the right data (quality &amp; quantity) to apply the algorithms in the first place. This can be especially tricky since in most cases you can&#8217;t just buy the data you need (like you would buy wood at a hardware store), but you have to collect it yourself (i.e., grow your own trees), which can take some time.)</p>
</li>
<li>
<p>What type of ML algorithms can transform the raw input into the kind of valuable thing I want? (More on the different kinds of ML algorithms in the next sections.)</p>
</li>
<li>
<p>Do I (or my employees) possess the necessary skills and have enough compute power available to actually accomplish this in practice? (If not, keep on reading and rent some hours on a cloud compute cluster like those provided by Amazon Web Services.)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>There exist many different ML algorithms&#8201;&#8212;&#8201;you can think of these as your <strong>ML toolbox</strong>:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/ml_toolset6.png" alt="image" width="640">
</div>
<div class="title"><span class="small">ML itself is a subfield of AI, which is currently the more frequently used buzzword, but really all the cool stuff (e.g., the examples you&#8217;ve seen in the beginning) actually use ML (AI additionally includes some old search algorithms that were used when building the first chess computers, for example). ML itself can be subdivided into 3 main subfields, unsupervised, supervised, and reinforcement learning, and another recent buzzword, &#8220;deep learning&#8221;, which just refers to all methods using neural networks. Some of the simplest algorithms used in ML, like linear regression or PCA (very similar to factor analysis), are also used by statisticians, who, however, additionally also use other tools, like hypothesis tests, which do not learn rules or patterns from data. Finally, most data scientists will use many tools from ML and statistics, but they as well use some additional tools like A/B tests (e.g., for checking whether a red or green &#8220;buy&#8221; button on a website will generate more sales), which do not fall into any of the other categories.</span></div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">ML algorithms solve &#8220;input &#8594; output&#8221; problems</dt>
<dd>
<p>What all of these ML algorithms in your toolbox have in common, is that they solve &#8220;input &#8594; output&#8221; problems like these:</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/input_output5.png" alt="image" width="500">
</div>
<div class="title"><span class="small">Example ML problems: recognizing objects in images; translating text from one language to another; determining a good next move given the current state of a Go board; identifying groups of users/customers based on some information about them like questionnaire answers (in marketing this is also called customer segmentation and, for example, used to target different groups of customers with specific advertisement campaigns, which can nowadays easily be done on social media). Despite their different nature, what all these tasks have in common is that a ML model operates on some input and should produce a corresponding useful output.</span></div>
</div>
<div class="paragraph">
<p>In the above examples, while a human (expert) typically could easily produce the correct output given the input (e.g., even a small child can recognize the cat in the first image), they have a hard time describing <em>how</em> they arrived at the correct output (e.g., how did you know that this is a cat? because of the pointy ears? the whiskers?). ML algorithms can instead learn such rules from the given samples.</p>
</div>
</div>
<div class="sect2">
<h3 id="_how_do_machines_learn">How do machines &#8220;learn&#8221;?</h3>
<div class="paragraph">
<p>The set of ML algorithms can be further subdivided based on how they work, i.e., how they learn from the data. This is inspired by how humans learn:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/ml_algorithms_short_human4.png" alt="image" width="740">
</div>
<div class="title"><span class="small"><strong>Unsupervised Learning:</strong> Humans are very good at picking up on statistical regularities in the world without being explicitly instructed to do so. For example, have you ever noticed that we don&#8217;t &#8230;&#8203; make &#8230;&#8203; pauses &#8230;&#8203; between &#8230;&#8203; words when we speak? Yet kids still intuitively learn which syllables belong to the same words and where a word ends and the new one begins. This works because some syllables always occur in the specific combination making up a single word, while this word can then be followed by many different words, starting with many different syllables. This means, simply by hearing lots of spoken text, we pick up on the conditional probability distributions of syllables. <strong>Supervised Learning:</strong> This type of learning occurs when you have a teacher that tells you what the right answers are and corrects you if you get something wrong. For example, when teaching a kid the meaning of a word, you would explicitly tell them what this word means, and if they mislabel something, e.g., call a small dog a cat, you would correct them. <strong>Reinforcement Learning:</strong> This is another type of learning that happens naturally, where humans learn the consequences of their actions. For example, while a camp fire might be nice and warm and pleasant to be around, if you got to close to a big fire, you would quickly notice that this is way too hot and avoid doing this in the future. What is important to note here is that the same action (hanging out near a fire) can have vastly different consequences depending on the given situation (camp fire vs. house burning down).</span></div>
</div>
<div class="paragraph">
<p>Analogously, machines can also learn with these three strategies:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/ml_algorithms_short4.png" alt="image" width="740">
</div>
<div class="title"><span class="small"><strong>Unsupervised Learning:</strong> Here the algorithms pick up on statistical regularities in the data, e.g., they can identify groups of similar item (like in the customer segmentation task) or find individual points that stand out (i.e., anomaly detection, for example, noticing when a machine shows some unusual behavior due to a broken part, or fraud detection like identifying suspicious credit card transactions). <strong>Supervised Learning:</strong> Here the algorithms learn from many input-output examples, e.g., images and what is shown on these images, or production conditions and whether or not the product that was produced under these conditions was faulty or okay. <strong>Reinforcement Learning:</strong> This type of learning is a bit more involved: Here the learning algorithm is also called an agent, which operates inside an environment (either, e.g., a robot moving around in the real world, or a virtual agent inside a simulation environment like a video game (which is usually much cheaper ;-)). The environment lets the agent know in which state or situation it currently is, then the agent can select how to react in this state, i.e., which (predefined) action to take, and then the environment determines the consequences of this action (e.g., kill a monster in a video game or fall off a cliff) and returns a reward depending on the outcome (e.g., extra points for defeating an enemy). Then the cycle repeats as the agent is in the next state. Based on the received reward, the agent learns over time which actions are beneficial in which situations and how to navigate the environment. The hard part here is that the reward signals often come much later after the action was executed, for example, in a video game, the agent might collect a key somewhere at the beginning of a level, but the door that can be opened with this key might only come many frames later, which means the reward will be delayed and the agent will have a hard time associating this reward with the appropriate action. Since humans have a lot of background knowledge, figuring out what works and what doesn&#8217;t in a game is much easier for us.</span></div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
In most of the book, the terms &#8220;ML algorithm&#8221; and &#8220;ML model&#8221; will be used interchangeably. To be more precise, however, in general the algorithm processes the data and learns some parameter values and these parameter settings then define the final model. (For example, a linear regression <em>model</em> is defined by its coefficients (i.e., the model&#8217;s parameters), which are found by doing some stuff with the data (i.e., executing the steps outlined in the linear regression <em>algorithm</em>, which includes solving an optimization problem).)
</td>
</tr>
</table>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<div class="title"><span class="underline">How a (supervised learning) algorithm &#8220;learns&#8221; from the data:</span></div>
<p></p>
</div>
<div class="paragraph">
<p><strong>Goal:</strong> Describe the relationship between input(s) \(x\) and output \(y\) (with a model)</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/learning_model_handout.png" alt="image" width="940">
</div>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Select a model class:</strong> Assumption: relationship is linear<br>
&#8594; linear regression model: \(y = f(x) = b + w\cdot x\)</p>
</li>
<li>
<p><strong>Define an objective:</strong> Minimize error between true &amp; predicted \(y\):<br>
&#8594; \(\min_{b,w} \sum_i (y_i - f(x_i))^2\)</p>
</li>
<li>
<p><strong>Find best model parameters given the data:</strong> i.e., solve the optimization problem defined in step 2<br>
&#8658; \(f(x) = -2.7 + 5.2x\)</p>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_when_should_you_use_ml">When should you use ML?</h3>
<div class="paragraph">
<p>While traditional software solutions are used to automate tasks that can be formulated as a fixed, predefined sequence of actions, executed according to some hard-coded rules (e.g., &#8220;a gate should open <em>if</em> an object passes through a photoelectric barrier and 20 seconds later the gate should close again&#8221;), machine learning can be used to <strong>automate &#8220;input &#8594; output&#8221; tasks</strong> for which it would otherwise be difficult to come up with such rules. For example, the quality control in a cookie factory is such an &#8220;input (cookie) &#8594; output (ok/defective)&#8221; task: While some broken cookies could be sorted out automatically by checking that each cookie weights around 15g, it would be difficult to formulate rules that reliably catch all possible defects. So either a human could watch the production line to recognize, e.g., over-baked cookies, or one could take pictures of the cookies and using them as input for a machine learning model to recognize the defective cookies:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/input_output_solving_cookie3.png" alt="image" width="780">
</div>
</div>
<div class="paragraph">
<p>To solve this problem with ML, first a large dataset needs to be compiled with photos of many good, but also all kinds of defective cookies, including the corresponding annotations, i.e., a label for each picture whether it displays a good or defective cookie. A ML algorithm can then learn to distinguish between good and defective cookies from these examples. What is important to note here is that the dataset only contains the information <em>that</em> a cookie is defective, but it is not necessary to say <em>why</em> the respective cookie is defective; these rules will be learned automatically from the data.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><span class="underline">When (not) to use ML:</span></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">ML is overkill if: </dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>a manually defined set of rules or mechanistic model can solve the problem (e.g., in the example above, if the only quality problem in the cookie factory that ever occurred were broken cookies, then the rule &#8220;cookie weight needs to be between 14-16g&#8221; would suffice to detect defective cookies).</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">ML has great potential when: </dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>an exact simulation with a mechanistic model takes too long (but can be used to generate a high quality dataset). For example, the AlphaFold model shown in the first section, which is used to predict the 3D structure of a protein from its amino acid sequence, can be trained on the data generated by the original simulation model used to solve this task before, but which was too slow to be applied to a large number of proteins.</p>
</li>
<li>
<p>solving a &#8220;simple&#8221; but hard to explain task (that takes a human ~1 second, like recognizing something in an image)<br>
&#8658; use ML to automate repetitive tasks &amp; make expert knowledge available to everyone (like Google&#8217;s diabetic retinopathy diagnostic model shown in the first section)<br>
<span class="underline">But:</span> success depends on data quality &amp; quantity!<br>
&#8594; humans are much better at generalizing from a few examples (e.g., a doctor can still easily recognize the disease even if the pictures were taken with a slightly different setup that might result, for example, in noisier images, while the ML model needs to be specifically trained for these cases, which means that in the worst case you might need to collect a lot of additional data for this new setup)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">ML is your best chance when: </dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>humans are overwhelmed by very complex, high dimensional data. For example, given an excel spreadsheet with hundreds of columns, a human can&#8217;t easily recognize any patterns in this sea of numbers. In the worst case, there actually aren&#8217;t any relationships in the data that could be discovered (maybe you didn&#8217;t record data from all the relevant sensors), but if there are, ML will most likely find them.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Steps to identify a potential ML project</dt>
</dl>
</div>
<div class="openblock">
<div class="content">
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Create a process map: which steps are executed in your business processes (flow of materials &amp; information) and what data is collected where? For example, in a production process where some of the produced parts are defective:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/automate_insights7a.png" alt="image" width="700">
</div>
</div>
</li>
<li>
<p>Identify parts of the process that could either be automated with ML (e.g., straightforward, repetitive tasks otherwise done by humans) or otherwise improved by analyzing data (e.g., to understand root causes of a problem, improve planning with what-if simulations, or optimize the use of resources):</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/automate_insights7b.png" alt="image" width="840">
</div>
<div class="title"><span class="small">While the final ML model that solves the input-output problem is just a piece of software, when a data scientist analyzes the results and interprets the model, she can generate insights that can be translated into action recommendations.</span></div>
</div>
</li>
<li>
<p>Prioritize: which project will have a high impact, but at the same time also a good chance of success, i.e., should yield a high return on investment (ROI)? For example, using ML to automate a simple task is a comparatively low risk investment, but might cause some assembly-line workers to loose their (possibly quite boring) jobs. In contrast, identifying the root causes of why a production process produces 10% scrap could save millions, but it is not clear from the start that such an analysis will actually yield useful results, since the collected data on the process conditions might not be sufficient, i.e., might not contain all the needed information.</p>
</li>
</ol>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Creating value: depth of analytics</dt>
<dd>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Exploratory analysis</strong> of historic data (with results for human post-processing)<br>
<em>Identify different groups of customers (&#8658; human: create targeted marketing campaign)</em></p>
</li>
<li>
<p>Develop a model to <strong>automate an &#8216;input &#8594; output&#8217; task</strong><br>
<em>Automatically recognize &amp; sort out products with scratches</em><br>
Use a model in a &#8220;what-if&#8221; forecast to <strong>facilitate planning</strong><br>
<em>How quickly would this machine component deteriorate under these process conditions?</em></p>
</li>
<li>
<p>Explain predictions &amp; interpret the model to <strong>understand root causes</strong><br>
<em>Identify conditions that lead to lower quality products</em></p>
</li>
<li>
<p>Systematically evaluate different inputs with the model to <strong>find optimal settings</strong><br>
<em>Determine the best production settings for a new type of raw material</em></p>
</li>
</ol>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_solving_problems_with_ml_workflow">Solving problems with ML: Workflow</h3>
<div class="paragraph">
<p>Solving &#8220;input &#8594; output&#8221; problems with ML requires three main steps:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/input_output_solving_abstract6.png" alt="image" width="680">
</div>
</div>
<div class="paragraph">
<p>The first (and arguably most important) step is to <strong>identify where machine learning can (and should) be used</strong> in the first place.</p>
</div>
<div class="paragraph">
<p>Once a suitable &#8220;input &#8594; output&#8221; problem as been identified, <strong>historic data needs to be gathered and the right ML algorithm needs to be selected and applied</strong> to obtain a working solution. This is what the next chapters are all about.</p>
</div>
<div class="paragraph">
<p>When the prototypical solution has been implemented and meets the required performance level, this solution then has to be deployed, i.e., <strong>integrated into the general workflow and infrastructure</strong> so that it can actually be used to improve the respective process in practice. There are generally two strategies for how to do this:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The ML model runs on the &#8220;edge&#8221;, i.e., on each individual machine where the respective data is collected and the output of the model is used in subsequent process steps. This is often the best strategy when the results need to be computed in real time and / or a continuous Internet connection can not be guaranteed, e.g., in self-driving cars. However, the downside of this is that, depending on the type of ML model, comparatively expensive computing equipment needs to be installed in each machine, e.g., GPUs for neural network models.</p>
</li>
<li>
<p>The ML model runs in the &#8220;cloud&#8221;, i.e., on a central server, e.g., in the form of a web application that receives the data from the individual machines, processes it, and sends back the results. This is often the more efficient solution if a response in near real time is sufficient for the respective use case, but can bring with it privacy concerns if user data is processed. One of the major benefits of this solution is that it is easier to update the ML model, for example, when more historic data becomes available or if the process changes and the model now has to deal with slightly different inputs (we&#8217;ll discuss this further in the section on messy data).</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>&#8594; As these decisions heavily depend on your specific use case, they go beyond the scope of this book. Search online for &#8220;MLOps&#8221; to find out more about these topics and hire a machine learning or data engineer to set up the required infrastructure in your company.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Machine Learning Workflow</dt>
<dd>
<p>Let&#8217;s look at the second main step, &#8220;devise a working solution&#8221;, in more detail. To solve a concrete problem using ML, you will generally follow this workflow:</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ds_workflow/data_science_workflow_17.png" alt="image" width="840">
</div>
<div class="title"><span class="small">You always start with some kind of question or problem that should be solved with ML. And to solve it, you need data, which you most likely will have to clean a bit before you can start working with it (e.g., merge different excel files, fix missing values, etc.). Then it&#8217;s time for an exploratory analysis to better understand what you&#8217;re dealing with. Depending on the type of data, you might also need to extract appropriate features or maybe engineer additional ones (for which domain knowledge will be very helpful). All these steps are grouped under "preprocessing" <em>(red box)</em> and the bubbles are arranged in zigzag, because often you find yourself jumping back and forth between these steps (e.g., by visualizing the dataset, you might realize that you have some outliers that you want to remove, or after engineering new features, you go back and visualize the dataset again). Next comes the ML part <em>(green box)</em>: you&#8217;ll probably start with some simple model, evaluate it, try a more complex model, experiment with different hyperparameters, &#8230;&#8203; and at some point realize, that you&#8217;ve exhausted your ML toolbox and are still not happy with the performance. This means you need to go back and either engineer better features or, if this also doesn&#8217;t help, even collect more and/or better data (e.g., more samples, data from additional sensors, cleaner labels, etc.). Finally, when you&#8217;re confident in the model&#8217;s predictions, there are two routes you might take: either the data science route, where you communicate your findings to the stakeholders (which will most likely result in further questions), or the ML-software route, where the final model is deployed somewhere in production (where you mustn&#8217;t forget to monitor the model&#8217;s performance and collect new data such that the model can continuously be improved, especially as the inevitable data or concept drifts occur). Working on a machine learning project is a very iterative process.</span></div>
</div>
<div class="paragraph">
<p>Unfortunately, due to a lack of standardized data infrastructure in most companies, the sad truth is that usually (at least) about 90% of a Data Scientist&#8217;s time will be spent collecting, cleaning, and otherwise preprocessing the data to get it into a format where the ML algorithms can be applied:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ds_workflow/data_science_workflow_19.png" alt="image" width="840">
</div>
</div>
<div class="paragraph">
<p>While sometimes frustrating, the time spent cleaning and preprocessing your data is never wasted, as only with a solid data foundation the ML algorithms can achieve decent results.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ml_with_python">ML with Python</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <a href="https://github.com/cod3licious/ml_exercises">exercises</a> accompanying this book are using the programming language Python.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Why Python?</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>free &amp; open source (unlike, e.g., MatLab)</p>
</li>
<li>
<p>easy; fast prototyping</p>
</li>
<li>
<p>general purpose language (unlike, e.g., R): easy to incorporate ML into regular applications or web apps</p>
</li>
<li>
<p>fast: many numerical operations are backed with C libraries</p>
</li>
<li>
<p>a lot of <strong>open source ML libraries</strong> with a very active community!!!</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">How?</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>regular scripts (i.e., normal text files ending in <code>.py</code>), especially useful for function definitions that you might reuse in different projects</p>
</li>
<li>
<p>iPython shell: interactive console to execute code</p>
</li>
<li>
<p>Jupyter Notebooks (i.e., special files ending in <code>.ipynb</code>): great for experimenting &amp; sharing work with others (also works with other programming languages: Jupyter stands for Julia, Python, and R; you can even mix languages in the same notebook)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>If you&#8217;re unfamiliar with Python, have a look at <a href="https://github.com/cod3licious/python_tutorial"><strong>this Python tutorial</strong></a> specifically written to teach you the basics needed for the examples in this book. This <a href="https://github.com/cod3licious/ml_exercises/blob/main/other/cheatsheet.pdf">cheat sheet</a> additionally provides a summary of the most important steps when developing a machine learning solution, incl. code snippets using the libraries mentioned below.</p>
</div>
<div class="paragraph lead">
<p><strong>Overview of Python Libraries for ML</strong></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The libraries are always imported with specific abbreviations (e.g., <code>np</code> or <code>pd</code>). It is highly recommended that you stick to these conventions and you will also see this in many code examples online (e.g., on StackOverflow).
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a href="https://numpy.org/"><code><strong>numpy</strong></code></a> (&amp; <a href="https://www.scipy.org/"><code><strong>scipy</strong></code></a>)</dt>
<dd>
<p>everything needed for scientific computing, incl. random numbers, linear algebra, basic statistics, and optimization. The main data structure to represent vectors and matrices is the numpy array (e.g., <code>np.array([1,2])</code>).</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">  <span class="keyword">import</span> <span class="include">numpy</span> <span class="keyword">as</span> np</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a href="https://pandas.pydata.org/"><code><strong>pandas</strong></code></a></dt>
<dd>
<p>higher level data manipulation with data stored in a <code>DataFrame</code> table similar to R; very useful for loading data, cleaning, and some exploration with different plots</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">  <span class="keyword">import</span> <span class="include">pandas</span> <span class="keyword">as</span> pd</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a href="https://matplotlib.org/"><code><strong>matplotlib</strong></code></a></dt>
<dd>
<p>create plots (e.g., <code>plt.plot()</code>, <code>plt.scatter()</code>, <code>plt.imshow()</code>)</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">  <span class="keyword">import</span> <span class="include">matplotlib.pyplot</span> <span class="keyword">as</span> plt</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a href="https://plotly.com/"><code><strong>plotly</strong></code></a></dt>
<dd>
<p>create interactive plots (e.g., <code>px.parallel_coordinates()</code>)</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">  <span class="keyword">import</span> <span class="include">plotly.express</span> <span class="keyword">as</span> px</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a href="https://scikit-learn.org/stable/"><code><strong>scikit-learn</strong></code></a></dt>
<dd>
<p>includes a lot of (non-deep learning) machine learning algorithms, preprocessing tools, and evaluation functions with a <em>unified interface</em>, i.e., all models (depending on their type) will have these <code>.fit()</code>, <code>.transform()</code>, and/or <code>.predict()</code> methods, which makes it very easy to switch out models in the code by just changing the line where the model was initialized</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">  <span class="comment"># import the model class from the specific submodule</span>
  <span class="keyword">from</span> <span class="include">sklearn.xxx</span> <span class="keyword">import</span> <span class="include">Model</span>
  <span class="keyword">from</span> <span class="include">sklearn.metrics</span> <span class="keyword">import</span> <span class="include">accuracy_score</span>

  <span class="comment"># initialize the model (usually you also set some parameters here)</span>
  model = Model()

  <span class="comment"># preprocessing/unsupervised learning methods:</span>
  model.fit(X)  <span class="comment"># only pass feature matrix X</span>
  X_transformed = model.transform(X)  <span class="comment"># e.g., the StandardScaler would return a scaled feature matrix</span>

  <span class="comment"># supervised learning methods:</span>
  model.fit(X, y)  <span class="comment"># pass features and labels for training</span>
  y_pred = model.predict(X_test)  <span class="comment"># generate predictions for new points</span>
  <span class="comment"># evaluate the model (the internal score function uses the model's prefered evaluation metric)</span>
  print(<span class="string"><span class="delimiter">&quot;</span><span class="content">The model is this good:</span><span class="delimiter">&quot;</span></span>, model.score(X_test, y_test))  <span class="comment"># .score() internally calls .predict()</span>
  print(<span class="string"><span class="delimiter">&quot;</span><span class="content">Equivalently:</span><span class="delimiter">&quot;</span></span>, accuracy_score(y_test, y_pred))</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1"><a href="https://pytorch.org/"><code><strong>torch</strong></code></a> (or <a href="https://keras.io/"><code><strong>keras</strong></code></a>)</dt>
<dd>
<p>neural network models (more details on these libraries in the section on neural networks)</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">   <span class="keyword">import</span> <span class="include">torch</span>
  (<span class="keyword">import</span> <span class="include">keras</span>)</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Additional useful Natural Language Processing (NLP) libraries: </dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><a href="https://spacy.io/"><code>spacy</code></a> (modern &amp; fast NLP tools)</p>
</li>
<li>
<p><a href="https://www.nltk.org/"><code>nltk</code></a> (traditional NLP tools)</p>
</li>
<li>
<p><a href="https://radimrehurek.com/gensim/"><code>gensim</code></a> (topic modeling)</p>
</li>
<li>
<p><a href="https://huggingface.co/"><code>transformers</code></a> (pre-trained neural network models for different tasks)</p>
</li>
<li>
<p><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/"><code>beautifulsoup</code></a> (parsing websites)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_data_preprocessing">Data &amp; Preprocessing</h2>
<div class="sectionbody">
<div class="paragraph">
<p>As we&#8217;ve seen, ML algorithms solve input-output tasks and to solve a ML problem, you first need to collect data. Preprocessing is the act of transforming raw data in such a way that ML algorithms can be applied:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ds_workflow/data_science_workflow_prepr.png" alt="image" width="840">
</div>
</div>
<div class="paragraph">
<p>For example, a production process, where you want to predict whether a produced part will be scrap given certain production conditions, would be a typical supervised learning problem. Here, the collected data for each produced part should include the process conditions under which it was produced, as well as the outcome (i.e., product was okay or scrap):</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/02_data/toy_data3.png" alt="image" width="740">
</div>
<div class="title"><span class="small">The data collected for this use case is structured data in a tabular form (e.g., in an excel sheet). One data point / sample / observation is always in one row of this table.</span></div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/02_data/toy_data6.png" alt="image" width="740">
</div>
<div class="title"><span class="small">The columns of the table contain the different measurements / variables that were collected for each sample. Here we distinguish between <em>features</em> (in this case the production conditions) and <em>labels</em> (whether the product produced under these conditions was okay or scrap). Features, also denoted as a matrix \(X\), are typically those measurements that we get basically for free, as they are often collected during the process for other purposes anyways (e.g., when the operator of the machine sets the temperature for the production to a certain value, this is recorded as the signal is passed along to the heating unit). The corresponding labels, denoted as a vector \(\mathbf{y}\), are often more expensive to collect. (For example, in the production process, to collect a data point with the label <em>"scrap"</em>, we have to (intentionally) produce a broken product that we can&#8217;t sell afterwards, costing us valuable resources. Another example would be when Google paid a team of specialist doctors to discuss and re-label some of the diabetic retinopathy images about which there existed conflicting opinions.) In the supervised learning setup, the features are used as the input to the model, while the labels constitute the target variable, i.e., the predicted output. Generally, features should be independent variables (e.g., settings that the operator can choose as he wishes), while the target value should be dependent on these inputs.</span></div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Structured vs. unstructured data</dt>
<dd>
<p>Data can come in various forms and while some data types might require additional preprocessing steps, in principle ML algorithms can be used with all kinds of data.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/02_data/data_types2.png" alt="image" width="640">
</div>
<div class="title"><span class="small">The main distinction that is made when characterizing data is between <em>structured</em> data, which is any dataset that contains individual variables that represent unique quantities, and <em>unstructured</em> data, which can not be subdivided into meaningful variables, e.g., in images &#8220;first pixel from the left&#8221; or in texts &#8220;10th word in the second paragraph&#8221; is not what you would call a variable, while &#8220;size in square meters&#8221; and &#8220;number of bedrooms&#8221; would be useful quantities to describe an apartment. Structured data is often heterogeneous, since the different variables in a dataset typically stand for very different things (e.g., when working with sensor data you normally would not have a dataset that only contains temperature measurements, but additionally it might contain, e.g., pressure and flow values, which have different units and might be on very different scales). Unstructured data, on the other hand, is homogeneous (i.e., there is no qualitative difference between the 10th and the 100th pixel in an image).</span></div>
</div>
</dd>
</dl>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Raw Data</dt>
<dd>
<p>can come in many different forms, e.g., sensor measurements, pixel values, text (e.g., HTML page), SAP database, &#8230;&#8203;<br>
&#8594; <em>n</em> data points, stored as rows in an excel sheet, as individual files, etc.</p>
</dd>
<dt class="hdlist1">Preprocessing</dt>
<dd>
<p>transforming and enriching the raw data before applying ML, for example:</p>
<div class="ulist">
<ul>
<li>
<p>feature extraction: transform into numerical values (e.g., unstructured data like text)</p>
</li>
<li>
<p>remove / correct missing or wrongly entered data (e.g., when someone misplaced the decimal point)</p>
</li>
<li>
<p>exclude zero variance features (i.e., variables with always the same value) and nonsensical variables (e.g., IDs)</p>
</li>
<li>
<p>feature engineering: compute additional/better features from the original variables</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>&#8658; <strong><em>feature matrix</em></strong> \(X \in \mathbb{R}^{n\times d}\): <em>n</em> data points; each represented as a <em>d</em>-dimensional vector (i.e., with <em>d</em> features)<br>
<span class="small">Please note that, in general, it is important that all samples in a dataset are represented as the same kind of fixed-length vectors. E.g., if the first position (i.e., feature) in the vector of one sample represents the temperature at which a product was produced, then the first position in the feature vector of another sample can not be this product&#8217;s height. This is critical, because most ML models learn some kind of weights that act on the individual features and if these would always be at different positions (or missing for some data points), then the algorithm would not be able to apply the correct weight to the respective feature.</span></p>
</div>
</dd>
<dt class="hdlist1">Prediction Targets?</dt>
<dd>
<p>&#8594; <strong><em>label vector</em></strong> \(\mathbf{y}\) : <em>n</em>-dimensional vector with one target value per data point</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_what_constitutes_1_data_point">What constitutes 1 data point?</h3>
<div class="paragraph">
<p>It&#8217;s always important to be really clear about what 1 data point actually is, i.e., what the inputs look like and what you want back as a result from the model for each sample / observation. Think of this in terms of how you plan to integrate the ML model with the rest of your workflow: what is the data that is produced in the previous step and flows into the ML part, and what do you need as an output from the model for the following step?</p>
</div>
<div class="paragraph">
<p>Even given the same raw data, depending on what you want to do, the <strong>definition of &#8216;1 data point&#8217;</strong> might be quite different.
For example, when dealing with time series data, <strong>the raw data might always be in the form &#8216;<em>n</em> time points with measurements from <em>d</em> sensors&#8217;</strong>, but depending on the type of question you are trying to answer, the actual feature matrix can look quite different:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">1 Data Point = 1 Time Point</dt>
<dd>
<p>e.g., anomaly detection (&#8594; determine for each time point if everything is normal or if there is something strange going on):</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_timeseries/timeseries1.png" alt="image" width="660">
</div>
</div>
<div class="paragraph">
<p>&#8594; \(X\): <em>n</em> time points \(\times\) <em>d</em> sensors, i.e., <em>n</em> data points represented as <em>d</em>-dimensional feature vectors</p>
</div>
</dd>
<dt class="hdlist1">1 Data Point = 1 Time Series</dt>
<dd>
<p>e.g., cluster sensors (&#8594; see if some sensors measure related things):</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_timeseries/timeseries3.png" alt="image" width="660">
</div>
</div>
<div class="paragraph">
<p>&#8594; \(X\): <em>d</em> sensors \(\times\) <em>n</em> time points, i.e., <em>d</em> data points represented as <em>n</em>-dimensional feature vectors</p>
</div>
</dd>
<dt class="hdlist1">1 Data Point = 1 Time Interval</dt>
<dd>
<p>e.g., classify time segments (&#8594; products are being produced one after another, some take longer to produce than others, and the task is to predict whether a product produced during one time window at the end meets the quality standards, i.e., we&#8217;re not interested in the process over time per se, but instead regard each produced product (and therefore each interval) as an independent data point):</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_timeseries/timeseries2.png" alt="image" width="660">
</div>
</div>
<div class="paragraph">
<p>&#8594; Data points always need to be represented as fixed-length feature vectors, where each dimension stands for a specific input variable. Since the intervals here have different lengths, we can&#8217;t just represent one product as the concatenation of all the sensor measurements collected during its production time interval, since these vectors would not be comparable for the different products. Instead, you could compute features for each time segment by aggregating the sensor measurements over the interval (e.g., min, max, mean, slope, &#8230;&#8203;)<br>
&#8594; \(X\): <em>k</em> intervals \(\times\) <em>q</em> features (derived from the <em>d</em> sensors), i.e., <em>k</em> data points represented as <em>q</em>-dimensional feature vectors</p>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_feature_extraction">Feature Extraction</h3>
<div class="paragraph">
<p>Machine learning algorithms only work with numbers. If your data does not consist of numerical values (e.g., text documents) or these numerical values should not be interpreted as such (e.g., sports players have numbers on their jerseys, but these numbers don&#8217;t mean anything in a numeric sense (e.g., higher numbers don&#8217;t mean the person scored more goals), they are merely IDs), then this data needs to be transformed accordingly, i.e., numerical features need to be extracted from the original data. (Statisticians distinguish here between nominal, ordinal, interval, and ratio data, but for simplicity we lump the first two together as categorical data, while the other two are considered meaningful numerical values.)</p>
</div>
<div class="paragraph">
<p><strong>Transforming raw data into <em>meaningful</em> numerical features:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p><span class="underline">categorical features:</span>  <strong>1-hot encoding</strong> (= creating dummy variables that enable the model to introduce a different offset for each category)<br>
For example, we might have 4 product categories <code>circle</code>, <code>triangle</code>, <code>square</code>, and <code>pentagon</code>, where each data point (representing a product) falls into exactly one of these categories. This means, we could create four features, <code>is_circle</code>, <code>is_triangle</code>, <code>is_square</code>, and <code>is_pentagon</code>, and indicate a data point&#8217;s product category using a binary flag, i.e., a value of 1 at the index of the true category and 0 everywhere else:<br>
e.g., product category: <code>triangle</code> &#8658; <code>[0, 1, 0, 0]</code><br></p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.preprocessing</span> <span class="keyword">import</span> <span class="include">OneHotEncoder</span></code></pre>
</div>
</div>
</li>
<li>
<p><span class="underline">text documents:</span> <strong>Bag-of-Words (BOW) TF-IDF features:</strong><br>
Represent a document as the weighted counts of the words occurring in the text:<br></p>
<div class="ulist">
<ul>
<li>
<p><em>Term Frequency</em> (TF): how often does this word occur in the current text document</p>
</li>
<li>
<p><em>Inverse Document Frequency</em> (IDF): a weight to capture how significant this word is. This is computed by comparing the total number of documents in the dataset to the number of documents in which the word occurs. The IDF weight thereby reduces the overall influence of words that occur in almost all documents (e.g., so-called stopwords like &#8216;and&#8217;, &#8216;the&#8217;, &#8216;a&#8217;, &#8230;&#8203;)</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_nlp/tfidf6.png" alt="image" width="500">
</div>
</div>
<div class="paragraph">
<p>&#8594; First, the whole <em>corpus</em> (= a dataset consisting of text documents) is processed once to determine the overall vocabulary (i.e., the unique words occurring in all documents that then make up the dimensionality of the BOW feature vector) and to compute the IDF weights for all words. Then each individual document is processed to compute the final TF-IDF vector. (Please note that in the picture above, the feature vector is shown as a column vector, but later each document will be one data point, i.e., one row in the feature matrix \(X\), while the TF-IDF values for the individual words are the features in the columns.)<br></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.feature_extraction.text</span> <span class="keyword">import</span> <span class="include">TfidfVectorizer</span></code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Disadvantages of TF-IDF vectors</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>similarity between individual words (e.g., synonyms) is not captured, since each word has its own distinct dimension in the feature vector and is therefore equally far away from all other words</p>
</li>
<li>
<p>word order is ignored (this is also where the name &#8220;bag of words&#8221; comes from, i.e., imagine all the words from a document are thrown into a bag and shook and then you just check how often each word occurred in the text)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_feature_engineering_transformations">Feature Engineering &amp; Transformations</h3>
<div class="paragraph">
<p>Often it is very helpful to not just use your original features as is, but to compute new, more informative features from them (what is also called feature engineering). Additionally, you should also check the distributions of the individual variables (e.g., by plotting a histogram) to see if the features are approximately <a href="https://en.wikipedia.org/wiki/Normal_distribution">normally distributed</a> (which is an assumption of most ML models).</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Generate additional features (i.e., feature engineering)</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>In general: e.g., product/ratio of 2 variables (e.g., compute a new feature that contains the ratio of the temperature inside your machine to the temperature outside in the room)<br>
&#8594; <a href="https://github.com/cod3licious/autofeat"><code>autofeat</code> library</a> <span class="small">(<em>Disclaimer:</em> written by yours truly.)</span></p>
</li>
<li>
<p>Relational data: e.g., aggregations across tables (for example, in a database you might have one table that contains all your customers and another table that contains all transactions and you want to compute a feature that shows the total volume of sales for each customer, i.e., the sum of the transactions grouped by customers)<br>
&#8594; <a href="https://www.featuretools.com/"><code>featuretools</code> library</a></p>
</li>
<li>
<p>Time series data: e.g., min/max/average over time intervals<br>
&#8594; <a href="https://tsfresh.readthedocs.io/en/latest/"><code>tsfresh</code> library</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>&#8658; Domain knowledge is invaluable here&#8201;&#8212;&#8201;instead of blindly computing hundreds of additional features, ask a domain expert which derived values she thinks might be the most helpful for the problem you&#8217;re trying to solve!</p>
</div>
</dd>
<dt class="hdlist1">Aim for normally/uniformly distributed features</dt>
<dd>
<p>especially important for heterogeneous data (e.g., different kinds of sensors with different scales, like a temperature between 100 and 500 degrees and a pressure sensor that measures values between 1.1 and 1.8 bar &#8594; the ML model only sees the values and does not know about the different units)</p>
<div class="openblock">
<div class="content">
<div class="ulist">
<ul>
<li>
<p>for each feature: subtract mean &amp; divide by standard deviation (i.e., transform arbitrary Gaussian distribution into a normal distribution)</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.preprocessing</span> <span class="keyword">import</span> <span class="include">StandardScaler</span></code></pre>
</div>
</div>
</li>
<li>
<p>for each feature: scale between 0 and 1</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.preprocessing</span> <span class="keyword">import</span> <span class="include">MinMaxScaler</span></code></pre>
</div>
</div>
</li>
<li>
<p>map to Gaussian distribution (e.g., take log/sqrt if the feature shows a skewed distribution with a few extremely large values)</p>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.preprocessing</span> <span class="keyword">import</span> <span class="include">PowerTransformer</span></code></pre>
</div>
</div>
</li>
</ul>
</div>
</div>
</div>
</dd>
</dl>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Not using (approximately) normally distributed data is a very common mistake!</strong></p>
</div>
<div class="paragraph text-center">
<p><span class="image"><img src="images/02_data/tsne_original.png" alt="image" width="270"></span>
<span class="image"><img src="images/02_data/tsne_standardized.png" alt="image" width="270"></span>
<span class="image"><img src="images/02_data/tsne_powertrans.png" alt="image" width="270"></span><br>
<span class="small">2D visualization created with t-SNE (&#8594; see section on dimensionality reduction) of the same dataset (each dot is one data point where the color denotes the point&#8217;s class), first using the original feature vectors, then on standardized data, and lastly after applying a power transformation.</span></p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_computing_similarities">Computing Similarities</h3>
<div class="paragraph">
<p>Many ML algorithms rely on similarities or distances between data points, computed with measures such as:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://en.wikipedia.org/wiki/Euclidean_distance">Euclidean distance</a></p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Cosine_similarity">Cosine similarity</a> (e.g., when working with text data)</p>
</li>
<li>
<p>Similarity coefficients (e.g., <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard index</a>)</p>
</li>
<li>
<p>&#8230;&#8203; and many more</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.metrics.pairwise</span> <span class="keyword">import</span> ...</code></pre>
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Which feature should have how much influence on the similarity between points? &#8594; Domain knowledge!
</td>
</tr>
</table>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8658; scale / normalize heterogeneous data (e.g., a pressure difference between 1.1 and 1.8 bar might be more dramatic in the process than a temperature difference between 200 and 250 degrees, but if you compute the distance using the unscaled values, the difference in temperature would completely overshadow the difference in pressure)</p>
</li>
<li>
<p>&#8658; exclude redundant / strongly correlated features (otherwise they count twice towards the distance)</p>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Example: Computing similarities between texts (represented as TF-IDF vectors) with the <em>cosine similarity</em></dt>
<dd>
<p>Scalar product (&#8594; <code>linear_kernel</code>) of length normalized TF-IDF vectors:</p>
<div class="stemblock">
<div class="content">
\[sim(\mathbf{x}_i, \mathbf{x}_j) = \frac{\mathbf{x}_i^\top \mathbf{x}_j}{\|\mathbf{x}_i\| \|\mathbf{x}_j\|} \quad \in [-1, 1]\]
</div>
</div>
<div class="paragraph">
<p>i.e., the cosine of the angle between the length-normalized vectors:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_nlp/cosine_sim.png" alt="image" width="640">
</div>
</div>
<div class="paragraph">
<p>&#8594; similarity score is between [0, 1] for TF-IDF vectors, since all entries in the vectors are positive</p>
</div>
</dd>
</dl>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Food for thought: Human vs. TF-IDF + Cosine Similarity understanding</dt>
</dl>
</div>
<div class="paragraph text-center">
<p><em>The hotel was great, but the weather was bad.</em><br>
vs.<br>
<em>The weather was great, but the hotel was bad.</em><br>
vs.<br>
<em>The accommodation was wonderful, but it was raining all day.</em></p>
</div>
<div class="paragraph">
<p>For which of the above sentences would you say that they mean something similar?<br>
Which sentence pairs would be assigned a high or lower similarity score when they are represented as TF-IDF vectors and the similarity is computed with the cosine similarity?</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_garbage_in_garbage_out">Garbage in, garbage out!</h3>
<div class="paragraph">
<p>Remember: data is your raw material when producing something valuable with ML. If the quality or quantity of the data is insufficient, you are facing a &#8220;garbage in, garbage out&#8221; scenario and no matter what kind of fancy ML algorithm you might try, you wont get a satisfactory result (actually, the fancier the algorithm (e.g., deep learning), the more data you need).</p>
</div>
<div class="paragraph">
<p>Below you find a summary of some common risks associated with data that can make it complicated or even impossible to apply ML:</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Raw data can be very messy: </dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Relevant data might be spread across multiple databases / excel sheets that need to be joined. <em>Worst case:</em> data points don&#8217;t have a single ID based on which the different entries can be linked, but instead one has to fall back on some error prone strategy like matching data based on time stamps.</p>
</li>
<li>
<p>Manually entered values can contain errors, e.g., misplaced decimal points.</p>
</li>
<li>
<p>It might not be possible to correct missing values. <em>Worst case:</em> missing values are not random, e.g., in surveys, rich people more often decline to answer questions regarding their income compared to poor or middle class people; sensors might fail right before something goes wrong during the production process.</p>
</li>
<li>
<p>Dataset might consist of different data types (structured and/or unstructured) with different scales.</p>
</li>
<li>
<p>The process might have changed over time (e.g., due to some external conditions like replacing a sensor or some other maintenance event), which means the collected data from different time periods is incompatible. <em>Worst case:</em> these external changes were not recorded anywhere and you only notice at the end of the analysis that the data you had been working with violated your assumptions.</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>&#8594; Pre-processing takes a very long time<br>
&#8594; Resulting dataset (after cleaning) might be a lot smaller than expected&#8201;&#8212;&#8201;possibly too small to do any meaningful analysis</p>
</div>
<div class="paragraph">
<p>&#8658; Before wanting to do ML, first think about if your data collection pipeline &amp; infrastructure could be improved!</p>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Not enough / not the right data to do ML: </dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Small dataset and/or too little variation (e.g., you only produce very few broken products or most of the time a process runs in a steady state, i.e., there is little or no variation in the inputs)<br>
&#8594; Effect of different input variables on the target can&#8217;t be estimated reliably from only very few observations<br>
&#8658; Do some experiments where you systematically vary different inputs and collect a more diverse dataset</p>
</li>
<li>
<p>Data is inconsistent / incomplete (e.g., same inputs with different output)</p>
<div class="ulist">
<ul>
<li>
<p>either the labels are very noisy, e.g., because the human annotators didn&#8217;t follow the same set of clear rules / some examples were ambiguous<br>
&#8658; clean up the data by relabeling (which can take some time but will pay off!&#8201;&#8212;&#8201;see also this <a href="https://youtu.be/06-AZXmwHjo">MLOps / data-centric AI talk by Andrew Ng</a> on how a small high-quality dataset can be more valuable than a larger noisy dataset)</p>
</li>
<li>
<p>or because some relevant input features are missing (&#8594; while it is relatively easy for humans to assess if all the relevant information is present in unstructured data (e.g., images: either you see a cat or you don&#8217;t), structured data often has too many different variables and complex interactions to know right away if all the relevant features were included)<br>
&#8658; talk to a domain expert about which additional input features might be helpful and should be included in the dataset. <em>Worst case:</em> need to install a new sensor in the machine and collect this data, i.e., all the data collected in the past is basically useless. BUT: using the right sensor can simplify the problem immensely and installing it will be worth it!<br>
<span class="small">In many applications, our first instinct might be to use a camera to generate the input data, since we humans rely primarily on our visual system to solve many tasks. However, even though image recognition algorithms have come a long way, using such a setup instead of a more specialized sensor can make the solution more error prone.<br>
Trying to detect mushy strawberries? Use a near infrared (NIR) sensor instead of a camera like <a href="https://www.aboutamazon.co.uk/innovation/machine-learning-using-algorithms-to-sort-fruit">Amazon fresh</a> did. They still use machine learning to analyze the resulting data, but in the NIR images the rotting parts of fruits are more easily visible than in normal photos.<br>
Trying to detect if a door is closed? With a simple <a href="https://www.deeplearning.ai/the-batch/issue-92/">magnet</a> and detector, this task can easily be solved without a complex analysis or training data! (You know the famous saying: &#8220;When you have a hammer, everything looks like a nail&#8221;. &#8594; Don&#8217;t forget to also consider solutions outside your ML toolbox! ;-))</span></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>&#8594; Unless the dataset is amended accordingly, any ML model will have a poor performance!</p>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you can, observe how the data is being collected. As in: actually physically stand there and watch how someone enters the values in some program or how the machine operates as the sensors measure something. You will probably notice some things that can be optimized in the data collection process directly, which might save you lots of preprocessing work in the future.
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Best Practice: Data Catalog</dt>
<dd>
<p>For each variable (in structured data) you should always have information available like:</p>
<div class="ulist">
<ul>
<li>
<p>Name of the variable</p>
</li>
<li>
<p>Description</p>
</li>
<li>
<p>Units</p>
</li>
<li>
<p>Data type (e.g., numerical or categorical values)</p>
</li>
<li>
<p>Date since when this variable is being recorded</p>
</li>
<li>
<p>Normal/expected range of values (&#8594; &#8220;if this variable is below this threshold, then the machine is off and the data points can be ignored&#8221;)</p>
</li>
<li>
<p>How missing values are recorded (i.e., are they actually recorded as missing values or substituted by some unrealistic value instead, which can happen since some sensors are not able to send a signal for NaN directly or the database might not allow the field to be empty)</p>
</li>
<li>
<p>Notes on anything else you should be aware of, e.g., a sensor malfunctioning during a certain period of time or some other glitch that resulted in incorrect data (which can sometimes be difficult to spot, for example, if someone instead manually entered or copy &amp; pasted values from somewhere, which might not look conspicuous at first glance)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Data as an Asset</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/02_data/data_asset.png" alt="image" width="600">
</div>
<div class="title"><span class="small">How to get from "garbage in, garbage out" to "data is the new oil".</span></div>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">With (big) data comes great responsibility!</dt>
<dd>
<p>Some data might not seem very valuable to you, but might still be a huge asset for others (i.e., with a different use case)!</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/09_ml_in_practice/data_responsibility.png" alt="image" width="540">
</div>
<div class="title"><span class="small">A fitness tracker startup thought it would be a cool idea to publish popular jogging routes based on the data they&#8217;ve collected from their users. However, since many US soldiers also happened to use the tracker and frequently jogged around their army bases, this startup thereby accidentally outed a secret army base in Afghanistan, which appeared as a bright spot on their interactive map in an area where they otherwise had only few users. So even if your data looks harmless at first glance, please do think about what could go wrong in case you publish it (even in an aggregated, anonymized form)!</span></div>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ml_solutions_overview">ML Solutions: Overview</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now that you&#8217;ve seen how to preprocess some raw data to get it in the right format to apply ML, let&#8217;s move on to the fun part:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ds_workflow/data_science_workflow_ml.png" alt="image" width="840">
</div>
</div>
<div class="paragraph">
<p>The inputs that the ML algorithms operate on can come in many forms, but your goal, i.e., the desired outputs, determines the type of algorithm you should use for the task:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/ml_goals3.png" alt="image" width="840">
</div>
<div class="title"><span class="small">If your goal is to simply understand your dataset a bit better and get an overview of it, then a dimensionality reduction algorithm from the area of unsupervised learning can be used to create a visualization of the dataset. If you want to discover patterns in the data, then you would also choose an algorithm from the field of unsupervised learning, but here it depends on which kinds of patterns you want to find: anomaly detection algorithms can be used to identify individual data points that deviate a lot from the rest (e.g., a malfunctioning machine or a fraudulent credit card transaction), while clustering algorithms can be used to identify groups of similar data points (e.g., for customer segmentation). If your goal is to make specific predictions, i.e., given an input get a corresponding output (e.g., predict whether a product will be faulty if it is produced under certain conditions), then you need to use an algorithm from the area of supervised learning. Here the main distinction is made between regression and classification models: in regression tasks, the target variable that should be predicted is continuous (e.g., number of users, price, etc.), while in classification tasks the target variable is discrete, i.e., can only take on one distinct value and there is no continuum between the different values (e.g., an animal in a picture can either be a cat or a dog, but not something in between). While unsupervised and supervised learning cover most general use cases, there are also other algorithms for more specific applications, e.g., recommender systems.</span></div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Unsupervised &amp; Supervised Learning</dt>
<dd>
<p>Let&#8217;s start with a more detailed look at the different unsupervised &amp; supervised learning algorithms and what they can help you with:</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ml_overview/ml_algorithms_12.png" alt="image" width="840">
</div>
<div class="title"><span class="small">When you want to apply unsupervised learning algorithms, having a feature matrix \(X\) is enough, while to learn a prediction model with supervised learning algorithms, you also need the corresponding labels \(\mathbf{y}\). Even if your ultimate goal is to predict something (i.e., do supervised learning), it can still be very helpful to first use unsupervised learning to get a better understanding of your dataset, for example, by visualizing your data with dimensionality reduction methods to see all samples and their diversity at a glance, by identifying outliers to clean the dataset, or, if you have a classification problem, by first clustering the samples to check if the given class labels match the naturally occurring groups in the data (e.g., maybe it might be helpful to combine two very similar classes to simplify the problem).</span></div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Same dataset, different use cases</dt>
<dd>
<p>To illustrate the usefulness of the 5 different types of unsupervised and supervised learning algorithms, lets apply them to this small example dataset:</p>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2858%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-center valign-top">m<sup>2</sup></th>
<th class="tableblock halign-center valign-top"># Bedr</th>
<th class="tableblock halign-center valign-top"># Bath</th>
<th class="tableblock halign-center valign-top">Renovated</th>
<th class="tableblock halign-center valign-top">&#8230;&#8203;</th>
<th class="tableblock halign-center valign-top">Price</th>
<th class="tableblock halign-center valign-top">Sold</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">125</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">4</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2000</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">500k</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">75</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">1990</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">350k</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">150</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">6</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2010</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">750k</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">0</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">35</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">5</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">1999</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">620k</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">0</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">65</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2015</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">220k</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-center valign-top"><p class="tableblock">100</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">3</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">1</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">2003</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">&#8230;&#8203;</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">450k</p></td>
<td class="tableblock halign-center valign-top"><p class="tableblock">0</p></td>
</tr>
</tbody>
</table>
</dd>
</dl>
</div>
<div class="paragraph text-justify">
<p><span class="small">This is a small toy example dataset with structured data about different apartments, which someone might have gathered from a real estate website, i.e., the size of the apartment in square meters, the number of bedrooms, the number of bathrooms, the year it was last renovated, and finally the price of the listing as well as whether it was sold for this price (1) or not (0).</span></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Example Unsupervised Learning: Dimensionality Reduction</dt>
<dd>
<p><strong>Goal:</strong> Visualize the dataset</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_housing_example/dimred.png" alt="image" width="840">
</div>
<div class="title"><span class="small">The first step when working with a new dataset is usually to visualize it, to get a better overview of all the samples and their diversity. This can be done with a dimensionality reduction algorithm, which takes the original high dimensional data as input (i.e., where each column in the table would be one dimension) and outputs a lower dimensional representation of the samples, i.e., a new matrix with fewer columns (generally 2 for a visualization). These two new features, in our case here called \(z_1\) and \(z_2\), can now be used to create a scatter plot of the dataset (i.e., where each sample / row (in this case each apartment) is represented as one point using this new 2D coordinate system). You can think of this plot as a map of your dataset, that enables you to view all data points at a glance and where you can often see interesting patterns, for example, groups of similar points, which would be arranged close to each other in this 2D map. Please note that for most dimensionality reduction methods, it is not possible to describe what is behind this new coordinate system, specifically, these are not just the two most informative original features, but really completely new dimensions that summarize the information of the original inputs. To better interpret these plots, it is often helpful to color the dots afterwards by some variable, which can then reveal the driving factors behind the most salient patterns in the dataset (e.g., in this example we could have used the price of each apartment to color the respective dot in the map, which might then reveal that similarly priced apartments are arranged next to each other).</span></div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Example Unsupervised Learning: Anomaly Detection</dt>
<dd>
<p><strong>Goal:</strong> Find outliers in the dataset</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_housing_example/anomaly.png" alt="image" width="840">
</div>
<div class="title"><span class="small">In the next step, you would usually check your dataset for outliers (to then subsequently correct or remove these samples). An outlier detection algorithm outputs for each sample an anomaly score, which indicates whether this data point deviates from the norm. You can also use these scores then to colorize the 2D map of your dataset you generated in the previous step to see the anomalies in context. One drawback is that an anomaly detection algorithm does not tell you <em>why</em> it considers an individual point an outlier, i.e., you as a data scientist then need to examine the points identified as outlier to see, e.g., if these should be removed due to flawed measurements or if they constitute some interesting edge cases. In this toy example, the sample identified as an anomaly is an apartment that supposedly has a size of only \(35 m^2\), but at the same time 5 bedrooms, i.e., here most likely the person that originally entered the data made a mistake and the size of the listing should actually be 135.</span></div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Example Unsupervised Learning: Clustering</dt>
<dd>
<p><strong>Goal:</strong> Find naturally occurring groups in the dataset</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_housing_example/clustering.png" alt="image" width="840">
</div>
<div class="title"><span class="small">Additionally, you might also want to check if the dataset contains naturally occurring groups. This can be accomplished with a clustering algorithm, which returns a cluster index for each sample, where points with the same index are in the same cluster. Please note that these cluster indices are not ordered and when running the algorithm again, the samples might be assigned different numbers, however, the groups of samples that were assigned the same number should still be in a cluster together, i.e., this cluster might now just be called &#8216;5&#8217; instead of &#8216;3&#8217;. Again you can use these cluster indices to colorize the 2D map of your dataset that you got from applying a dimensionality reduction method to see the clusters in context. While a clustering algorithm groups similar points together, it again does not tell you <em>why</em> the points were assigned to a cluster and what this cluster means, i.e., again you as a data scientist now need to examine the results to try to describe the different clusters (e.g., in our toy example, the clusters might be &#8220;cheap studio apartments&#8221;, &#8220;large family apartments&#8221;, and &#8220;luxurious penthouses&#8221;).</span></div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Example Supervised Learning: Classification</dt>
<dd>
<p><strong>Goal:</strong> Predict a discrete value for each data point</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_housing_example/classification.png" alt="image" width="840">
</div>
<div class="title"><span class="small">Next, you might decide that you want to predict whether an apartment will be sold for the listed price. Since the variable &#8220;sold&#8221; can only take on discrete values (i.e., yes (1) or no (0)), this is a classification problem. A classification model would then use the attributes of an apartment together with the listing&#8217;s price as an input and predict whether the apartment will be sold for this price. Since we also have the true labels available (at least for the initial dataset that we had collected), we can evaluate how well the model performed by computing how many wrong predictions it generated (this is the nice thing about supervised learning: we can always determine how good the solution is and benchmark different models against each other, while in unsupervised learning the data scientist needs to manually examine the results in detail to try to make sense of them).</span></div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Example Supervised Learning: Regression</dt>
<dd>
<p><strong>Goal:</strong> Predict a continuous value for each data point</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_housing_example/regression.png" alt="image" width="760">
</div>
<div class="title"><span class="small">Finally, you might want to predict a reasonable price that should be used when listing an apartment. Since prices are continuous values, this would be a regression problem, where the model would use as input the attributes of the apartments and then predict a suitable price. Again, since for the collected data we have the true prices available at which the apartments were originally listed, we can compute how far off the regression model was with its estimates from the original price set by a real estate agent.</span></div>
</div>
</div>
</div>
<div class="paragraph">
<p>Some other examples of input &#8594; output problems and what type of ML algorithm can be used to solve them:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Input \(X\)</th>
<th class="tableblock halign-left valign-top">Output \(Y\)</th>
<th class="tableblock halign-left valign-top">ML Algorithm Category</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">sensor measurements</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">everything normal?</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">anomaly detection</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">questionnaire answers</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">customer segmentation</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">clustering</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">past usage of a machine</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">remaining lifetime</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">regression</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">email</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">spam (yes/no)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">classification (binary)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">image</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">which animal?</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">classification (multi-class)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">user’s purchases</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">products to show</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">recommender systems</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">search query</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">relevant documents</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">information retrieval</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">audio</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">text</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">speech recognition</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">text in English</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">text in French</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">machine translation</p></td>
</tr>
</tbody>
</table>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">To solve complex problems, you might need multiple algorithms</dt>
<dd>
<p>Example: virtual assistant (e.g., Siri or Alexa): &#8220;<em>Hey &lt;smart speaker&gt;, tell me a joke!</em>&#8221; &#8594; a random joke</p>
</dd>
</dl>
</div>
<div class="paragraph">
<div class="title"><span class="small">This might look like an input-output problem, but it would be very difficult and inefficient to solve it directly. Instead, the problem should be broken down into smaller subtasks:</span></div>
<p></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Trigger word detection:</strong><br>
audio &#8594; &#8220;Hey &lt;smart speaker&gt;&#8221; (yes/no)?</p>
</li>
<li>
<p><strong>Speech recognition:</strong><br>
audio &#8594; text</p>
</li>
<li>
<p><strong>Intent classification:</strong><br>
text &#8594; (joke/timer/weather/&#8230;&#8203;)?</p>
</li>
<li>
<p><strong>Request-specific program (e.g., select random joke)</strong></p>
</li>
<li>
<p><strong>Speech generation:</strong><br>
text &#8594; audio</p>
</li>
</ol>
</div>
<div class="paragraph">
<div class="title"><span class="small">First, the smart speaker needs to know whether it was spoken to. For this, specific trigger words (e.g., &#8220;Hey Siri&#8221;) are used to activate it, since you also wouldn&#8217;t want the speaker to continuously stream everything you said into the cloud. This is a simple binary classification task (trigger word: yes/no). Next, the spoken words that follow the trigger word are transcribed into text, since text is easier to handle, because, for example, variations due to different accents are removed. Then, based on this text, the intent is recognized, i.e., which of the different functionalities of the virtual assistant should be used (e.g., tell a joke, play music, set an alarm, etc.), which is a multi-class classification problem. The next step is then to actually execute the request, which is not done with ML, but instead some task-specific program is run, e.g., to select a joke from a database or set a timer, etc., based on the apps installed on the device. Finally, the output of the program needs to be converted into an audio signal again, where again a ML model can help to get smoothly spoken text (and in the near future maybe with the voice of George Clooney or some other famous person).</span></div>
<p><br>
&#8658; It is generally advisable to first think about how your problem could be decomposed into easier-to-solve subproblems, especially since there might already be a large dataset or pre-trained ML model available for one of these subtasks (e.g., for speech recognition you could train a model on audio books and political speeches in addition to the data collected from your smart speaker users).</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_taxonomy_of_ml_problems_solutions">Taxonomy of ML problems &amp; solutions</h3>
<div class="paragraph">
<p>Machine learning algorithms can be used to solve a wide variety of problems involving different kinds of inputs data. But different problem types require different approaches and come with their own unique set of challenges.</p>
</div>
<div class="paragraph">
<p>The following is by no means an exhaustive list of all the different areas where machine learning is applied, but should cover the most important cases where ML currently adds value and why might it fail. (Please note, this summary contains some terms that will be explained in the following chapters, so you might want to come back to this later.)</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph lead">
<p><strong>[Supervised Learning] automate &#8216;input &#8594; output&#8217; problems with unstructured data</strong></p>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Goal:</span></div>
<ul class="none">
<li>
<p>Automate tedious, repetitive tasks otherwise done by humans</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Examples:</span></div>
<ul>
<li>
<p>text classification (e.g., identify spam / hate speech / fake news)</p>
</li>
<li>
<p>sentiment analysis (subtask of text classification: identify if text is positive or negative, e.g., for product reviews)</p>
</li>
<li>
<p>speech recognition (e.g., transcribe dictated notes or add subtitles to videos)</p>
</li>
<li>
<p>machine translation (translate texts from one language into another)</p>
</li>
<li>
<p>image classification / object recognition (e.g., identify problematic content (like child pornography) or detect street signs and pedestrians in autonomous driving)</p>
</li>
<li>
<p>image captioning (generate text that describes what&#8217;s shown in an image, e.g., to improve the online experience for the visually impaired)</p>
</li>
<li>
<p>data generation (e.g., generate new photos/images of specific objects or scenes)</p>
</li>
<li>
<p>style transfer (transform a given image into another style, e.g., make photos look like van Gogh paintings)</p>
</li>
<li>
<p>separate individual sources of an audio signal (e.g., unmix a song, i.e., separate vocals and instruments into individual tracks)</p>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Approach:</span></div>
<ul class="none">
<li>
<p>usually deep learning, i.e., a task-specific neural network (NN) architecture</p>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Chance of success:</span></div>
<ul class="none">
<li>
<p>High: Since humans can solve the task, it is at least in principle possible to generate the right output given the input.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Possible challenges:</span></div>
<ul>
<li>
<p>selecting a suitable neural network architecture &amp; getting it to work properly</p>
</li>
<li>
<p>computational resources (don&#8217;t train a NN without a GPU!)</p>
</li>
<li>
<p>data quality and quantity: need a lot of <em>consistently</em> labeled data, i.e., many training instances labeled by human annotators who have to follow the same guidelines (but can be mitigated in some cases by pre-training the network using self-supervised learning)</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph lead">
<p><strong>[Supervised Learning] &#8216;input &#8594; output&#8217; problems previously solved with classical simulation models</strong></p>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Goal:</span></div>
<ul class="none">
<li>
<p>Speed up the estimation for new samples by using a ML model to predict the results instead of the slow simulation model to compute them exactly</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Examples:</span></div>
<ul>
<li>
<p>AlphaFold: generate 3D protein structure from amino acid sequence (to facilitate drug development)</p>
</li>
<li>
<p>SchNet: predict energy and other properties of molecules given their configuration of atoms (to speed up materials research)</p>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Approach:</span></div>
<ul class="none">
<li>
<p>usually deep learning, i.e., a task-specific neural network architecture</p>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Chance of success:</span></div>
<ul class="none">
<li>
<p>High: Since the original simulation model can solve the task, it is at least in principle possible to generate the right output given the input. Furthermore, the original simulation model can be used to generate a sufficient amount of high quality training data.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Possible challenges:</span></div>
<ul>
<li>
<p>often necessary to develop a completely new type of neural network architecture specifically designed for this task and inputs / outputs, which requires a lot of ML &amp; domain knowledge, intuition, and creativity</p>
</li>
<li>
<p>computational resources (don&#8217;t train a NN without a GPU!)</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph lead">
<p><strong>[Supervised Learning] &#8216;input &#8594; output&#8217; problems with structured data</strong></p>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Goal:</span></div>
<ul class="none">
<li>
<p>Describe (and subsequently better understand and optimize) input-output relationships in some real world process.<br>
For example, a manufacturing process may have some Key Performance Indicators (KPIs, i.e., metrics based on which the current performance of the process can be judged), but no one truly understands how all the different process conditions, settings, and other (possibly external) factors really influence these KPIs, under which conditions the process performs better or worse, or how it could be improved.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Examples:</span></div>
<ul>
<li>
<p>determine the price that should be set for a new apartment listing and tell home owners what they can do to sell their house at a higher price (e.g., a freshly renovated bathroom may have a higher influence on what potential buyers are willing to pay than a new coat of paint on the outside)</p>
</li>
<li>
<p>predict in advance whether a product produced under the proposed process conditions will be of high quality or would be a waste of resources</p>
</li>
<li>
<p>identify which process conditions have the most influence on the quality of the product and which settings generally lead to the best results</p>
</li>
<li>
<p>given some external conditions (e.g., outside temperature, composition of raw input materials from a new vendor), automatically determine the best process settings to produce high quality products</p>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Approach:</span></div>
<ul class="none">
<li>
<p>Traditional statistical or ML regression or classification models that describe the functional relationship between inputs and outputs, e.g., linear models, decision trees / random forests, kernel methods, or (feed forward) neural networks, as well as possibly additional methods for optimization (classical or reinforcement learning (RL)).<br>
<span class="underline">Steps:</span></p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>[Optional] Create a dashboard where the KPI(s) can be monitored</p>
</li>
<li>
<p>Build a model that reliably captures the input-output relationship between the process variables and KPIs</p>
</li>
<li>
<p>Analyze the model to identify root causes, i.e., determine which inputs have the most influence on the KPIs and investigate how they are related</p>
</li>
<li>
<p>Use the model in a what-if forecast to facilitate planning</p>
</li>
<li>
<p>Use the model in an outer control loop to automatically find optimal inputs (either with classical optimization techniques or RL for longer time horizons)</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Chance of success:</span></div>
<ul class="none">
<li>
<p>Uncertain: while it is fairly straightforward to apply the models, it is difficult to determine in advance whether there even exists any relation between the measured inputs and KPIs (&#8594; beware of garbage in, garbage out! See also chapter about common pitfalls / causality &amp; extrapolation).</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Possible challenges:</span></div>
<ul>
<li>
<p>appropriate definition of the output/target/KPI that should be modeled, i.e., what does it actually mean for a process to run well and how might external factors influence this definition (e.g., can you expect the same performance on an exceptionally hot summer day?)</p>
</li>
<li>
<p>missing important input variables, e.g., if there exist other influencing factors that you haven&#8217;t considered or couldn&#8217;t measure, which means not all of the target variable&#8217;s variance can be explained</p>
</li>
<li>
<p>lots of possibly irrelevant input variables that require careful feature selection to avoid <a href="https://www.tylervigen.com/spurious-correlations">spurious correlations</a>, which would result in incorrect &#8216;what-if&#8217; forecasts since the true causal relationship between the inputs and outputs isn&#8217;t captured</p>
</li>
<li>
<p>often very time intensive data preprocessing necessary, e.g., when combining data from different sources</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph lead">
<p><strong>[Information Retrieval / Recommender Systems] improve search results / personalized suggestions</strong></p>
</div>
<div class="ulist">
<div class="title"><span class="underline">Goal/Examples/Approach:</span></div>
<ul>
<li>
<p><strong>information retrieval</strong> / similarity search (with a single type of data): given a query, rank results, e.g.,</p>
<div class="ulist">
<ul>
<li>
<p>return matching documents / websites given a search query</p>
</li>
<li>
<p>show similar movies given the movie a user is currently looking at (e.g., same genre, director, etc.)</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>recommender systems</strong> (on pairwise data): given a sample from one type of data (e.g., user, protein structure), identify the most relevant samples from another type of data (e.g., movie, drug composition), e.g.,</p>
<div class="ulist">
<ul>
<li>
<p>show a user movies that other users with a similar taste also liked</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Chance of success:</span></div>
<ul class="none">
<li>
<p>Worth a try: usually these suggestions are better than not showing anything</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Possible challenges:</span></div>
<ul>
<li>
<p>little / incomplete data: different users might like the same item for different reasons and it is unclear whether, e.g., a user didn&#8217;t watch a movie because he&#8217;s not interested in it or because he just didn&#8217;t notice it yet</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph lead">
<p><strong>[Unsupervised Learning] data preprocessing to improve performance in the following analysis steps</strong></p>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Goal/Examples/Approach:</span></div>
<ul class="none">
<li>
<p><strong>dimensionality reduction</strong> (e.g., with (Kernel) PCA): noise reduction / feature engineering</p>
</li>
<li>
<p><strong>outlier detection</strong> (e.g., with \(\gamma\)-index, Isolation Forest, or One-Class SVM): clean up the data, e.g., by removing samples with wrongly entered values</p>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Chance of success:</span></div>
<ul class="none">
<li>
<p>Worth a try: whether these measures help or not depends on the dataset as well as the algorithms applied to the preprocessed data afterwards, but investing time in data cleaning is usually well spent</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Possible challenges:</span></div>
<ul>
<li>
<p>transforming the data with (Kernel) PCA constructs new features as a (non-)linear combination of the original features, which decreases the interpretability of the analysis results</p>
</li>
<li>
<p>you should always have a good reason for throwing away data points&#8201;&#8212;&#8201;outliers are seldom random, sometimes they reveal interesting edge cases that should not be ignored</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph lead">
<p><strong>[Unsupervised Learning] identify patterns: samples that can be grouped together or that don&#8217;t belong</strong></p>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Goal/Examples/Approach:</span></div>
<ul class="none">
<li>
<p><strong>dimensionality reduction</strong> (e.g., with t-SNE): create a 2D visualization to explore the dataset as a whole, where you can often already see any clusters or outliers</p>
</li>
<li>
<p><strong>clustering</strong> (e.g., with <em>k</em>-means or DBSCAN): identify groups of related data points, e.g., customer segmentation for targeted marketing campaign</p>
</li>
<li>
<p><strong>anomaly detection</strong> (e.g., with \(\gamma\)-index, Isolation Forest, or One-Class SVM): identify fraudulent transaction in e-commerce; monitor a machine to see when something out of the ordinary happens</p>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Chance of success:</span></div>
<ul class="none">
<li>
<p>Worth a try: the algorithms will always find something, but whether this is useful (i.e., what the identified patterns mean) can only be determined by a human in a post-processing step</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Possible challenges:</span></div>
<ul>
<li>
<p>no ground truth: difficult to choose between different models and hyperparameter settings</p>
</li>
<li>
<p>many of the algorithms rely on similarities or distances between data points, and it can be difficult to define an appropriate measure for this or know in advance which features should be compared (e.g., what makes two customers similar?)</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph lead">
<p><strong>[Reinforcement Learning] optimize sequences of actions in changing environments</strong></p>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Goal:</span></div>
<ul class="none">
<li>
<p>Determine an optimal sequence of actions given changing environmental conditions.<br>
Unlike in regular optimization, where the optimal inputs given a single specific external condition are determined, here an &#8220;agent&#8221; (= the RL algorithm) tries to learn an optimal <em>sequence</em> of inputs to maximize the cumulative reward received over multiple time steps, where there can be a significant time delay between the inputs and the rewards that they generate (e.g., in a video game you might need to pick up a key in the beginning of a level, but the door that can be opened with it only comes several frames later).</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Examples:</span></div>
<ul>
<li>
<p>virtual agent playing a (video) game</p>
</li>
<li>
<p>robot with complex movement patterns, e.g., picking up differently shaped objects from a box</p>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Approach:</span></div>
<ul class="none">
<li>
<p>lots of options, many nowadays based on neural networks (e.g., AlphaGo / MuZero)</p>
</li>
</ul>
</div>
<div class="ulist none">
<div class="title"><span class="underline">Chance of success:</span></div>
<ul class="none">
<li>
<p>Depends on the task; works well in many video games, since here the true environment is itself a simulation and the rewards are clearly defined (see challenges).</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><span class="underline">Possible challenges:</span></div>
<ul>
<li>
<p>usually requires a simulation environment for the agent to learn in before it starts acting in the real world, but developing an accurate simulation model isn&#8217;t easy and the agent will exploit any bugs if that results in higher rewards</p>
</li>
<li>
<p>can be tricky to define a clear reward function that should be optimized (imitation learning is often a better option, where the agent instead tries to mimic the decisions made by a human in some situation)</p>
</li>
<li>
<p>difficult to learn correct associations when there are long delays between critical actions and the received rewards</p>
</li>
<li>
<p>agent generates its own data: if it starts off with a bad policy, it will be tricky to escape from this (e.g., in a video game, if the agent always falls down a gap instead of jumping over it, it never sees the rewards that await on the other side and therefore can&#8217;t learn that it would be beneficial to jump over the gap)</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_unsupervised_learning">Unsupervised Learning</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The first algorithms we look at in more detail are from the area of unsupervised learning:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ml_overview/ml_algorithms_unsupervised.png" alt="image" width="840">
</div>
</div>
<div class="paragraph">
<p>While the different subfields of unsupervised learning all include lots of algorithms that can be used for the respective purpose, we&#8217;ll always just examine a few example algorithms with different underlying ideas in more detail. But feel free to, e.g., have a look at the <a href="https://scikit-learn.org/stable/unsupervised_learning.html">sklearn user guide</a> for more information about other models.</p>
</div>
<div class="sect2">
<h3 id="_dimensionality_reduction">Dimensionality Reduction</h3>
<div class="paragraph">
<p>The first subfield of unsupervised learning that we look at is dimensionality reduction:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ml_overview/ml_algorithms_dimred.png" alt="image" width="740">
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Goal</dt>
<dd>
<p>reduce the number of features without loosing relevant information</p>
</dd>
<dt class="hdlist1">Advantages</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>reduced data needs less memory (usually not that important anymore today)</p>
</li>
<li>
<p>noise reduction (by focusing on the most relevant signals)</p>
</li>
<li>
<p>create a visualization of the dataset (what we will mostly be using these algorithms for)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Example: Embed images of hand written digits in 2 dimensions</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/03_unsupervised/dimred_problem.png" alt="image" width="470">
</div>
<div class="title"><span class="small">Our dataset in this small example consists of a set of 8 x 8 pixel images showing handwritten digits (i.e., each data point can be represented as a 64-dimensional input feature vector containing the gray-scale pixel values). Usually, this dataset is used for classification, i.e., where a model should predict which number is shown on the image. We instead only want to get a better overview of the dataset, i.e., our goal is to reduce the dimensionality of this dataset to 2 coordinates, which we can then use to visualize all samples in a 2D overview map. Please note that the algorithms only use the original image pixel values as input to compute the 2D coordinates, but afterwards we additionally use the labels of the images (i.e., the digit shown in the image) to give the dots in the plot some color to better interpret the results.</span></div>
</div>
<div class="openblock text-center">
<div class="content">
<div class="paragraph">
<p><span class="image"><img src="images/03_unsupervised/dimred_pca.png" alt="image" width="420"></span>
<span class="image"><img src="images/03_unsupervised/dimred_tsne.png" alt="image" width="420"></span></p>
</div>
</div>
</div>
<div class="openblock text-justify">
<div class="content">
<div class="paragraph">
<p><span class="small">The two plots show the results, i.e., the 2-dimensional representation of the dataset, created with two different dimensionality reduction algorithms, PCA and t-SNE. Each point or thumbnail in the plot represents one data point (i.e., one image), where the colors, numbers, and example images were added in the graphic afterward to make it easier to interpret what is shown here. There is no right or wrong way to represent the data in 2D (it&#8217;s an unsupervised learning problem, which by definition has no ground truth answer), but the algorithms arrive at two very different solutions, since they follow different strategies and have a different definition of what it means to preserve the relevant information. While PCA created a plot that preserves the global relationship between the samples, t-SNE arranged the samples in localized clusters. The remarkable thing here is that these methods did not know about the fact that the images displayed different, distinct digits (i.e., they did not use the label information), yet t-SNE grouped images showing the same number closer together. From such a plot we can already see that if we were to solve the classification problem here (i.e., predict which digit is shown in an image), this task should be fairly easy, since even an unsupervised learning algorithm that did not use the label information showed that images displaying the same number are very similar to each other and can easily be distinguished from images showing different numbers (or conversely, if our classification model performed very poorly on this task, we would know that we have a bug somewhere, since apparently the relevant information is present in the features to solve this task). <em>Please note that even though t-SNE seems to create clusters here, this is not a clustering algorithm. As a dimensionality reduction algorithm, t-SNE produces a set of new 2D coordinates for our samples and when plotting the samples at these coordinates, they happen to be arranged in clusters. However, a clustering algorithm instead outputs cluster indices, that state which samples were assigned to the same group (which could then be used to color the points in the 2D coordinate plot).</em></span></p>
</div>
</div>
</div>
</dd>
</dl>
</div>
<div class="sect3">
<h4 id="_principal_component_analysis_pca">Principal Component Analysis (PCA)</h4>
<div class="dlist">
<dl>
<dt class="hdlist1">Useful for</dt>
<dd>
<p>general dimensionality reduction &amp; noise reduction (&#8594; the transformed data is then sometimes used as input to other algorithms instead of the original features)</p>
</dd>
<dt class="hdlist1">Main idea</dt>
<dd>
<p>compute the eigendecomposition of the dataset&#8217;s covariance matrix (a symmetric matrix of size \(d \times d\) (with <em>d</em> = number of original input features), which states how strongly any two features co-vary, i.e., how related they are, similar to the linear correlation between two features). By computing the eigenvalues and -vectors of this matrix, the main directions of variance are identified as the new principle components (which can be expressed as linear combinations of the original features) and we can now reorient the data along these new axis (have a look at <a href="https://www.youtube.com/watch?v=5HNr_j6LmPc">this video</a> for a more detailed explanation):</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/03_unsupervised/pca.png" alt="image" width="740">
</div>
<div class="title"><span class="small">Here the original data only has two features anyways, so a dimensionality reduction does not make much sense, but it nicely illustrates how the algorithm works: the main direction of variance is selected as the first new dimension, while the direction with the next strongest variation (orthogonal to the first) is the second new dimension, also called principle components. The data can then be rotated accordingly, such that the amount of captured variation in the data (i.e., the information content and also the eigenvalue associated with this principle component) decreases from the first to the last of these new dimensions.</span></div>
</div>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.decomposition</span> <span class="keyword">import</span> <span class="include">PCA</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><span class="underline">Important Parameters:</span></p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; <code>n_components</code>: new dimensionality of data (this can be as many as the original features (or the rank of the feature matrix))</p>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>linear algebra based: global optima (i.e., when you compute PCA multiple times on the same dataset you&#8217;ll always get the same solution)</p>
</li>
<li>
<p>know how much information is retained (check the attributes <code>explained_variance_ratio_</code> or <code>lambda_</code>):<br>
the principle components are always ordered by the magnitude of their corresponding eigenvalues (largest first);<br>
for <em>k</em> components with eigenvalues \(\lambda_i\), the amount of variation that is preserved is: \(\frac{\sum_{i=1}^k \lambda_i}{\sum_{i=1}^d \lambda_i}\)<br>
(if the intrinsic dimensionality of the dataset is lower than the original number features, e.g., because some features were strongly correlated, then the last few eigenvalues will be zeros; you can also plot the <a href="https://en.wikipedia.org/wiki/Scree_plot">eigenvalue spectrum</a>, i.e., the eigenvalues ordered by their magnitude, to see how many dimensions you might want to keep, i.e., when this curve starts to flatten out)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>computationally expensive for many (&gt; 10k) features<br>
&#8594; if you have less data points than features, consider using Kernel PCA instead (this computes the eigendecomposition of a similarity matrix, which is \(n \times n\) (with <em>n</em> = number of data points), i.e., when <em>n</em> &lt; <em>d</em> this matrix will be smaller than the covariance matrix and therefore computing its eigendecomposition will be faster)</p>
</li>
<li>
<p>outliers can heavily skew the results (because a few points away from the center can introduce a large variance in that direction)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_t_sne">t-SNE</h4>
<div class="dlist">
<dl>
<dt class="hdlist1">Useful for</dt>
<dd>
<p>visualizing data in 2D (but please do not use the transformed data as input for other algorithms)</p>
</dd>
<dt class="hdlist1">Main idea</dt>
<dd>
<p>randomly initialize the points in 2D and move them around until their distances in 2D match the original distances in the high dimensional input space, i.e., until the points that were similar to each other in the original high dimensional space are located close together in the new 2D map of the dataset (&#8594; have a look at the animations in this great blog article to see <a href="https://distill.pub/2016/misread-tsne/">t-SNE in action</a>)</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.manifold</span> <span class="keyword">import</span> <span class="include">TSNE</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><span class="underline">Important Parameters:</span></p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; <code>perplexity</code>: roughly: how many nearest neighbors a point is expected to have (see also the corresponding section in the blog article linked above for an example; what an appropriate value for this parameters is depends on the size and diversity of your dataset, e.g., if you have a dataset of 1000 images with 10 classes, then a perplexity of 5 might be a reasonable choice, while in a dataset with 1 million samples, 500 could be a good value <span class="small">(the original paper says values up to 50 work well, but in 2003 &#8220;big data&#8221; also wasn&#8217;t a buzzword yet ;-)</span>)</p>
</li>
<li>
<p>&#8594; <code>metric</code>: how to compute the distances in the original high dimensional input space (which tells you which points should be close together in the 2D map)</p>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>very nice visualizations</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>can get stuck in a local optimum (e.g., some points trapped between clusters)</p>
</li>
<li>
<p>selection of distance metric for heterogeneous data (&#8594; normalize!)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>&#8594; also check out the <a href="https://github.com/YingfanWang/PaCMAP"><code>pacmap</code></a> and <a href="https://umap-learn.readthedocs.io/en/latest/"><code>umap</code></a> libraries!</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_outlier_anomaly_detection">Outlier / Anomaly Detection</h3>
<div class="paragraph">
<p>Next up on our list of ML tools is anomaly or outlier detection:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ml_overview/ml_algorithms_outliers.png" alt="image" width="740">
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Useful for</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>detecting anomalies for monitoring purposes (e.g., machine failures or fraudulent credit card transactions)<br></p>
</li>
<li>
<p>removing outliers from the dataset to improve the performance of other algorithms</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>When trying to remove outliers or detect anomalies, there are many things that need to be considered:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Does the dataset consist of <strong>independent data points or time series data</strong> with dependencies?</p>
</li>
<li>
<p>Are you looking for <strong>outliers in individual dimensions</strong> (e.g., in time series data you might not see a failure in all sensors simultaneously, but only one sensor might act up spontaneously (i.e., show a value very different from the previous time point), which would be enough to rule this time point an anomaly irrespective of the values of the other sensors) or is it necessary to consider <strong>multidimensional outlier patterns</strong> (e.g., for independent data points individual feature values might not seem anomalous by themselves, only when considered in combination with the data point&#8217;s other feature values (e.g., a \(35 m^2\) apartment could be a nice studio, but if this apartment is also supposed to have 5 bedrooms then something is off))?</p>
</li>
<li>
<p>Are you expecting a few <strong>individual outliers or clusters</strong> of outliers (the latter is especially common in time series data, where, e.g., a machine might experience an issue for several minutes or even hours before the signals look normal again)? Clusters of outliers are more tricky to detect, especially if the data also contains other &#8216;legitimate&#8217; clusters of normal points. Domain expertise is key here!</p>
</li>
<li>
<p>Do you have any <strong>labels</strong> available? E.g., while you might not know what the different kinds of (future) anomalies could look like, maybe you <em>do</em> know what normal data points look like, which is important information that you can make use of by checking how far new points deviate from these normal points (also called novelty detection).</p>
</li>
</ul>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
Know your data - are missing values marked as NaNs (= "Not a Number")?
</td>
</tr>
</table>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
While removing outlier points from a dataset is often a necessary cleaning step, e.g., to obtain better prediction models, you should always be able to explain <em>why</em> you removed these points, as they could also be interesting edge cases. If possible, you should always remove as many outliers as possible with manually crafted rules (e.g., &#8220;when this sensor is 0, the machine is off and the points can be disregarded&#8221;), especially when the dataset contains clusters of outliers, which are also more difficult to detect with data-driven methods.
</td>
</tr>
</table>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Please note that some of the data points that will be encountered in the future might be outliers as well, i.e., before applying a prediction model to new test points in production, these should be screened for outliers as well, as the predictions for these points would not be accurate if the model was trained on a dataset with outliers removed.
</td>
</tr>
</table>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Different methods for outlier/anomaly detection</dt>
<dd>
<p>There is no one-size-fits-all solution, but depending on the characteristics of your dataset you might want to experiment with some of these approaches:</p>
<div class="ulist">
<ul>
<li>
<p>Detecting multidimensional outlier patterns, especially in datasets with independent data points (see also <a href="https://scikit-learn.org/stable/modules/outlier_detection.html">sklearn user guide</a>):</p>
<div class="ulist">
<ul>
<li>
<p>\(\gamma\)-index (see below)</p>
</li>
<li>
<p>Local Outlier Factor (from <code>sklearn</code>; similar to the \(\gamma\)-index)</p>
</li>
<li>
<p>Isolation Forest (from <code>sklearn</code>; read about decision trees and random forests first)</p>
</li>
<li>
<p>One-class SVM (from <code>sklearn</code>; read about kernel methods and normal SVMs first)</p>
</li>
<li>
<p>DBSCAN (a clustering algorithm described in the next section that allows for noise, which would be considered outliers)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Comparing actual data points to denoised samples or predicted values:</p>
<div class="ulist">
<ul>
<li>
<p>Use (kernel) PCA or an auto-encoder neural network architecture to first compress a sample and then reconstruct it in order to remove noise. If the denoised data point deviates a lot from the original sample, it is probably an anomaly.</p>
</li>
<li>
<p>For time series data: model the expected course of an individual time series, e.g., using a moving window average or an ARIMA model (see section on time series data for more details), and then compare how much a time point deviates from this predicted value.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Get creative: you know your data best&#8201;&#8212;&#8201;define rules and custom anomaly KPIs based on your domain knowledge (e.g., set thresholds for what would be considered unrealistic feature values etc.)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_gamma_index">\(\gamma\)-index</h4>
<div class="paragraph">
<p><span class="small">Harmeling, Stefan, et al. &#8220;From outliers to prototypes: ordering data.&#8221; <em>Neurocomputing</em> 69.13-15 (2006): 1608-1618.</span></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Main idea</dt>
<dd>
<p>compute the average distance of a point to its <em>k</em> nearest neighbors;<br>
&#8594; points with a large average distance are likely to be outliers<br>
(&#8658; set a threshold at what average distance the point is considered an outlier)</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/03_unsupervised/outliers.png" alt="image" width="640">
</div>
<div class="title"><span class="small">This is a toy example in 2D, while normally you would compute the Euclidean distance between the points in their (high dimensional) input feature space.</span></div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">import</span> <span class="include">numpy</span> <span class="keyword">as</span> np
<span class="keyword">from</span> <span class="include">sklearn.metrics</span> <span class="keyword">import</span> <span class="include">pairwise_distances</span>

<span class="keyword">def</span> <span class="function">gammaidx</span>(X, k):
    <span class="docstring"><span class="delimiter">&quot;&quot;&quot;</span><span class="content">
</span><span class="content">    Inputs:</span><span class="content">
</span><span class="content">        - X [np.array]: n samples x d features input matrix</span><span class="content">
</span><span class="content">        - k [int]: number of nearest neighbors to consider</span><span class="content">
</span><span class="content">    Returns:</span><span class="content">
</span><span class="content">        - gamma_index [np.array]: vector of length n with gamma index for each sample</span><span class="content">
</span><span class="content">    </span><span class="delimiter">&quot;&quot;&quot;</span></span>
    <span class="comment"># compute n x n Euclidean distance matrix</span>
    D = pairwise_distances(X, metric=<span class="string"><span class="delimiter">'</span><span class="content">euclidean</span><span class="delimiter">'</span></span>)
    <span class="comment"># sort the entries of each row, such that the 1st column is 0 (distance of point to itself),</span>
    <span class="comment"># the following columns are distances to the closest nearest neighbors (i.e., smallest values first)</span>
    Ds = np.sort(D, axis=<span class="integer">1</span>)
    <span class="comment"># compute mean distance to the k nearest neighbors of every point</span>
    gamma_index = np.mean(Ds[:, <span class="integer">1</span>:(k+<span class="integer">1</span>)], axis=<span class="integer">1</span>)
    <span class="keyword">return</span> gamma_index

<span class="comment"># or more efficiantly with the NearestNeighbors class</span>
<span class="keyword">from</span> <span class="include">sklearn.neighbors</span> <span class="keyword">import</span> <span class="include">NearestNeighbors</span>

<span class="keyword">def</span> <span class="function">gammaidx_fast</span>(X, k):
    <span class="docstring"><span class="delimiter">&quot;&quot;&quot;</span><span class="content">
</span><span class="content">    Inputs:</span><span class="content">
</span><span class="content">        - X [np.array]: n samples x d features input matrix</span><span class="content">
</span><span class="content">        - k [int]: number of nearest neighbors to consider</span><span class="content">
</span><span class="content">    Returns:</span><span class="content">
</span><span class="content">        - gamma_index [np.array]: vector of length n with gamma index for each sample</span><span class="content">
</span><span class="content">    </span><span class="delimiter">&quot;&quot;&quot;</span></span>
    <span class="comment"># initialize and fit nearest neighbors search</span>
    nn = NearestNeighbors(n_neighbors=k).fit(X)
    <span class="comment"># compute mean distance to the k nearest neighbors of every point (ignoring the point itself)</span>
    <span class="comment"># (nn.kneighbors returns a tuple of distances and indices of nearest neighbors)</span>
    gamma_index = np.mean(nn.kneighbors()[<span class="integer">0</span>], axis=<span class="integer">1</span>)  <span class="comment"># for new points: nn.kneighbors(X_test)</span>
    <span class="keyword">return</span> gamma_index</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>conceptually very simple and easy to interpret</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>computationally expensive for large datasets (distance matrix: \(\mathcal{O}(n^2)\)) &#8594; compute distances to a random subsample of the dataset or to a smaller set of known non-anomalous points instead</p>
</li>
<li>
<p>normalize heterogeneous datasets before computing distances!</p>
</li>
<li>
<p>know your data: does the dataset contain larger clusters of outliers? &#8594; <em>k</em> needs to be large enough such that a tight cluster of outliers is not mistaken as prototypical data points</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Extension for time series data: don&#8217;t identify the <em>k</em> nearest neighbors of a sample based on the distance of the data points in the feature space, but take the neighboring time points instead.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_clustering">Clustering</h3>
<div class="paragraph">
<p>The last category of unsupervised learning algorithms is clustering:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ml_overview/ml_algorithms_clustering.png" alt="image" width="740">
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Useful for</dt>
<dd>
<p>identifying naturally occurring groups in the data (e.g., for customer segmentation)</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>There exist <a href="https://scikit-learn.org/stable/modules/clustering.html">quite a lot of different clustering algorithms</a> and we&#8217;ll only present two with different ideas here. If you look at the linked sklearn examples, please note that even though other clustering algorithms might seem to perform very well on fancy toy datasets, data in reality is seldom arranged in two concentric circles, and on real-world datasets the k-means clustering algorithm is often a robust choice.</p>
</div>
<div class="sect3">
<h4 id="_k_means_clustering"><em>k</em>-means clustering</h4>
<div class="dlist">
<dl>
<dt class="hdlist1">Main idea</dt>
<dd>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>randomly place <em>k</em> cluster centers (where <em>k</em> is a hyperparameter set by the user);</p>
</li>
<li>
<p>assign each data point to its closest cluster center;</p>
</li>
<li>
<p>update cluster centers as mean of the assigned data points;</p>
</li>
<li>
<p>repeat 2-3 until convergence.</p>
</li>
</ol>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/03_unsupervised/kmeans.png" alt="image" width="840">
</div>
<div class="title"><span class="small">Please note that even though in these pictures the data is depicted in 2D, of course all these methods also work in high dimensional spaces!</span></div>
</div>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.cluster</span> <span class="keyword">import</span> <span class="include">KMeans</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><span class="underline">Important Parameters:</span></p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; <code>n_clusters</code>: how many clusters (<em>k</em>) you want to find</p>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>fast</p>
</li>
<li>
<p>usually good results on real world datasets</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>depends on random initialization (&#8594; local optimum, but usually not problematic in practice due to multiple restarts)</p>
</li>
<li>
<p>assumes spherical clusters</p>
</li>
<li>
<p>need to guess the number of clusters (but can be done with a heuristic)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_dbscan">DBSCAN</h4>
<div class="dlist">
<dl>
<dt class="hdlist1">Main idea</dt>
<dd>
<p>find &#8216;core samples&#8217; in dense areas of the data and then expand clusters by iteratively including points with a distance &lt; <code>eps</code></p>
<div class="imageblock text-center">
<div class="content">
<img src="images/03_unsupervised/dbscan.png" alt="image" width="840">
</div>
</div>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.cluster</span> <span class="keyword">import</span> <span class="include">DBSCAN</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><span class="underline">Important Parameters:</span></p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; <code>eps</code>: maximum neighborhood distance of two samples</p>
</li>
<li>
<p>&#8594; <code>metric</code>: how to compute the distance in the input feature space</p>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>allows for noise (&#8594; can also use the algorithm to detect outliers)</p>
</li>
<li>
<p>no need to guess the number of clusters</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>very dependent on distance measure: may be tricky to get good results for heterogeneous data even after normalization (but: try on text data)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>&#8594; also check out the <a href="https://hdbscan.readthedocs.io/en/latest/"><code>hdbscan</code></a> library!</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_supervised_learning_basics">Supervised Learning Basics</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now that you&#8217;ve gotten to know different unsupervised learning algorithms, we move on to supervised learning:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ml_overview/ml_algorithms_supervised.png" alt="image" width="840">
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Supervised learning in a nutshell</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/04_supervised_intro/sl_steps5.png" alt="image" width="440">
</div>
<div class="title"><span class="small">Before you start, you need to be very clear on what you want, i.e., what should be predicted, how will predicting this variable help you achieve your overall goals and create value, and how do you measure success (i.e., what is the Key Performance Indicator (KPI) of your process)? Then, you need to collect data&#8201;&#8212;&#8201;and since we&#8217;re doing supervised learning now, this needs to be <em>labeled</em> data (with the labels corresponding to the target variable that you want to predict). Next, you can "learn" (or "train" or "fit") a model on this data and finally use it to generate predictions for new data points.</span></div>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Don’t stop there! (Depth of analytics revisited):</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/04_supervised_intro/supervised_more4.png" alt="image" width="540">
</div>
<div class="title"><span class="small">In many use cases, it is not enough to simply predict the target for a new data point (e.g., predict whether a product produced under certain conditions will be of high quality or not). Instead, it is often necessary to additionally be able to explain <em>why</em> this prediction was made (e.g., which input feature values were the deciding factors&#8201;&#8212;&#8201;both to better understand possible root causes of a problem, but also to be assured that the model is basing its predictions on reasonable assumptions). Furthermore, a learned model can also be used within an outer optimization loop, i.e., in the simplest case one could systematically check what product quality the model predicts for different process conditions and then select the settings with the highest predicted quality to produce new products (but keep in mind that ML models are only build to interpolate, not extrapolate, i.e., make sure the settings that are tested are withing the training domain).</span></div>
</div>
<div class="paragraph">
<p>Supervised learning in a nutshell – more formally, with scikit-learn:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/04_supervised_intro/supervised_learning_14.png" alt="image" width="840">
</div>
<div class="title"><span class="small">First, the available data needs to be split into a training and test part (please note that for them to better fit in the graphic, \(X\) and \(\mathbf{y}\) were rotated here by 90 degrees, i.e., as an exception, the features are here in the rows and the data points are in the columns), where we&#8217;re assigning the majority of the data points to the training set and the rest to the test set. Next, you need to decide on the type of model that you want to use to describe the relationship between the inputs \(X\) and the outputs \(\mathbf{y}\) and this model also comes with some hyperparameters that you need to set (which are passed as arguments when instantiating the respective sklearn class). Then you can call the <code>.fit(X_train, y_train)</code> method on the model to learn the internal model parameters by minimizing some model-specific objective function on the training data. Now the model is ready to generate predictions for new data points, i.e., by calling <code>.predict(X_test)</code>, you obtain the predicted values \(\mathbf{\hat{y}}\) for the test points. Finally, to get an estimate of how useful the model will be in practice, we evaluate it by comparing the predicted target values of the test set to the corresponding true labels.</span></div>
</div>
<div class="paragraph">
<p>In the following sections, we introduce the different approaches to supervised learning and explain when to use which kind of model, then discuss how to evaluate and select a supervised learning model.</p>
</div>
<div class="sect2">
<h3 id="_different_types_of_models">Different types of models</h3>
<div class="paragraph">
<p>The most important task of a data scientist is to select an appropriate model (and its hyperparameters) for solving a problem.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<div class="title"><span class="underline">3 considerations when choosing a supervised learning model</span></div>
<p></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">1. Problem type</dt>
<dd>
<p>What kind of problem are you trying to solve: <em>regression</em> or <em>classification</em>?<br>
&#8594; depends on the type of target variable, i.e., if it has continuous or discrete values</p>
</dd>
<dt class="hdlist1">2. Problem complexity</dt>
<dd>
<p>How complicated is the relationship between the input features and target variable: <em>linear</em> or <em>non-linear</em>?<br>
&#8594; depends on the available data</p>
</dd>
<dt class="hdlist1">3. Algorithmic approach</dt>
<dd>
<p>Which type of model works best for this dataset size &amp; complexity: <em>features-based</em> or <em>similarity-based</em>?<br>
&#8594; depends on the model you choose, i.e., it either learns according to the first or second strategy</p>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_problem_type_regression_vs_classification">Problem type: Regression vs. Classification</h4>
<div class="paragraph">
<p>The type of the target variable that you need to predict determines whether you are dealing with a regression or classification problem.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Regression</dt>
<dd>
<p>prediction of continuous value(s) <em>(e.g., price, number of users, etc.)</em></p>
</dd>
<dt class="hdlist1">Classification</dt>
<dd>
<p>prediction of discrete values, either<br></p>
<div class="ulist">
<ul>
<li>
<p>binary <em>(e.g., product will be faulty: yes/no)</em> or</p>
</li>
<li>
<p>multi-class <em>(e.g., picture displays cat/dog/house/car/&#8230;&#8203;)</em></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>&#8594; many classification models actually predict probabilities for the different classes (i.e., a score between 0 and 1 for each class), and the final class label is then chosen by applying a threshold on this score (typically 0.5 for binary classification problems) or by taking the outcome with the highest score (in multi-class problems)</p>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>&#8658; Whether you are dealing with a regression or classification problem is important to know and has implications for your overall workflow, e.g., how you should define &amp; measure success. However, the actual models that you can use to solve these problems are very similar, e.g., almost all <code>sklearn</code> models exist in either a <code>Regressor</code> or <code>Classifier</code> variant to generate the appropriate output for the respective problem type.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>In some cases it is even entirely up to you whether to frame the task as a regression or classification problem.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Example</dt>
<dd>
<p>A product is deemed faulty, if it breaks within the warranty period of 6 months (where we assume that normally the product would be used at most 300 times during these 6 months).</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Depending on your use case, you might either be interested in how long a product lasts in total, or only whether this product will be a warranty case or not, i.e., you could formulate your problem as:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>a regression task: predict, <em>after how many uses</em> the product will break</p>
</li>
<li>
<p>a classification task: predict, <em>if the product will break</em> before it was used 300 times</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>However, in many cases where you have a continuous target variable, you can learn a more accurate prediction model with the regression approach, since here the labels carry much more information and edge case errors are not penalized as much (e.g., in the classification case, predicting that a product is okay when it lasted 299 uses would be just as wrong as predicting &#8216;okay&#8217; for a product that lasted only 2 uses). If the workflow where your model is later embedded in requires a classification output, you can still transform the regression output of the model into a classification output later by simply setting a threshold, i.e., in this case if the regression model predicts a value lower than 300 you would output &#8216;faulty&#8217; and otherwise &#8216;okay&#8217;.</p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_problem_complexity_linear_or_non_linear">Problem complexity: linear or non-linear</h4>
<div class="paragraph">
<p>In accordance with the product warranty example described above, we now illustrate what it means for a problem to be linear or non-linear on a small toy dataset:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/04_supervised_intro/problem_types2.png" alt="image" width="340">
</div>
<div class="title"><span class="small">The first input feature we consider is the production temperature, which is an independent variable, since the operator in control of the production process is free to just choose some value here. The target variable that we want to predict is the lifetime of the produced product and depends on this input variable. For the different temperature settings that were tested, we have collected the respective lifetime measurements (and, as you can imagine, getting such labels can be quite expensive, since these products not only needed to be produced, but also go through some stress test to determine after how many uses they break).</span></div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/04_supervised_intro/problem_types8.png" alt="image" width="840">
</div>
<div class="title"><span class="small">As you might have already guessed, the relationship between the target variable lifetime and the input feature temperature <em>(top left)</em> is a linear one, i.e., you could describe it by a straight line. Since the lifetime is a continuous variable, this is a regression problem. However, by defining some cutoff on the target variable (e.g., at 300 usages for in and out of warranty), this problem can be transformed into a classification problem, where the task here is to distinguish between faulty and good products <em>(bottom left)</em>. Again, the relationship between the target and the input variable temperature is linear, since the problem can be solved by drawing one line parallel to the y-axis, which defines some threshold on the temperature, where all data points with a temperature lower than this threshold would be classified as &#8216;ok&#8217; and those products produced at a higher temperature would be predicted as &#8216;broken&#8217;. In the center panel, we have the same situation only this time with a different input feature, pressure. In the regression case, the lifetime values now follow some quadratic curve, i.e., we could not adequately describe the relationship between our target variable and the input feature &#8216;pressure&#8217; with a single straight line, which makes this a non-linear problem. Similarly, in the classification case below, we would need to define two thresholds on the pressure values to separate the two classes, i.e., again we could not solve the problem with a single straight line. While these 4 examples were univariate problems, i.e., with a single input variable, in machine learning we usually deal with multivariate problems, often with hundreds or even thousands of input features. For the case of two input variables, this is illustrated on the right, where the data is now plotted in a scatter plot where the axis correspond to the features temperature and pressure, while the color of the dots indicates the target value (either on a continuous scale or the discrete class labels). In the multidimensional case, a problem would be considered linear if it can by solved by a single hyperplane (instead of a line) in the input feature space.</span></div>
</div>
<div class="paragraph">
<p>As illustrated in the above examples, whether your problem can be solved by a simple linear model (i.e., a single straight line or hyperplane) or requires a more complex non-linear model to adequately describe the relationship between the input features and target variable entirely depends on the given data. This also means that sometimes you might just need to install an additional sensor to measure some feature that is linearly related to your target variable or do some feature engineering to then be able to get satisfactory results with a linear model, i.e., sometimes, with the right preprocessing, a non-linear problem can also be transformed into a linear one.</p>
</div>
</div>
<div class="sect3">
<h4 id="_algorithmic_approaches_features_based_vs_similarity_based_models">Algorithmic approaches: Features-based vs. similarity-based models</h4>
<div class="paragraph">
<p>Finally, lets look at how the different models work and arrive at their predictions. This is what really distinguishes the various algorithms, whereas we have already established that there always exists a regression and a classification variant of each model and some models are inherently expressive enough that they can be used to describe non-linear relationships in the data, while others will only yield satisfactory results if there exists a linear relationship between the available input features and the target variable.</p>
</div>
<div class="paragraph">
<p>While features-based models learn some parameters or rules that are applied directly to a new data point&#8217;s input feature vector \(\mathbf{x} \in \mathbb{R}^d\), for the similarity-based models, first a vector \(\mathbf{s} \in \mathbb{R}^n\) with the similarities of the new data point to the training data points is computed and the model then operates on this vector instead of the original input features:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/04_supervised_intro/algo_approach_handout.png" alt="image" width="640">
</div>
<div class="title"><span class="small"><em>Left:</em> Features-based models can be described by a parametrized function that operates on the original input features. For example, in the regression case <em>(top)</em>, the predicted target for a new data point would be the value on the line corresponding to its input features, while in the classification case <em>(bottom)</em>, the prediction would be made according to on which side of the dividing line the inputs lie. <em>Right:</em> The similarity-based models make the prediction for a new sample based on this data point&#8217;s nearest neighbors. Depending on the type of model, this could be as simple as predicting the average target value of the nearest neighbors (regression, <em>top</em>) or their most frequent class (classification, <em>bottom</em>).</span></div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
This distinction between algorithmic approaches is not only interesting from a theoretical point of view, but even more so from a user perspective: when using a similarity-based algorithm, you have to be very careful which features you include when computing the similarities, make sure that these features are appropriately scaled, and in general think about which similarity measure is appropriate for your data (e.g., you could capture domain knowledge by using a custom similarity function specifically tailored to your problem). When using a features-based model, on the other hand, the model itself can learn which features are most predictive by assigning individual weights to each input feature and therefore possibly ignore irrelevant features or account for variations in heterogeneous data (of course, domain knowledge is still beneficial here, as it can, for example, guide you when engineering additional, more informative input features).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Okay, now, when should you use which approach?</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Features-based models</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>number of features should be less than the number of samples!</p>
</li>
<li>
<p>good for heterogeneous data due to individual feature weights (although scaling is usually still a good idea)</p>
</li>
<li>
<p>easier to interpret (since they describe a direct relationship between input features &amp; target)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Similarity-based models</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>non-linear models for small datasets</p>
</li>
<li>
<p>need appropriate similarity function &#8594; domain knowledge! (especially for heterogeneous data)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/04_supervised_intro/comparison_all4.png" alt="image" width="840">
</div>
<div class="title"><span class="small">This is an overview of the different features-based and similarity-based models we&#8217;ll discuss in the following chapters, as well as for which dataset size and problem complexity they are appropriate: While linear models are rather simple and&#8201;&#8212;&#8201;as the name suggests&#8201;&#8212;&#8201;only yield good results for linear problems, they are very efficient and can be applied to large datasets. Decision trees are very efficient as well, but can also capture more complex relationships between inputs and output. Similarity-based models like <em>k</em>-nearest neighbors (kNN) or their more sophisticated cousin kernel methods, on the other hand, can be used to solve very complex non-linear problems, however, as they require the computation of a similarity matrix that scales with the number of training points, they should only be applied to comparatively small datasets (~ a few thousand points). Finally, neural networks are the most sophisticated model class and can be used to solve extremely complex problems, but they are also rather data hungry (depending on the size of the network).</span></div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_model_evaluation">Model Evaluation</h3>
<div class="paragraph">
<p>Since in supervised learning problems we know the ground truth, we can now objectively evaluate different models and benchmark them against each other.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Is this a good model for the task?</strong><br>
i.e., does the model generate <em>reliable predictions</em> for <em>new data points</em>?</p>
</div>
<div class="ulist">
<ul>
<li>
<p>split the data into training and test sets to be able to get a reliable estimate of how your model will later perform when applied to new data points that it wasn&#8217;t trained on</p>
</li>
<li>
<p>quantify the quality of the model’s predictions (on the test set) with a suitable evaluation metric (depending on the problem type)<br></p>
<div class="dlist">
<dl>
<dt class="hdlist1">Evaluation metrics: </dt>
<dd>
<p><em>Regression:</em> mean absolute error, mean squared error, \(R^2\)<br>
<em>Classification:</em> (balanced) accuracy<br>
<em>Ranking:</em> <a href="https://en.wikipedia.org/wiki/Precision_and_recall">precision/recall</a> (&#8594; F1 score), hits@<em>k</em></p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>&#8658; are some mistakes worse than others? (e.g., consider false positives vs. false negatives in medical tests)<br>
&#8658; always choose <em>a single metric/KPI</em> to optimize! (maybe: additional constraints like runtime)</p>
</div>
</li>
<li>
<p>compare your model to a stupid baseline (predict mean / most frequent class)</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_evaluation_metrics">Evaluation Metrics</h4>
<div class="paragraph">
<p>First 3 evaluation metrics for regression problems, the mean absolute error, mean squared error, and \(R^2\).</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Mean absolute error (MAE)</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/error_mean_absolute.png" alt="image" width="480">
</div>
<div class="title"><span class="small">This is probably the most straightforward regression error metric and additionally easy to interpret since the error is given in the same units of measurement as the target variable (e.g., if you&#8217;re predicting a price in euros, you would know exactly by how many euros the model is off on average).</span></div>
</div>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.metrics</span> <span class="keyword">import</span> <span class="include">mean_absolute_error</span></code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Mean squared error (MSE)</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/error_mean_squared.png" alt="image" width="480">
</div>
<div class="title"><span class="small">Since this regression error metric is differentiable, it is often used internally when optimizing the parameters of a model (e.g., in linear regression). When reporting the final error of a model, one often takes the square root of the result, i.e., instead reports the root mean squared error (RMSE), since this is again in the same units as the original target variable.</span></div>
</div>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.metrics</span> <span class="keyword">import</span> <span class="include">mean_squared_error</span></code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">\(R^2\)</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/error_r2.png" alt="image" width="700">
</div>
<div class="title"><span class="small">The \(R^2\), or coefficient of determination, essentially compares the MSE of a regression model against the MSE of the stupid baseline for the regression (i.e., predicting the mean), i.e., it normalizes the MSE by the variance of the data. In the best case, the \(R^2\) is 1, i.e., when the model explains the data perfectly, and in the worst case, it can even become negative, i.e., when the model performs worse then simply predicting the mean.</span></div>
</div>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.metrics</span> <span class="keyword">import</span> <span class="include">r2_score</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Now lets look at evaluation metrics for classification problems.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Classification errors in detail</dt>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/error_class2.png" alt="image" width="560">
</div>
<div class="title"><span class="small">Most (binary) classification models predict the probability that a sample belongs to a certain class, i.e., a score between 0 and 1. By applying a threshold on this probability (typically at 0.5), the prediction score can be transformed into the class label, i.e., either predicting the positive or negative class for this sample. We distinguish between two types of mistakes that a classification model can make in this prediction: <em>false positives (FP)</em>, i.e., incorrectly predicting the positive class for samples belonging to the negative class, and <em>false negatives (FN)</em>, i.e., incorrectly predicting the negative class for samples from the positive class. Depending on the goal of your application, one type of error might be worse than the other, e.g., in a medical test you might rather tell someone that they should come in for a second test to confirm some problematic results than send them home with an undetected disease. By moving the classification threshold, you can control the trade-off between FP and FN.</span></div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Accuracy</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/error_class_accuracy.png" alt="image" width="440">
</div>
<div class="title"><span class="small">The accuracy is the most widely used classification evaluation metric, where you simply check out of all samples, how many were classified correctly (i.e., TP and TN). However, this can be misleading for unequal class distributions and you should always compare the accuracy of your model against the stupid baseline for classification, i.e., what the accuracy would be for a &#8220;model&#8221; that always predicts the most frequent class.</span></div>
</div>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.metrics</span> <span class="keyword">import</span> <span class="include">accuracy_score</span></code></pre>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Unbalanced class distributions: Accuracy vs. Balanced Accuracy</dt>
<dd>
<p>Below you see the decision boundaries of two models on a toy dataset (where the shaded background indicates whether the model would predict the blue or red class for a data point in this area). Which model do you think is more useful?</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/balanced_acc4.png" alt="image" width="640">
</div>
<div class="title"><span class="small">With unbalanced class distributions, e.g., in this case a lot more samples from the blue compared to the red class, the accuracy of a model that simply always predicts the most frequent class can be quite large. But while an accuracy of 0.9 might sound impressive when you report the performance of your model to your project&#8217;s stakeholders, this doesn&#8217;t necessarily mean that the model is actually useful, especially since in real world problems the undersampled class is often the one we care about most (e.g., people with a rare disease or products that have a defect). Instead, the balanced accuracy is often the more informative measure when evaluating classification models and can help us to distinguish between a model that has actually learned something and the stupid baseline.</span></div>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Balanced Accuracy</dt>
<dd>
<p>To avoid pitfalls of accuracy: consider misclassification rates of both classes separately:</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/error_class_balanced_accuracy.png" alt="image" width="440">
</div>
<div class="title"><span class="small">For the balanced accuracy, first the faction of correctly classified points is computed for each class individually and then these values are averaged.</span></div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.metrics</span> <span class="keyword">import</span> <span class="include">balanced_accuracy_score</span></code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Multi-class problems: micro vs. macro averaging</dt>
<dd>
<p>The accuracy and balanced accuracy scores can also be generalized for the multi-class classification case. Here we instead use the terms micro- and macro-averaging to describe the two strategies (which can also be used for other kinds of metrics like the F1-score), where micro-averaging means we compute the score by averaging over all samples, while macro-averaging means we first compute the score for each class separately and then average over the values for the different classes.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>micro-averaged score (&#8594; <code>accuracy_score</code>):</p>
</div>
<div class="stemblock">
<div class="content">
\[\begin{aligned}
\frac{TP + TN}{TP + FN + TN + FP} = \frac{TP_\text{pos} + TP_\text{neg}}{n_\text{pos} + n_\text{neg}} &amp; \quad \Rightarrow \quad \frac{\sum_c TP_{c}}{\sum_c n_{c}}
\end{aligned}\]
</div>
</div>
<div class="paragraph">
<p>\(n_{c}\) : number of samples belonging to class \(c\)<br>
\(TP_{c}\) : number of correctly classified samples from class \(c\)</p>
</div>
<div class="paragraph">
<p>macro-averaged score (&#8594; <code>balanced_accuracy_score</code>):</p>
</div>
<div class="stemblock">
<div class="content">
\[\begin{aligned}
\frac{1}{2} \left(\frac{TP}{TP+FN} + \frac{TN}{TN+FP} \right) = \frac{1}{2} \left(\frac{TP_\text{pos}}{n_\text{pos}} + \frac{TP_\text{neg}}{n_\text{neg}} \right) &amp; \quad \Rightarrow \quad \frac{1}{C} \sum_{c=1}^C \frac{TP_{c}}{n_{c}}
\end{aligned}\]
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Multi-class problems: Confusion matrix</dt>
<dd>
<p>Similarly, the table with the TP/FP/TN/FN entries can be extended for the multi-class classification case:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/confusion_matrix2.png" alt="image" width="740">
</div>
<div class="title"><span class="small">The heatmap on the left show the (normalized) confusion matrix for a 10-class classification problem (recognizing handwritten digits), while the plot on the right shows example images for each case. Examining the confusion matrix and some individual examples can give you more faith in the predictions of your model, as you might realize that some misclassifications (highlighted in red) could also happen to a human, e.g., the 4 that was classified as a 1 or even the 4 that was classified as a 7 (which might even be a labeling error from when the dataset was originally created).</span></div>
</div>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.metrics</span> <span class="keyword">import</span> <span class="include">confusion_matrix</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_model_selection">Model Selection</h4>
<div class="paragraph">
<p>After you&#8217;ve chosen an appropriate evaluation metric for your problem, you can use the resulting scores to automatically select the best model hyperparameters and ultimately the best model.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">The case for an additional validation set</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/validation_set.png" alt="image" width="480">
</div>
<div class="title"><span class="small">As we&#8217;ve established in the beginning, before experimenting with any models, the dataset should always be split into a training and test set. However, this is actually not the full picture: since you are typically experimenting with many different types of models and for each model type with dozens of hyperparameter settings, you should not use this test set to evaluate each of these model candidates, since it might happen that with all these things you try you end up choosing a model that performs really well on this test set, but then actually does not generalize to new data later and you would have no way of finding this out before deploying the model in production. Therefore, we introduce a new data split, the <strong>validation set</strong>, that is used to evaluate the different candidate models, while the test set remains locked away until you&#8217;re ready to evaluate your final model to get a realistic estimate of how it should actually perform on new data. If your original dataset is quite big, say, over 100k samples (depending on the diversity of your data, e.g., the number of classes), then it is usually enough to just split the data into training, validation, and test sets at the start, where the validation and test sets could contain about 10% of the data each and should be representative of the diversity of the original dataset. However, when the original dataset is smaller, it might not be possible to get such representative splits, which is when a technique called <em>cross-validation</em> (also abbreviated x-val) can come in very handy.</span></div>
</div>
</dd>
</dl>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Cross-Validation</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/cross_val.png" alt="image" width="540">
</div>
<div class="title"><span class="small">In a <strong><em>k</em>-fold cross-validation</strong>, the dataset is split into <em>k</em> parts, where each part is once the designated validation set, while the remaining <em>k-1</em> parts are used for training. This way, the model is trained and evaluated <em>k</em> times, each time on different splits. By computing the mean and standard deviation of the error metrics on all folds, we get a reliable estimate of the model&#8217;s generalization error and its variation due to the diversity of the dataset. The extreme case of the <em>k</em>-fold cross-validation is the <em>Leave-One-Out</em> cross-validation, where the model is always evaluated on only a single sample.</span></div>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Hyperparameter Tuning</dt>
<dd>
<p>Often it is necessary to systematically evaluate a given model with different hyperparameter settings to find the best option. One straightforward approach for doing this is a <strong>grid search</strong>. In a grid search, you define the different values you want to test for each hyperparameter and then all combinations of these different values for all hyperparameters are automatically evaluated, similar to how you would do it manually with nested for-loops. This is very useful, as often the different hyperparameter settings influence each other. Conveniently, sklearn furthermore combines this with a cross-validation. However, with many individual settings, this also comes at a computational cost, as the model is trained and evaluated \(k \times m_1 \times m_2 \times \dots \times m_i\) times, where \(k\) is the number of folds in the cross-validation and \(m_1...m_i\) are the number of values that need to be tested for each of the <em>i</em> hyperparameters of the model.<br></p>
<div class="paragraph">
<p>For example, with two hyperparameters, the grid search results could look something like the plot below, which shows a heatmap of the average accuracy achieved with each hyperparameter combination of a model in the cross-validation:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/grid_search.png" alt="image" width="360">
</div>
</div>
<div class="paragraph">
<p>While sklearn&#8217;s grid search method will always directly tell you the best hyperparameter combination out of the ones it tested (here marked with a red star), it is important to actually check the complete set of results to verify that you have <strong>covered the whole range of possible hyperparameter values</strong> that could give good results (e.g., in the plot here we see a peak in the middle with the results getting worse to the sides, i.e., we know that better hyperparameter values are unlikely to lie outside of the range we&#8217;ve tested). It is generally a good idea to first start with a large range of values and then zoom in to the area that seems most promising (and of course knowledge about the different algorithms helps a lot in choosing reasonable settings as well).<br></p>
</div>
<div class="paragraph">
<p>Besides the basic grid search, there also exist other, more advanced hyperparameter tuning routines. For example, sklearn additionally implements a randomized search, and other dedicated libraries provide even fancier approaches, such as <a href="https://machinelearningmastery.com/what-is-bayesian-optimization/">Bayesian optimization</a>.<br></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.model_selection</span> <span class="keyword">import</span> <span class="include">GridSearchCV</span>, <span class="include">RandomizedSearchCV</span></code></pre>
</div>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_supervised_learning_models">Supervised Learning Models</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now that you&#8217;re familiar with the basics of supervised learning&#8201;&#8212;&#8201;problem types, algorithmic approaches, model evaluation and selection&#8201;&#8212;&#8201;we discuss the different features- and similarity-based models in more detail (except neural networks, which are covered in the chapter on Deep Learning &amp; more):</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/04_supervised_intro/comparison_all4.png" alt="image" width="840">
</div>
</div>
<div class="sect2">
<h3 id="_linear_models">Linear Models</h3>
<div class="openblock float-group">
<div class="content">
<div class="paragraph">
<p><span class="image left"><img src="images/04_supervised_intro/comparison_linear.png" alt="image" width="180"></span></p>
</div>
<div class="paragraph">
<p>The first type of supervised learning model that we&#8217;ll look at in more detail are linear models, which are a type of features-based model that are very efficient (i.e., can be used with large datasets), but, as the name suggests, are only capable of describing linear relationships between the input and target variables.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Linear models can be used for regression problems (&#8594; the typical linear regression model that you might have already heard of) as well as for classification problems (&#8594; logistic regression, which predicts a probability score between 0 and 1):</p>
</div>
<div class="paragraph text-center">
<p><span class="image"><img src="images/05_supervised_other/linreg.png" alt="image" width="340"></span>
<span class="image"><img src="images/05_supervised_other/logreg.png" alt="image" width="340"></span></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Main idea</dt>
<dd>
<p>Prediction is a linear combination of the input features (and intercept \(b\)):</p>
</dd>
</dl>
</div>
<div class="stemblock">
<div class="content">
\[f(\mathbf{x}; \mathbf{w}) = b + \langle\mathbf{w}, \mathbf{x}\rangle = b + \sum_{k=1}^d w_k \cdot x_k = \hat{y}\]
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.linear_model</span> <span class="keyword">import</span> <span class="include">LinearRegression</span>, <span class="include">LogisticRegression</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Linear Regression</strong>:<br>
find \(\mathbf{w}\) that minimizes MSE \(\| \mathbf{y} - \mathbf{\hat y}\|_2^2\) with \(\hat y\) computed as described above</p>
</div>
<div class="paragraph">
<p><strong>Logistic Regression</strong> (&#8594; for classification problems!):<br>
make predictions as</p>
</div>
<div class="stemblock">
<div class="content">
\[\sigma\left(b + \langle\mathbf{w}, \mathbf{x}\rangle\right) = \hat y\quad\quad \text{with: } \sigma(z) = \frac{1}{1+e^{-z}} \quad \Rightarrow\; \hat y  \in [0, 1]\]
</div>
</div>
<div class="paragraph">
<p>where \(\sigma(z)\) is the so-called sigmoid (or logistic) function that squeezes the output of the linear model within the interval \([0, 1\)] (i.e., the S-curve you&#8217;ve seen in the plot at the beginning).</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>linear models are good for small datasets</p>
</li>
<li>
<p>extensions for non-linear problems exist (&#8594; feature engineering (e.g., including interaction terms), GAMs, etc.)</p>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
When a statistician tells you that he did a &#8220;polynomial regression&#8221; what he really means is that he did some feature engineering to include new variables like \(x_5^2\) and \(x_2^3x_7\) and then fitted a linear regression model on this extended set of features. I.e., the model is still linear in the parameters (i.e., the prediction is still a linear combination of the inputs), but some of the inputs are now polynomial terms of the original features.
</td>
</tr>
</table>
</div>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>regularization (to keep \(\mathbf{w}\) in check) is often a good idea</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="sect3">
<h4 id="_regularization">Regularization</h4>
<div class="paragraph">
<p>Motivation: for uncorrelated but noisy data, which model should you choose?</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_other/regularization_motivation2.png" alt="image" width="420">
</div>
</div>
<div class="paragraph">
<p>&#8658; regularization = assume no relationship between \(x\) and \(y\) unless the data strongly suggests otherwise</p>
</div>
<div class="paragraph">
<p>This is accomplished by imposing constraints on the model&#8217;s weights by adding a penalty term in the optimization:</p>
</div>
<div class="stemblock">
<div class="content">
\[\min_\mathbf{w}\; \underbrace{\sum_{i=1}^n (y_i - (b + \langle\mathbf{w},\mathbf{x}_i\rangle))^2}_{\text{Linear Regression}} + \lambda_1 \underbrace{\sum_{k=1}^d |w_k|}_{L1} + \lambda_2 \underbrace{\sum_{k=1}^d w_k^2}_{L2}\]
</div>
</div>
<div class="paragraph">
<p>This means the optimal solution now not only achieves a low MSE between the true and predicted values (i.e., the normal linear regression error), but additionally does so with the smallest possible weights. (The regularization therefore also defines a unique solution in the face of collinearity.)</p>
</div>
<div class="paragraph">
<p><strong><em>L1</em> Regularization</strong> (&#8594; Lasso Regression): sparse weights (i.e., many 0, others normal)<br>
 &#8594; good for data with possibly irrelevant features</p>
</div>
<div class="paragraph">
<p><strong><em>L2</em> Regularization</strong> (&#8594; Ridge Regression): small weights<br>
 &#8594; computationally beneficial; can help for data with outliers</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Often when you&#8217;re working with a new dataset, it might include lots of variables, many of which might not be relevant for the prediction problem. In this case, an <em>L1</em>-regularized model can be helpful to sort out irrelevant features. Then, when you are sure which input variables are relevant for the prediction problem, an <em>L2</em>-regularized model can give you a robust performance.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.linear_model</span> <span class="keyword">import</span> <span class="include">RidgeCV</span>, <span class="include">LassoLarsCV</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Regularization is also used in many other <code>sklearn</code> models. Depending on the type of model (for historical reasons), what we denoted as \(\lambda\) in the formula above is a hyperparameter that is either called <code>alpha</code> or <code>C</code>, where you have to be careful, because while for <code>alpha</code> higher values mean more regularization (i.e., this acts exactly as the \(\lambda\) in the formula above), when the model instead has the hyperparameter <code>C</code>, here higher values mean <em>less</em> regularization!
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_generalized_additive_models_gams">Generalized Additive Models (GAMs)</h4>
<div class="paragraph">
<p>GAMs are a very powerful generalization of linear models. While in a linear regression, the target variable is modeled as a sum of linear functions of the input variables (parametrized by the respective coefficients), GAMs instead fit a smooth function \(f_k(x_k)\) to each input variable and then predict the target variable as a sum of these:</p>
</div>
<div class="stemblock">
<div class="content">
\[\hat{y} = b + \sum_{k=1}^d \; w_k \cdot x_k \quad\quad \Rightarrow \quad\quad \hat{y} = b + \sum_{k=1}^d \; f_k(x_k)\]
</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_other/gam2.png" alt="image" width="740">
</div>
</div>
<div class="paragraph">
<p>&#8594; <code>gam</code> library in R; Python: <a href="https://pygam.readthedocs.io/"><code>pyGAM</code></a>, <a href="https://github.com/interpretml/interpret"><code>interpret</code></a></p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_decision_trees">Decision Trees</h3>
<div class="openblock float-group">
<div class="content">
<div class="paragraph">
<p><span class="image left"><img src="images/04_supervised_intro/comparison_dt.png" alt="image" width="180"></span></p>
</div>
<div class="paragraph">
<p>Next, we&#8217;ll look at decision trees, another type of features-based model that is very efficient as well, but can also capture more complex relationships between inputs and output.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>We&#8217;ll describe the decision tree algorithm with the help of an example dataset:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Example: Iris Dataset</dt>
<dd>
<p>The famous Iris dataset was initially studied by the influential statistician R. Fisher. It includes samples from 3 different types of Iris flowers, each described by 4 measurements. The task is to classify to which type of Iris flower a sample belongs:</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_other/iris_dataset.png" alt="image" width="640">
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Main idea</dt>
<dd>
<p>iteratively set a threshold on one of the features such that the remaining samples are split into two &#8220;cleaner&#8221; groups (where &#8220;clean&#8221; means that all samples in a group have a similar label, e.g., belong to the same class if you&#8217;re dealing with a classification problem):</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_other/decision_tree_iris2.png" alt="image" width="840">
</div>
<div class="title"><span class="small"><em>Left:</em> Scatter plot of the data, which shows how the splits of the decision tree translate into a decision surface in the feature space, which also shows the characteristic cuts orthogonal to the respective axis (&#8594; new points are classified according to the color of the shaded areas). <em>Right:</em> Illustration of the learned decision tree: starting left at the root of the tree, the first decision is made to split the data at the &#8216;petal width&#8217; feature, where all samples with a value smaller than 0.8 are classified as setosa Irises (&#8658; perfectly clean group at this leaf) and the other samples advance to a followup decision. (To come up with this decision, the decision tree algorithm basically looked at the histograms of all features to figure out for which of the features the distributions for the different classes were separated the most and then set a threshold there to split the samples.) Next, in the lower branch of the tree, the remaining samples are now split again according to their petal width and then again at their petal length (although it is a coincidence that the same variable is used in both branches at this level to make the cut). Eventually, at each leaf (i.e., terminal node of the tree), the samples that ended up there are mostly from one single class, i.e., the decision tree succeeded in splitting the dataset into cleaner groups. To classify a new sample (i.e., if you went for a walk and found an Iris flower and decided to measure it), you could now compare the flower&#8217;s measurements to the thresholds in the tree (starting at the root) and depending on the leaf you end up in you got a prediction for the Iris type as the most frequent class of the training samples that ended up in this leaf. For regression problems, the tree is built in the same way, but the final prediction is given as the mean of the target variable of the training samples in a leaf. (Please note that decision trees are normally drawn from top to bottom and, unlike real trees, their root is at the top and their branches and leaves grow towards the bottom&#8201;&#8212;&#8201;the computer scientist who came up with binary trees probably spent too much time indoors&#8230;&#8203;).</span></div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.tree</span> <span class="keyword">import</span> <span class="include">DecisionTreeClassifier</span>, <span class="include">DecisionTreeRegressor</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><span class="underline">Important Parameters:</span></p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; <code>max_depth</code>: maximum number of decisions to make about a sample</p>
</li>
<li>
<p>&#8594; <code>min_samples_leaf</code>: how many samples have to end up in each leaf (at least), to prevent overly specific leaves with only few samples</p>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>easy to interpret (i.e., you know exactly what decisions were made to arrive at the prediction)</p>
</li>
<li>
<p>good for heterogeneous data: no normalization necessary since all features are considered individually</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>if the hyperparameters (e.g., <code>min_samples_leaf</code>) aren&#8217;t set appropriately, it can happen that the tree becomes very specific and memorizes individual samples, which means it probably wont generalize well to new data points (also called &#8220;overfitting&#8221;, e.g., in the example above, one of the leaves contains only 3 samples, which might not have been a very useful split)</p>
</li>
<li>
<p>unstable: small variations in the data can lead to very different trees</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_ensemble_methods">Ensemble Methods</h3>
<div class="paragraph">
<p>What is better than one model? Multiple models!</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Main idea</dt>
<dd>
<p>train multiple models &amp; combine their predictions (regression: average; classification: most frequent class)</p>
</dd>
</dl>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; different types of models</p>
</li>
<li>
<p>&#8594; same type of model but with different hyperparameter settings (this can also include the random seed used when initializing the model, e.g., for neural networks)</p>
</li>
<li>
<p>&#8594; models trained on different subsets of the data</p>
</li>
<li>
<p>&#8594; boosting: models are trained sequentially and each additional model focuses on those data points that the previous models got wrong</p>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>more stable prediction (tip: use individual models that on their own would overfit a bit)</p>
</li>
<li>
<p>get an estimate of how certain the prediction is (how many models agree?)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>computationally expensive (depending on the models used)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Popular example</dt>
<dd>
<p><em>Random Forest</em>: multiple decision trees trained on random subsamples of the data (this exploits fact that decision trees can be sensitive to small variations in the dataset)<br></p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.ensemble</span> <span class="keyword">import</span> <span class="include">RandomForestClassifier</span>, <span class="include">RandomForestRegressor</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>For more advanced approaches, also check out the voting ensemble and boosting methods from <a href="https://scikit-learn.org/stable/modules/ensemble.html">sklearn</a>, with which you can also combine arbitrary models into an ensemble.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Ensemble methods like random forests and gradient boosting trees give very good results on real world structured datasets and dominate the leader boards for many competitions at <a href="https://www.kaggle.com/">Kaggle</a>, a website where companies can upload datasets for data scientists to benchmark themselves against each other and even win prize money. (Kaggle is also a great place to look for practice problems &amp; datasets!)
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_k_nearest_neighbors_knn">k-Nearest Neighbors (kNN)</h3>
<div class="openblock float-group">
<div class="content">
<div class="paragraph">
<p><span class="image left"><img src="images/04_supervised_intro/comparison_knn.png" alt="image" width="180"></span></p>
</div>
<div class="paragraph">
<p>The first similarity-based model we&#8217;ll look at is <em>k</em>-nearest neighbors (kNN), which follows a rather naive and straightforward approach, but nevertheless often achieves a good performance on complex problems.</p>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Main idea</dt>
<dd>
<p>For a new sample, identify the <em>k</em> most similar training data points and predict the average of their target values / their most frequent class:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_other/knn.png" alt="image" width="640">
</div>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>This kind of approach is also called <em>Lazy Learning</em>, since the model doesn&#8217;t actually learn any kind of internal parameters, but all the real computation only happens when you make a prediction for a new data point (&#8594; when calling the fit-method on the sklearn model, only a search tree is built, with which the nearest neighbors for a new data point can be identified efficiently).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.neighbors</span> <span class="keyword">import</span> <span class="include">KNeighborsRegressor</span>, <span class="include">KNeighborsClassifier</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><span class="underline">Important Parameters:</span></p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; <code>n_neighbors</code>: how many nearest neighbors to consider when making a prediction</p>
</li>
<li>
<p>&#8594; <code>metric</code>: how to compute the similarity between the samples (default: Euclidean distance)</p>
</li>
<li>
<p>&#8594; <code>weights</code>: by setting this to <code>'distance'</code> instead of the default <code>'uniform'</code>, the labels of the nearest neighbors contribute to the prediction proportionally to their distance to the new data point</p>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>intuitive approach</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>results completely depend on the similarity measure</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_kernel_methods">Kernel Methods</h3>
<div class="openblock float-group">
<div class="content">
<div class="paragraph">
<p><span class="image left"><img src="images/04_supervised_intro/comparison_kernel.png" alt="image" width="180"></span></p>
</div>
<div class="paragraph">
<p>Kernel methods are more sophisticated similarity-based models and were the hot stuff in the late 90s, when datasets were still of moderate size and computers weren&#8217;t fast enough to train large neural networks. They have some elegant math behind them, but please don&#8217;t be discouraged, if you don&#8217;t fully understand it the first time you read it&#8201;&#8212;&#8201;this is completely normal 😉.</p>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Main idea / &#8220;Kernel Trick&#8221;</dt>
<dd>
<p>by working on similarities (computed with special <em>kernel functions</em>) instead of the original features, linear methods can be applied to solve non-linear problems</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Assume there exists some function \(\phi(\mathbf{x})\) (also called a &#8216;feature map&#8217;) with which the input data can be transformed in such a way that the problem can be solved with a linear method (basically the ideal outcome of feature engineering).<br>
For example, in the simple toy dataset shown below, the two classes become linearly separable when projecting the original input features into the space of their second order monomials:</p>
</div>
<div class="paragraph text-center">
<p><span class="image"><img src="images/05_supervised_other/kernels_xspace.png" alt="image" width="340"></span> &#8594; \(\phi(\mathbf{x})\) &#8594;
<span class="image"><img src="images/05_supervised_other/kernels_zspace.png" alt="image" width="340"></span><br>
<span class="small">While in the original 2D representation on the left you would need a circle (i.e., a non-linear function) to separate the blue from the red points, in the 3D plot on the right, the data points are arranged in a cone shape, where you could cut off the red points at the tip of the cone with a hyperplane.</span></p>
</div>
<div class="paragraph">
<p>Of course, coming up with such a feature map \(\phi(\mathbf{x})\), especially for more complex problems, isn&#8217;t exactly easy. But as you will see, we don&#8217;t actually need to know what this transformation looks like!</p>
</div>
<div class="paragraph">
<p><span class="underline"><strong>Example:</strong> (Kernel) Ridge Regression</span></p>
</div>
<div class="paragraph">
<p>Remember: In a linear regression model, the prediction for a new data point \(\mathbf{x}'\) is computed as the scalar product of the feature vector with the weight vector \(\mathbf{w}\):</p>
</div>
<div class="stemblock">
<div class="content">
\[\hat{y}' = \mathbf{x}' \mathbf{w}\]
</div>
</div>
<div class="paragraph">
<p>(for simplicity, we omit the bias term here; using a bias term is equivalent to including an additional input feature that is always 1).</p>
</div>
<div class="paragraph">
<p>The parameters of a linear ridge regression model are found by taking the derivative of the objective function,</p>
</div>
<div class="stemblock">
<div class="content">
\[\| \mathbf{y} - \mathbf{Xw}\|_2^2 + \lambda \| \mathbf{w}\|_2^2\]
</div>
</div>
<div class="paragraph">
<p>with respect to \(\mathbf{w}\), setting it to 0, and solving for \(\mathbf{w}\) (i.e. to find the minimum). This gives the following solution:</p>
</div>
<div class="stemblock">
<div class="content">
\[\mathbf{w} = (\mathbf{X}^\top \mathbf{X} +\lambda I)^{-1}\mathbf{X}^\top \mathbf{y}\]
</div>
</div>
<div class="paragraph">
<p>where \(\mathbf{X} \in \mathbb{R}^{n \times d}\) is the feature matrix of the training data and \(\mathbf{y} \in \mathbb{R}^n\) are the corresponding target values.</p>
</div>
<div class="paragraph">
<p>Now we replace every occurrence of the original input features \(\mathbf{x}\) in the formulas with the respective feature map \(\phi(\mathbf{x})\) and do some linear algebra:</p>
</div>
<div class="stemblock">
<div class="content">
\[\begin{aligned}
\hat{y}' &amp;= \phi(\mathbf{x}') \mathbf{w} \quad\quad\quad\text{ with }\; \mathbf{w} = (\phi(\mathbf{X})^\top \phi(\mathbf{X}) +\lambda I)^{-1}\phi(\mathbf{X})^\top \mathbf{y}\\
&amp;= \phi(\mathbf{x}') (\phi(\mathbf{X})^\top \phi(\mathbf{X}) +\lambda I)^{-1}\phi(\mathbf{X})^\top \mathbf{y}\\
&amp; \quad\quad\vdots\\
&amp;= \underbrace{\phi(\mathbf{x}')\phi(\mathbf{X})^\top}_{\mathbf{k}'= k(\mathbf{x'}, \mathbf{X})} (\underbrace{\phi(\mathbf{X}) \phi(\mathbf{X})^\top}_{\mathbf{K} = k(\mathbf{X}, \mathbf{X})} +\lambda I)^{-1} \mathbf{y}\\
&amp;= \mathbf{k}'\underbrace{(\mathbf{K}  +\lambda I)^{-1} \mathbf{y}}_{\mathbf{\alpha}} = \sum_{i=1}^n k(\mathbf{x}', \mathbf{x}_i) \alpha_i
\end{aligned}\]
</div>
</div>
<div class="paragraph">
<p>After the reformulation, every \(\phi(\mathbf{x})\) only occurs in scalar products with other \(\phi(\mathbf{x})\), and all these scalar products were replaced with a so-called <em>kernel function</em> \(k(\mathbf{x}', \mathbf{x})\), where \(k(\mathbf{X}, \mathbf{X}) = \mathbf{K} \in \mathbb{R}^{n \times n}\) is the <em>kernel matrix</em>, i.e., the similarity of all training points to themselves, and \(k(\mathbf{x}', \mathbf{X}) = \mathbf{k}' \in \mathbb{R}^{n}\) is the <em>kernel map</em>, i.e., the similarities of the new data point to all training points.</p>
</div>
<div class="paragraph">
<p>Now the prediction \(\hat{y}'\) is computed as a weighted sum of the similarities in the kernel map, i.e., where in the normal linear regression model the sum goes over the number of input features <em>d</em> and the weight vector is denoted as \(\mathbf{w}\), here the sum goes over the number of data points <em>n</em> and the weight vector is called \(\mathbf{\alpha}\).</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Kernel Functions</strong></p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A kernel function is basically a similarity function, but with the special requirement that the similarity matrix computed using this function, also called the <em>kernel matrix</em>, is positive semi-definite, i.e., has only eigenvalues \(\geq 0\).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>There exist different kinds of kernel functions and depending on how they are computed, they induce a different kind of kernel feature space \(\phi(\mathbf{x})\), where computing the kernel function for two points would be the same as computing the scalar product of their vectors in this kernel feature space.</p>
</div>
<div class="paragraph">
<p>Think back to the initial example, where the data was projected into the space of second order monomials. When we compute the scalar product between the feature maps of two vectors \(\mathbf{a}\) and \(\mathbf{b}\), we arrive at a polynomial kernel of second degree:</p>
</div>
<div class="stemblock">
<div class="content">
\[\langle\phi(\mathbf{a}), \phi(\mathbf{b})\rangle = (a_1^2, \sqrt{2}a_1a_2, a_2^2)(b_1^2, \sqrt{2}b_1b_2, b_2^2)^\top
= \langle\mathbf{a}, \mathbf{b}\rangle^2
=: k(\mathbf{a}, \mathbf{b})\]
</div>
</div>
<div class="paragraph">
<p>i.e, computing the kernel function \(k(\mathbf{a}, \mathbf{b})\) between the two points is the same as computing the scalar product of the two feature maps \(\langle\phi(\mathbf{a}), \phi(\mathbf{b})\rangle\). While for the polynomial kernel of second degree, \(\langle\mathbf{a}, \mathbf{b}\rangle^2\), we could easily figure out that the feature map consisted of the second order monomials, for other kernel functions, the corresponding feature map is not that easy to identify and the kernel feature space might even be infinite dimensional. However, since all the feature map terms \(\phi(\mathbf{x})\) in the kernel ridge regression formulas only occurred in scalar products, we could replace them by a kernel function (which we can compute using the original input feature vectors), therefore, we don&#8217;t actually need to know what the respective feature map looks like for other kernel functions!</p>
</div>
<div class="paragraph">
<p>So while kernel methods are internally working in this really awesome kernel feature space \(\phi(\mathbf{x})\), induced by the respective kernel function, where all our problems are linear, all we need to know is how to compute the kernel function using the original feature vectors.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If you are curious what the kernel feature space looks like for some kernel function, you can use Kernel PCA to get an approximation of \(\phi(\mathbf{x})\). Kernel PCA computes the eigendecomposition of a given kernel matrix, thereby generating a new representation of the data such that the scalar product of these new vectors approximates the kernel matrix. This means, the new kernel PCA feature vector you computed for some data point \(i\) approximates \(\phi(\mathbf{x}_i)\)&#8201;&#8212;&#8201;however, this still doesn&#8217;t tell you what the function \(\phi\) itself looks like (i.e., how to get from \(\mathbf{x}\) to \(\phi(\mathbf{x})\)), you only get (an approximation of) the final result \(\phi(\mathbf{x})\).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the example above you were already introduced to the polynomial kernel of second degree; the generalization, i.e., the polynomial kernel of degree <em>k</em>, is computed as \(\langle\mathbf{x}', \mathbf{x}_i\rangle^k\).</p>
</div>
<div class="paragraph">
<p>The most popular kernel function that works well in many use cases is the <strong>Radial Basis Function (RBF) / Gaussian kernel</strong>:</p>
</div>
<div class="stemblock">
<div class="content">
\[k(\mathbf{x}', \mathbf{x}_i) = e^{-\gamma \|\mathbf{x}_i - \mathbf{x}' \|^2}\]
</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_other/rbf2.png" alt="image" width="540">
</div>
<div class="title"><span class="small">With the RBF kernel function, the similarity of a new point \(\mathbf{x}'\) to the training sample \(\mathbf{x}_i\) is computed by centering a Gaussian function (with a width inversely proportional to \(\gamma\)) over the \(i^{th}\) training sample and then checking where the new point falls on this curve. Depending on the choice of \(\gamma\), either many samples will later contribute to the prediction (if the Gaussian function is very wide and therefore the similarity to multiple training points will be large) or only the closest points will be considered (if the curve is very narrow and therefore the similarity to most training examples would be close to 0).</span></div>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Support Vector Machine (SVM)</dt>
<dd>
<p>A more efficient method, especially when the training set is large.<br>
<span class="underline">Key idea:</span> only compute similarity to &#8216;critical&#8217; training points (= support vectors):</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_other/svm.png" alt="image" width="440">
</div>
</div>
<div class="stemblock">
<div class="content">
\[\sum_{i=1}^n k(\mathbf{x}', \mathbf{x}_i) \alpha_i  \quad \Rightarrow \quad  \sum_{i \in \{\text{SV}\}} k(\mathbf{x}', \mathbf{x}_i) \alpha_i\]
</div>
</div>
<div class="paragraph">
<p>This reduces the memory requirements and makes the prediction for new data points much faster, since it is only necessary to store the support vectors and compute the similarity to them instead of the whole training set.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.decomposition</span> <span class="keyword">import</span> <span class="include">KernelPCA</span>     <span class="comment"># Kernel variant of PCA</span>
<span class="keyword">from</span> <span class="include">sklearn.kernel_ridge</span> <span class="keyword">import</span> <span class="include">KernelRidge</span>    <span class="comment"># Kernel variant of ridge regression (-&gt; use SVR instead)</span>
<span class="keyword">from</span> <span class="include">sklearn.svm</span> <span class="keyword">import</span> <span class="include">SVC</span>, <span class="include">SVR</span>                <span class="comment"># SVM for classification (C) and regression (R)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><span class="underline">Important Parameters:</span></p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; <code>kernel</code>: the kernel function used to compute the similarities between the points (&#8594; see <code>sklearn.metrics.pairwise</code>; usually <code>'rbf'</code>)</p>
</li>
<li>
<p>&#8594; additionally: kernel parameters, e.g., <code>gamma</code> for <code>'rbf'</code> kernel</p>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>non-linear predictions with global optimum</p>
</li>
<li>
<p>fast to train (on medium size datasets; compared to, e.g., neural networks)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>computationally expensive for large datasets (kernel matrix: \(\mathcal{O}(n^2)\))</p>
</li>
<li>
<p>kernel functions, just like other similarity functions, benefit if heterogeneous data is scaled</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_deep_learning_more">Deep Learning &amp; more</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now that we&#8217;ve discussed different unsupervised and supervised learning methods, we explore some other special-purpose models (except reinforcement learning), which can be used to solve somewhat less straightforward problems:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/ml_goals_other.png" alt="image" width="840">
</div>
</div>
<div class="sect2">
<h3 id="_information_retrieval_similarity_search">Information Retrieval (Similarity Search)</h3>
<div class="paragraph">
<p>The goal of information retrieval is to identify similar items given some query:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_other/inforetr.png" alt="image" width="640">
</div>
<div class="title"><span class="small">Just like in the reverse Google image search, we here use as input a query image and get as a result the <em>k</em> images that are most similar to it.</span></div>
</div>
<div class="paragraph">
<p>This can be accomplished by building a nearest neighbors search tree (i.e., just like for the k-nearest neighbors algorithm, only that here we return the neighbors directly instead of using them to predict the label for the new data point).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.neighbors</span> <span class="keyword">import</span> <span class="include">NearestNeighbors</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>But of course, the success of this approach is again highly dependent on being able to compute meaningful similarities between the data points. For text datasets, information retrieval often works quite well by using simple TF-IDF feature vectors together with a cosine similarity, however, for images, for example, out-of-the-box similarity measures that operate directly on the original input features (i.e., pixel values) are only able to identify images with similar colors, not necessarily similar content (e.g., an image showing a black cat would be more similar to an image showing a black dog than a white cat). To get around this problem, we could use neural networks to obtain a more informative feature representation, with which it is then easier to compute meaningful semantic similarities.</p>
</div>
</div>
<div class="sect2">
<h3 id="_deep_learning_neural_networks">Deep Learning (Neural Networks)</h3>
<div class="openblock float-group">
<div class="content">
<div class="paragraph">
<p><span class="image left"><img src="images/04_supervised_intro/comparison_nn.png" alt="image" width="180"></span></p>
</div>
<div class="paragraph">
<p>The next topic is &#8220;deep learning&#8221;, i.e., neural networks, the most sophisticated model class, which can be used to solve extremely complex problems (besides regular supervised learning task), but that are also rather data hungry (depending on the size of the network).</p>
</div>
</div>
</div>
<div class="sidebarblock text-center">
<div class="content">
<div class="paragraph">
<p><strong>Basic Math</strong></p>
</div>
<div class="stemblock">
<div class="content">
\[\begin{aligned}
\begin{pmatrix}
W_{11} &amp; W_{12} &amp; \cdots &amp; W_{1j}\\
W_{21} &amp; W_{22} &amp; \cdots &amp; W_{2j}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
W_{i1} &amp; W_{i2} &amp; \cdots &amp; W_{ij}\\
\end{pmatrix}
\end{aligned}\]
</div>
</div>
<div class="paragraph">
<p><strong>Dangerous Artificial Intelligence</strong></p>
</div>
<div class="stemblock">
<div class="content">
\[\begin{aligned}
\begin{pmatrix}
W_{11} &amp; W_{12} &amp; \cdots &amp; W_{1j}\\
W_{21} &amp; W_{22} &amp; \cdots &amp; W_{2j}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
W_{i1} &amp; W_{i2} &amp; \cdots &amp; W_{ij}\\
\end{pmatrix} \cdot
\begin{pmatrix}
W_{11} &amp; W_{12} &amp; \cdots &amp; W_{1k}\\
W_{21} &amp; W_{22} &amp; \cdots &amp; W_{2k}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
W_{j1} &amp; W_{j2} &amp; \cdots &amp; W_{jk}\\
\end{pmatrix} \cdot
\begin{pmatrix}
W_{11} &amp; W_{12} &amp; \cdots &amp; W_{1l}\\
W_{21} &amp; W_{22} &amp; \cdots &amp; W_{2l}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
W_{k1} &amp; W_{k2} &amp; \cdots &amp; W_{kl}\\
\end{pmatrix} \cdot
\begin{pmatrix}
W_{11} &amp; W_{12} &amp; \cdots &amp; W_{1m}\\
W_{21} &amp; W_{22} &amp; \cdots &amp; W_{2m}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
W_{l1} &amp; W_{l2} &amp; \cdots &amp; W_{lm}\\
\end{pmatrix}
\end{aligned}\]
</div>
</div>
<div class="paragraph">
<p><span class="small">Deep learning just means using more matrices.</span></p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_overview">Overview</h4>
<div class="dlist">
<dl>
<dt class="hdlist1">Recap: Linear Models</dt>
<dd>
<p>Prediction is a linear combination of input features (and intercept / bias term \(b\)):</p>
<div class="stemblock">
<div class="content">
\[f(\mathbf{x}; \mathbf{w}) = b + \langle\mathbf{w},\mathbf{x}\rangle = b + \sum_{k=1}^d w_k \cdot x_k = \hat{y}\]
</div>
</div>
<div class="paragraph">
<p>In the case of multiple outputs \(\mathbf{y}\) (e.g., in a multi-class classification problem, where \(\mathbf{y}\) could contain the probabilities for all classes):</p>
</div>
<div class="stemblock">
<div class="content">
\[f(\mathbf{x}; W) = \mathbf{x^\top}W = \mathbf{\hat{y}}\]
</div>
</div>
<div class="paragraph">
<p>(for simplicity, we omit the bias term \(b\) here; using a bias term is equivalent to including an additional input feature that is always 1).</p>
</div>
</dd>
<dt class="hdlist1">Intuitive Explanation of Neural Networks</dt>
<dd>
<p><span class="small">[Adapted from: &#8220;AI for everyone&#8221; by Andrew Ng (coursera.org)]</span></p>
<div class="paragraph">
<p>A very simple linear model with one input and one output variable and a non-linearity:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/neural_network_intuitive_a4.png" alt="image" width="440">
</div>
<div class="title"><span class="small">Let&#8217;s say you have an online shop and are trying to predict how much of a product you will sell in the next month. The price you are willing to sell the product for will obviously influence the demand, as people are trying to get a good deal, i.e., the lower the price, the higher the demand; a negative correlation that can be captured by a linear model. However, the demand will never be below zero (i.e., when the price is very high, people wont suddenly return the product), so we need to adapt the model such that the predicted output is never negative. This can be achieved by applying the max function, in this context also called a non-linear activation function (a <em>rectified linear unit</em> (ReLU) to be more precise), to the output of the linear model, so that now when the linear model would return a negative value, we instead predict 0. Together, this functional relationship can be visualized as a circle with one input <em>(price)</em> and one output <em>(demand)</em>, where the incoming arrow represents the weight multiplied with the input feature and the S-curve in the circle indicates that a non-linear activation function is applied to the result. We will later see these circles as a single unit or &#8220;neuron&#8221; of a neural network.</span></div>
</div>
<div class="paragraph">
<p>Usually, even with linear models you have multiple inputs:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/neural_network_intuitive_b2.png" alt="image" width="540">
</div>
<div class="title"><span class="small">Using additional input variables will probably improve your prediction. You already know how to include them in a linear model.</span></div>
</div>
<div class="paragraph">
<p>To further improve the performance, you could now manually construct more informative features from the original inputs by combining them in meaningful ways (&#8594; feature engineering) before computing the output:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/neural_network_intuitive_b6.png" alt="image" width="540">
</div>
<div class="title"><span class="small">You can probably come up with a few more informative features, derived from the original input variables, to further improve the prediction accuracy. For example, since you&#8217;re running an online shop, the customers also have to pay shipping fees, which means to reflect the true affordability of the product, you actually need to combine the product price with the shipping costs. Next, the customers are interested in high quality products. However, not only the actual quality of the raw materials you used to make your product influences how your customers perceive the product, but you can also reinforce the impression that your product is of high quality with a marketing campaign. Furthermore, a high price also suggests that your product is superior. This means by creating these additional features, the price can actually contribute in two ways towards the final prediction: while, on the one hand, a lower price is beneficial for the affordability of the product, a higher price, on the other hand, will result in a larger perceived quality. While in this toy example it was possible to construct such features manually, the nice thing about neural networks is that they do exactly that automatically: By using multiple layers, i.e., stacking multiple linear models (with non-linear activation functions) on top of each other, it is possible to create more and more complex combinations of the original input features, which can improve the performance of the model.</span></div>
</div>
<div class="paragraph">
<p>&#8658; the power of neural networks comes from constructing more meaningful feature representations automatically by using multiple layers (i.e., by being &#8220;deep&#8221;).</p>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Since different tasks (and especially different types of input data) benefit from different feature representations, there exist different types of neural network architectures to accommodate this, e.g.</p>
</div>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; Feed Forward Neural Networks (FFNNs) for &#8216;normal&#8217; data</p>
</li>
<li>
<p>&#8594; Convolutional Neural Networks (CNNs) for images</p>
</li>
<li>
<p>&#8594; Recurrent Neural Networks (RNNs) for sequential data like text or time series</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>We will talk about these different architectures in more detail in the next section.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>state-of-the-art performance (especially on data with <a href="https://towardsdatascience.com/geometric-foundations-of-deep-learning-94cdd45b451d">input invariances</a>)</p>
</li>
<li>
<p>prediction for new test points is fast (just a few matrix multiplications)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>can take a long time to train (use a GPU!!! (or <a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit">TPU</a>))</p>
</li>
<li>
<p>need a lot of data (depending on the size of the NN architecture)</p>
</li>
<li>
<p>solution only a local optimum (which is usually not too problematic in practice, as there are many good optima)</p>
</li>
<li>
<p>tricky to train: performance depends on many parameters like learning rate, batch size, and even the random seed used when initializing the weights!</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_nn_architectures">NN architectures</h4>
<div class="paragraph">
<p>Just like domain-specific feature engineering can result in vastly improved model performances, it really pays off to construct a neural network architecture tailored to the task.</p>
</div>
<div class="sect4">
<h5 id="_feed_forward_neural_network_ffnn">Feed Forward Neural Network (FFNN)</h5>
<div class="paragraph">
<p>This is the original and most straightforward neural network architecture, which you&#8217;ve already seen in the initial example. Each layer here is basically a linear model, i.e., it consists of a weight matrix \(W_i\) and some non-linear activation function \(\sigma_i\) that is applied to the output. These layers are applied sequentially to the input features \(\mathbf{x}\), i.e., the network computes a composite function (in this case for 3 layers):</p>
</div>
<div class="stemblock">
<div class="content">
\[f(\mathbf{x}) = \sigma_3(\sigma_2(\sigma_1(\mathbf{x^\top}W_1)W_2)W_3) = \mathbf{\hat{y}}\]
</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/neural_network.png" alt="image" width="840">
</div>
<div class="title"><span class="small">Feed Forward Neural Network (FFNN) architecture: The input feature vector \(\mathbf{x}\), representing one data point, is multiplied by the first weight matrix \(W_1\) to create a new vector, which, after applying the non-linear activation function (e.g., a ReLU function as we&#8217;ve seen in the initial example) results in the first hidden layer representation \(\mathbf{x}'\). This new vector is then multiplied by the second weight matrix \(W_2\) and again a non-linear activation function is applied to yield the second hidden layer representation of the sample, \(\mathbf{x}''\). Depending on how many layers the network has (i.e., how deep it is), this could be repeated multiple times now until finally the last layer computes the output \(\mathbf{\hat{y}}\). For a regression problem, the output would be a direct prediction of the target values (i.e., without applying a final non-linear activation function), while for a classification problem, the output consists of a vector with probabilities for the different classes, created by applying a softmax activation function on the output, which ensures all values are between 0 and 1 and sum up to 1.</span></div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Test your understanding</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Why do you need the non-linear activation functions between the layers, i.e., how could you simplify a network with multiple layers, if it didn&#8217;t have any non-linear activation functions between the layers?</p>
</li>
<li>
<p>In what way could you manipulate the parameters (i.e., weight matrices) of an existing neural network without changing its predictions? (This is also a reason why there exist many equally good local optima.)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Number of hidden layers and units: </dt>
<dd>
<p>While the size of the input and output layers are determined by the number of input features and targets respectively, the dimensionality and number of hidden layers of the network is up to you (usually, the hidden layers get smaller (i.e., have fewer units) as the data moves from the input to the output layer and when experimenting with different settings you can start with no hidden layers (which should give you the same result as with a linear model) and then progressively increase the size of the network until the performance stops improving).</p>
</dd>
</dl>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Training Neural Networks</dt>
<dd>
<p>To train a neural network, one first needs to choose the loss function that should be optimized (e.g., mean squared error for regression problems or cross-entropy for classification problems).<br></p>
<div class="paragraph">
<p>While for a linear regression model, the optimal weights could be found analytically by setting the derivative of this loss function to 0 and solving for the weights, in a network with multiple layers and therefore many more weights, this is not feasible. Instead, the weights are tuned iteratively using a <strong>gradient descent</strong> procedure, where the derivative of the loss function w.r.t. each layer is computed step by step using the chain rule by basically pushing the error backwards through the network (i.e., from the output, where the error is computed, to the input layer), also called error <strong>backpropagation</strong>. Along the way, the weights are then adapted according to their gradient, such that the next time the same samples are passed through the network, the prediction will be closer to the true output (and the value of the error function is closer to a local minima). Since a training set usually contains lots of data points, it would be too computationally expensive to do gradient descent based on the whole dataset at once and instead one uses mini-<strong>batches</strong>, i.e., subsets of 16-128 data points, for each training step.<br></p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/loss_surface.png" alt="image" width="460">
</div>
<div class="title"><span class="small">Training loss surface over the network&#8217;s parameter space (simplified, i.e., showing only two weights (\(\theta_1\) and \(\theta_2\)), while in reality, this would be a super complex non-linear function), where every possible weight configuration of a network results in a different loss on the training set. By taking a step into the direction of steepest descent of this loss function, the weights of the network get closer to a configuration where the loss is at a local minimum.</span></div>
</div>
<div class="paragraph">
<p>At the beginning, all weight matrices are randomly initialized, so, for example, in the classification problem, for a given sample the network would predict approximately equal probabilities for all classes. Typically, the weights are adapted over multiple <strong>epochs</strong>, where one epoch means going over the whole training set once.
By plotting the <a href="https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/">learning curves</a>, i.e., the training and validation loss against the number of training epochs, one can check whether the training was successful (i.e., whether the weights have converged to a good solution).</p>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_recurrent_neural_network_rnn">Recurrent Neural Network (RNN)</h5>
<div class="paragraph">
<p>Recurrent neural networks are great for sequential data such as time series data or text (i.e., a sequence of words).</p>
</div>
<div class="paragraph">
<p>In its simplest form, a RNN is like a FFNN, but with additional recurrent connections \(W_h\) in the hidden layer to create a memory of the past:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/rnn2.png" alt="image" width="460">
</div>
</div>
<div class="paragraph">
<p>It&#8217;s easiest when thinking about the RNN unrolled in time:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/rnn_unrolled2.png" alt="image" width="540">
</div>
<div class="title"><span class="small">At the beginning of a new sequence, the hidden state \(\mathbf{x}'_0\) is initialized with zeros. Then for each new sample \(\mathbf{x}_t\) (with \(t \in \{1, ..., T\}\)) in the sequence, the hidden state is updated based on this new input (after multiplying \(\mathbf{x}_t\) with \(W_1\)), as well as the previous hidden state at \(t-1\) (by multiplying  \(\mathbf{x}'_{t-1}\) with \(W_h\)). From this new hidden state \(\mathbf{x}'_t\), the output for this time step can then be predicted (by multiplying \(\mathbf{x}'_t\) with \(W_2\)). While this network only includes a single recurrent layer, a more complex architecture could also contain multiple such layers.</span></div>
</div>
<div class="paragraph">
<p>The original RNN layer uses a very simple update rule for the hidden state, but there also exist more advanced <a href="https://towardsdatascience.com/44e9eb85bf21">types of RNNs</a>, like the Long Short Term Memory (LSTM) network or Gated Recurrent Units (GRU), which define more complex rules for how to combine the new input with the existing hidden state, i.e., they learn in more detail what to remember and which parts to forget, which can be beneficial when the data consists of longer sequences.</p>
</div>
<div class="paragraph">
<p>The cool thing about RNNs is that they can process input sequences of varying length (where one sequence represents one data point, e.g., a text document). Whereas all methods that we&#8217;ve discussed so far always expected the feature vectors that represent one data point to have a fixed dimensionality, for RNNs, while the input at a single time step (i.e., \(\mathbf{x}_t\) with \(t \in \{1, ..., T\}\)) is also a feature vector of a fixed dimensionality, the sequences themselves do not need to be of the same length \(T\) (e.g., text documents can consist of different numbers of words). This comes in especially handy for time series analysis, as you&#8217;ll see in the next chapter.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Useful in Natural Language Processing (NLP):</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">RNNs can take word order into account, which is ignored in TF-IDF vectors</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_nlp/rnn_wordemb.png" alt="image" width="440">
</div>
<div class="title"><span class="small">This is an example architecture for a sentence classification task (e.g., sentiment analysis, i.e., deciding whether the text is positive or negative). The individual words in the sentence are represented as so-called word embeddings, which are just <em>d</em>-dimensional vectors that contain some (learned) information about the individual words (e.g., whether the word is more male or female; how these embeddings are created is discussed in the section on self-supervised learning below). The RNN is then fed the sentence word by word and at the end of the sentence, the final hidden state (which contains the accumulated information of the whole sentence) is used to make the prediction. Since the RNN processes the words in the sentence sequentially, the order of the words is taken into account (e.g., whether a &#8220;not&#8221; occurred before an adjective), and since we use word embeddings as inputs, which capture semantic and syntactic information about the words, similarity between individual words (e.g., synonyms) is captured, thereby creating more meaningful representations of text documents compared to TF-IDF vectors (at the expense of greater computational complexity).</span></div>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_convolutional_neural_network_cnn">Convolutional Neural Network (CNN)</h5>
<div class="paragraph">
<p>Manual feature engineering for computer vision tasks is incredibly difficult. While humans recognize a multitude of objects in images without effort, it is hard to describe <em>why</em> we can identify what we see, e.g., which features allow us to distinguish a cat from a small dog. Deep learning had its first breakthrough success in this field, because neural networks, in particular CNNs, manage to learn meaningful feature representations of visual information through a hierarchy of layers.</p>
</div>
<div class="paragraph">
<p>Convolutional neural networks are very well suited for processing visual information, because they can operate on the 2D images directly and do not need the input to be flattened into a vector. Furthermore, they utilize the fact that images are composed of a lot of local information (e.g., eyes, nose, and mouth are all localized components of a face).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/cnn.png" alt="image" width="840">
</div>
<div class="title"><span class="small">CNNs utilize two important operations, convolutions and pooling layers, to generate meaningful feature representations: A <a href="https://en.m.wikipedia.org/wiki/Convolution">convolution</a> is computed by taking a small filter patch (e.g., a \(5 \times 5\) matrix) and moving it over the image pixel by pixel and row by row, at each position multiplying the filter with the image (see also <a href="https://youtu.be/Oqm9vsf_hvU?t=275">this animation</a>). This results in a feature map of the same size as the original image, where a high value at some position indicates that the respective feature in the filter (e.g., an edge with a specific orientation) was detected at this position in the original image. Since this is done for multiple filters, the output after a convolutional layer consists of as many new feature maps as the layer had filters. The filter patches (i.e., multiple small matrices) are the learned weights of the CNN, and after training they can look something like the small tiles shown below the network architecture. The pooling layers then perform a subsampling of the individual feature maps by taking the max (or sometimes mean) value of multiple pixels in a small area. This reduces the dimensionality of the hidden layer representation, thereby improving the computational efficiency. Additionally, the pooling introduces some positional invariance, since it is not important anymore where exactly in some area a detected feature was, e.g., a face can be recognized even if the eyes of one person are further apart than usual or they have a longer nose, etc. Usually, the convolutional and pooling layers are interleaved, however, there is no strict rule saying that a pooling layer always has to follow a convolutional layer. With more layers, more and more complex features can be detected as a composition of the features identified in the lower layers (notice how the filters first detect edges, then individual components of a face, then full faces), i.e., by making the network deeper, we can solve more complex tasks. Finally, after multiple convolution and pooling layers, the feature representation is flattened into a vector and fed to a FFNN to perform the classification.</span></div>
</div>
<div class="paragraph">
<p>Compared to the dense / fully-connected layers in FFNNs, which consist of one huge matrix mapping from one layer to the next, the filter patches used in convolutional layers are very small, i.e., there are less parameters that need to be learned. Furthermore, the fact that the filters are applied at every position in the image has a regularizing effect, since the filters need to be general enough capture relevant information in multiple areas of the images.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
By the way, the edge filters typically learned in the first layer of a CNN nicely match the <a href="https://en.wikipedia.org/wiki/Gabor_filter">Gabor filters</a> used in early computer vision feature engineering attempts. Combined with the subsequent pooling operation, they compute something similar as the <a href="https://towardsdatascience.com/45afa1046f7f">simple and complex cells</a> in the human primary visual cortex.
</td>
</tr>
</table>
</div>
</div>
<div class="sect4">
<h5 id="_general_principles_advanced_architectures">General Principles &amp; Advanced Architectures</h5>
<div class="paragraph">
<p>When trying to solve a problem with a NN, always consider that the network needs to understand the inputs, as well as generate the appropriate outputs:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/nn_architectures4.png" alt="image" width="740">
</div>
<div class="title"><span class="small">As we&#8217;ve seen in the CNN used for image classification in the previous section, the representation generated by the CNN is at some point flattened and a FFNN then computes the final prediction for the classification task. Similarly, the final hidden state of a RNN, representing the information contained in a sentences, can be passed to a FFNN to generate a prediction (e.g., for sentiment analysis). However, some problems do not fall into the category of simple supervised learning tasks (i.e., regression or classification), and require a different output. For example, in machine translation, the output should be the sentence translated into the other language, which can be achieved by coupling two RNNs: the first &#8216;understands&#8217; the sentence in the original language and this representation of the meaning of the sentence is then passed to a second RNN, which generates from it the translated sentence word by word. (If you need to translate texts from and to multiple languages, this can be done very efficiently by using just one input and one output network for each language and have them operate on the same meaning representations, i.e., instead of learning multiple pairs of networks for each language combination individually, you only learn for each language one network to understand this language and one network to generate output sentences in this language.) Another example would be the task of image captioning (i.e., generating text describing what can be seen on an image, e.g., to improve the online experience for the visually impaired), where first the image is &#8216;understood&#8217; by a CNN and then this representation of the input image is passed to a RNN to generate the matching text.</span></div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Here are two examples of neural network architectures that deal with somewhat unusual inputs and outputs and incorporate a lot of domain knowledge, which enables them to achieve state-of-the-art performance on the respective tasks:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Predicting the 3D structure of a protein from its amino acid sequence with Alpha Fold</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/01_alphafold_nn.png" alt="image" width="840">
</div>
<div class="title"><span class="small">https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology (30.11.2020)</span></div>
</div>
</dd>
<dt class="hdlist1">Predicting properties of molecules with SchNet (which is an example of a <a href="https://www.youtube.com/watch?v=uF53xsT7mjc">Graph Neural Network (GNN)</a>)</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/schnet.png" alt="image" width="840">
</div>
<div class="title"><span class="small">Schütt, Kristof T., et al. &#8220;Quantum-chemical insights from deep tensor neural networks.&#8221; <em>Nature communications</em> 8.1 (2017): 1-8.</span></div>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tips_tricks">Tips &amp; Tricks</h4>
<div class="sect4">
<h5 id="_self_supervised_transfer_learning">Self-Supervised &amp; Transfer Learning</h5>
<div class="paragraph">
<p><a href="https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/"><strong>Self-supervised learning</strong></a> is a very powerful technique with which neural networks can learn meaningful feature representations from unlabeled data. Using this technique is cheap since, like in unsupervised learning, it does not require any labels generated by human annotators. Instead, pseudo labels are generated from the inputs themselves by masking parts of it. For example, a network could be trained by giving it the first 5 words of a sentence as input and then asking it to predict what the next word should be. This way, the network learns some general statistics and knowledge about the world, similar to how human brains interpolate from the given information (e.g., in the <a href="https://en.wikipedia.org/wiki/Blind_spot_(vision)">blind spot test</a> you can nicely observe how your brain predicts missing information from the given context). Self-supervised learning is often used to &#8220;pretrain&#8221; a neural network before using it on a supervised learning task (see transfer learning below).</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>NLP Example: <strong>Neural Network Language Models</strong> (e.g., <code>word2vec</code> &#8594; have a look at <a href="https://jalammar.github.io/illustrated-word2vec/">this blog article</a> for more details) use self-supervised learning to generate word embeddings that capture semantic &amp; syntactic relationships between the words (which is ignored in TF-IDF vectors, where each word dimension has the same distance to all other words):</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_nlp/word2vec.png" alt="image" width="640">
</div>
<div class="title"><span class="small">The learned word embeddings can be used to solve analogy questions like those posed in an IQ test, e.g., "<em>man</em> is to <em>king</em> as <em>women</em> is to <em>XXX</em>", where the correct answer would be <em>queen</em>. This can be solved with vector arithmetic, i.e., by taking the word embedding for <em>king</em>, subtracting from it the embedding for <em>man</em>, adding the embedding for <em>women</em> and then checking which word embedding is closest to this new vector (which should be the embedding for <em>queen</em>).</span></div>
</div>
<div class="paragraph">
<p>&#8594; these word embedding vectors can then be used as input to a RNN</p>
</div>
</div>
</div>
<div class="paragraph">
<p><strong>Transfer learning</strong> is the idea of using what a network has learned before on a different task (e.g., a self-supervised learning task) as a starting point when tackling a new task. In practice, this means the weights of the network are initialized with (some of) the weights of a network trained on another task, before training the network on the new task. We also say that the network was pretrained on a source task before it is fine-tuned on the target task.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/transfer_learning_nn.png" alt="image" width="760">
</div>
<div class="title"><span class="small">From an old project, you have a network that was trained on a large dataset to recognize dogs in images (= source task). Now you&#8217;re working on a new project, where you want to recognize cats in images (= target task). Since the two tasks are very similar (cats and dogs share a lot of the same features) and you only have a small dataset available for the new task, transfer learning could improve the prediction performance on the target task.</span></div>
</div>
<div class="paragraph">
<p>Typically, not all the weights of a target network are initialized with weights from a source network, but only those from the earlier layers, where the source network has learned some general principles that are not task specific (e.g., observe how the first layer of the CNN in the previous section had learned to detect edges, which seems like a relevant skill for pretty much all computer vision tasks). Often, using a pretrained network will give you a more robust solution and boost the prediction performance, especially if you only have a very small dataset for the target task available to train the network. However, since when training a neural network you&#8217;re trying to find weights that minimize your error function by iteratively improving the weights starting with some initialization, if this initialization is unfavorable because it is very far away from a good minimum (i.e., further away than a random initialization), e.g., because you&#8217;ve initialized the weights with those from a source network trained on a very different task, then this will actually hurt the performance, since the network first has to unlearn a lot of things from this unrelated task before it can learn the actual task. Therefore, transfer learning should only be used if the source and target tasks are &#8220;related enough&#8221;. Pretraining a network on a self-supervised learning task (i.e., a task that is just about understanding the world in general, not solving a different kind of specific task) usually works quite well though.<br>
When using transfer learning, one question is whether to &#8220;freeze&#8221; the weights that were copied from the source network, i.e., to use the pretrained part of the network as a fixed feature extractor and only train the later layers that generate the final prediction. This is basically the same as first transforming the whole dataset once by pushing it through the first layers of a network trained on a similar task and then using these new feature representations to train a different model. While you often get good results when training a traditional model (e.g., a SVM) on these new feature representations, it is generally not recommended for neural networks. In some cases, you might want to keep the pretrained weights fixed for the first few epochs, but in most cases the performance will be best if all weights are eventually fine-tuned on the target task.</p>
</div>
<div class="paragraph">
<p>In cases where transfer learning is not beneficial, because it turns out that the source and target tasks are too different after all, it can nevertheless be helpful to copy the network architecture in general (i.e., number and shape of the hidden layers). Using an appropriate architecture is often more crucial than initializing the weights themselves.</p>
</div>
</div>
<div class="sect4">
<h5 id="_how_to_get_your_network_to_learn_something">How to get your network to learn something</h5>
<div class="ulist">
<ul>
<li>
<p>scale your data (for classification tasks only inputs, for regression tasks also outputs or adapt the bias of the last layer; <code>StandardScaler</code> is usually a good choice) as otherwise the weights have to move far from their initialization to scale the data for you</p>
</li>
<li>
<p>use sample weights for classification problems with unequal class distributions</p>
</li>
<li>
<p>NN are trained with gradient descent, which requires a good learning rate (i.e., step size for each training iteration &#8594; not too small, otherwise nothing is learned, not too big, otherwise it spirals out of control):</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/nn_learning_rate4.png" alt="image" width="540">
</div>
<div class="title"><span class="small">A simple strategy to select a suitable initial learning rate is to train the network with different learning rates for one epoch an a subsample of your dataset and then check the loss after training. For too small learning rates (left), the loss will stay the same, while for too large learning rates (right) the loss will be higher after training.</span></div>
</div>
</li>
<li>
<p>sanity check: a linear network (i.e., a FFNN with only 1 layer mapping directly from the inputs to the outputs) should achieve approximately the same performance as the corresponding linear model from sklearn</p>
</li>
<li>
<p>gradually make the network more complex until it can perfectly memorize a small training dataset (to get a network that has enough capacity to at least in principle capture the complexity of the task)</p>
</li>
<li>
<p>when selecting hyperparameters, always check if there is a clear trend towards an optimal setting; if the pattern seems random, initialize your network with different random seeds to see how robust the results are</p>
</li>
<li>
<p>using a learning rate scheduler (to decrease the learning rate over time to facilitate convergence) or early stopping (i.e., stopping the training when the performance on the validation set stops improving) can improve the generalization performance</p>
</li>
<li>
<p>but often it is more important to train the network long enough, like, for hundreds of epochs (depending on the dataset size).</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><span class="small">&#8594; more tips for training NN: <a href="http://karpathy.github.io/2019/04/25/recipe/" class="bare">http://karpathy.github.io/2019/04/25/recipe/</a></span></p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
If you want to learn more about neural networks, there are many great free resources available online, such as the introductory videos from <a href="https://www.3blue1brown.com/topics/neural-networks">3blue1brown</a>, which nicely illustrate what neural networks are actually computing and how backpropagation works; the <a href="https://www.coursera.org/specializations/deep-learning">Coursera Deep Learning Specialization (by Andrew Ng)</a>, which provides a good general introduction with many practical tips and also covers application areas like computer vision and NLP; or the <a href="https://atcold.github.io/pytorch-Deep-Learning/">Deep Learning with PyTorch course (by Yann LeCun)</a>, which is a bit more advanced and discusses state-of-the-art architectures.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_neural_networks_in_python">Neural Networks in Python</h4>
<div class="paragraph">
<p>There are several libraries available for working efficiently with neural networks (especially since many of the big firms doing machine learning decided to develop their own library): <code>theano</code> was the first major deep learning Python framework, developed by the MILA institute at the university of Montreal (founded by Yoshua Bengio), then came <code>TensorFlow</code>, developed by the Google Brain team, <code>MXNet</code> (pushed by Amazon), and finally <code>PyTorch</code>, developed by the Facebook AI Research (FAIR) team (lead by Yann LeCun). PyTorch is currently preferred by most ML researchers, while TensorFlow is still found in many (older) applications used in production.</p>
</div>
<div class="paragraph">
<p>Below you can find some example code for how to construct a neural network using PyTorch or Keras (which is a wrapper for TensorFlow to simplify model creation and training). Further details can be found in the example notebooks on GitHub, which also use the (Fashion) MNIST datasets described below to benchmark different architectures.</p>
</div>
<div class="paragraph">
<p>[Recommended:] <a href="https://pytorch.org/"><code>torch</code> library</a>
(&#8594; to simplify model training, combine with <a href="https://skorch.readthedocs.io/en/stable/"><code>skorch</code> library</a>!)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">import</span> <span class="include">torch</span>
<span class="keyword">import</span> <span class="include">torch.nn.functional</span> <span class="keyword">as</span> F

<span class="keyword">class</span> <span class="class">MyNeuralNet</span>(torch.nn.Module):

    <span class="keyword">def</span> <span class="function">__init__</span>(<span class="predefined-constant">self</span>, n_in, n_hl1, n_hl2, n_out=<span class="integer">10</span>):
        <span class="comment"># neural networks are always a subclass of torch modules, which makes it possible</span>
        <span class="comment"># to use backpropagation and gradient descent to learn the weights</span>
        <span class="comment"># the call to the super() constructor is vital for this to work!</span>
        <span class="predefined">super</span>(MyNeuralNet, <span class="predefined-constant">self</span>).__init__()
        <span class="comment"># initialize the layers of the network with random weights</span>
        <span class="comment"># a Linear layer is the basic layer in a FFNN with a weight matrix,</span>
        <span class="comment"># in this case with shape (n_in, n_hl1), and a bias vector</span>
        <span class="predefined-constant">self</span>.l1 = torch.nn.Linear(n_in, n_hl1)  <span class="comment"># maps from dimensionality n_in to n_hl1</span>
        <span class="comment"># you need to make sure that the shape of the weights matches up</span>
        <span class="comment"># with that from the previous layer</span>
        <span class="predefined-constant">self</span>.l2 = torch.nn.Linear(n_hl1, n_hl2)
        <span class="predefined-constant">self</span>.lout = torch.nn.Linear(n_hl2, n_out)

    <span class="keyword">def</span> <span class="function">forward</span>(<span class="predefined-constant">self</span>, x):
        <span class="comment"># this defines what the network is actually doing, i.e.,</span>
        <span class="comment"># how the layers are connected to each other</span>
        <span class="comment"># they are now applied in order to transform the input into the hidden layer representations</span>
        h = F.relu(<span class="predefined-constant">self</span>.l1(x))       <span class="comment"># 784 -&gt; 512 [relu]</span>
        h = F.relu(<span class="predefined-constant">self</span>.l2(h))       <span class="comment"># 512 -&gt; 256 [relu]</span>
        <span class="comment"># and finally to predict the probabilities for the different classes</span>
        y = F.softmax(<span class="predefined-constant">self</span>.lout(h))  <span class="comment"># 256 -&gt; 10 [softmax]</span>
        <span class="keyword">return</span> y

<span class="comment"># this initializes a new network</span>
my_nn = MyNeuralNet(<span class="integer">784</span>, <span class="integer">512</span>, <span class="integer">256</span>)
<span class="comment"># this calls the forward function on a batch of training samples</span>
y_pred = my_nn(X_batch)
<span class="comment"># (btw: using an object like a function also works for other classes if you implement a __call__ method)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><a href="https://keras.io/"><code>keras</code> framework</a> (which simplifies the construction and training of <a href="https://www.tensorflow.org/">TensorFlow</a> networks)</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">tensorflow</span> <span class="keyword">import</span> <span class="include">keras</span>

<span class="comment"># construct a feed forward network:</span>
<span class="comment"># 784 -&gt; 512 [relu] -&gt; 256 [relu] -&gt; 10 [softmax]</span>
model = keras.Sequential()
<span class="comment"># you need to tell the first layer the shape of your input features</span>
model.add(keras.layers.Dense(<span class="integer">512</span>, activation=<span class="string"><span class="delimiter">'</span><span class="content">relu</span><span class="delimiter">'</span></span>, input_shape=(<span class="integer">784</span>,)))
<span class="comment"># the following layers know their input shape from the previous layer</span>
model.add(keras.layers.Dense(<span class="integer">256</span>, activation=<span class="string"><span class="delimiter">'</span><span class="content">relu</span><span class="delimiter">'</span></span>))
model.add(keras.layers.Dense(<span class="integer">10</span>, activation=<span class="string"><span class="delimiter">'</span><span class="content">softmax</span><span class="delimiter">'</span></span>))

<span class="comment"># compile &amp; train the model (for a classification task)</span>
model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adam(), metrics=[<span class="string"><span class="delimiter">'</span><span class="content">accuracy</span><span class="delimiter">'</span></span>])
model.fit(X, y)

<span class="comment"># predict() gives probabilities for all classes; with argmax we get the actual labels</span>
y_pred = np.argmax(model.predict(X_test), axis=<span class="integer">1</span>)
<span class="comment"># evaluate the model (returns loss and whatever was specified for metrics in .compile())</span>
print(<span class="string"><span class="delimiter">&quot;</span><span class="content">The model is this good:</span><span class="delimiter">&quot;</span></span>, model.evaluate(X_test, y_test)[<span class="integer">1</span>])
<span class="comment"># but of course you can also use the evaluation functions from sklearn</span>
print(<span class="string"><span class="delimiter">&quot;</span><span class="content">Equivalently:</span><span class="delimiter">&quot;</span></span>, accuracy_score(y_test, y_pred))</code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Standard ML Benchmarking Datasets</dt>
<dd>
<p>The MNIST handwritten digits dataset is very old and super easy even for traditional models<br>
&#8594; \(28 \times 28\) pixel gray-scale images with 10 different classes:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/MnistExamples.png" alt="image" width="640">
</div>
</div>
<div class="paragraph">
<p>The new MNIST dataset: Fashion &#8658; same format (i.e., also 10 classes and images of the same shape), but more useful for benchmarks since the task is harder</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/05_supervised_nn/mnist_fashion.jpeg" alt="image" width="640">
</div>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_time_series_forecasting">Time Series Forecasting</h3>
<div class="paragraph">
<p>In the chapter on data, where we discussed what could be considered &#8216;one data point&#8217;, you&#8217;ve already encountered some tasks that involve time series data. Now we&#8217;re looking into possibly the most difficult question that you can try to solve with time series data, namely predicting the future.</p>
</div>
<div class="paragraph">
<p>In time series forecasting, the goal is to predict the future time course of a variable (i.e., its values for \(t' &gt; t\)) from its past values (and possibly some additional information).
This is, for example, used in <strong>Predictive Maintenance</strong>, where the remaining life span or degradation of important process components is forecast based on their past usage and possibly some future process conditions:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_timeseries/timeseries4.png" alt="image" width="660">
</div>
<div class="title"><span class="small">One predictive maintenance problem coming up over and over again in the chemical production industry is trying to predict the remaining activity or lifetime of a catalyst (a critical component in a chemical plant that facilitates the reaction; visualized as the purple line) under different process conditions (which are planned for the future; blue and green lines). For example, the catalyst might decay faster, if the process is run at a higher temperature. If the weekend is coming up, a predictive maintenance model could be used to estimate the temperature at which the process should be run such that the catalyst lasts until the next Monday, when the crew to replace it is back.</span></div>
</div>
<div class="paragraph">
<p><strong>Predictive Maintenance Example Paper:</strong><br>
Bogojeski, M., et al. &#8220;Forecasting industrial aging processes with machine learning methods.&#8221; <em>Computers and Chemical Engineering</em> 144 (2021): 107123. <a href="https://arxiv.org/abs/2002.01768">(arXiv:2002.01768)</a></p>
</div>
<div class="sect3">
<h4 id="_input_and_target_variables">Input and Target Variables</h4>
<div class="paragraph">
<p>Basically, you can think of time series forecasting as a supervised learning problem with more complicated inputs &amp; outputs:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_timeseries/tsf_inout8.png" alt="image" width="800">
</div>
<div class="title"><span class="small">Depending on the task (i.e., what you want to forecast), you either have a <strong>univariate</strong> forecasting problem (if you only need to predict the development of a single variable) or a <strong>multivariate</strong> problem (i.e., with multiple target variables). Additionally, it is important to note for <strong>how many time steps into the future</strong> the variables need to be forecast: in the easiest case, only the next time step needs to be predicted, but it might also be necessary to predict a fixed window of \(k\) time steps into the future, and sometimes the prediction horizons might even be of varying lengths. In any case, one should always try to make use of as much (relevant) information as possible when making forecasts. In principle, <strong>all values from the past can be used as input features</strong>, especially those from the target variable(s) (&#8594; see also auto-regressive models, e.g., <a href="https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average">ARIMA</a>). What is often overlooked, however, is all the additional <strong>information about the future</strong> that can be used as inputs as well, provided that these values are independent of the targets, i.e., <strong>exogenous variables</strong> outside of the system.</span></div>
</div>
<div class="paragraph">
<p>For example, let&#8217;s say you own a small cafe and want to predict how much ice cream you are likely to sell tomorrow. Certainly, the amount of ice cream you&#8217;ve sold yesterday or on the same day last week will be useful input features, but additionally, for example, the weather forecast for tomorrow or whether or not there is a holiday or some special event happening would be useful predictive information that should not be ignored and that can be used since these are independent variables.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><span class="underline">Know your data: Beware of hidden feedback loops!</span></p>
</div>
<div class="paragraph">
<p>In this predictive maintenance example, the pressure in some pipes indicates how much residual material has built up on the walls of the pipes (&#8594; <a href="https://en.wikipedia.org/wiki/Fouling">fouling</a>) and the task is to predict when these pipes need to be cleaned again, i.e., when the next maintenance event is due.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">What are input features, what are targets?</dt>
<dd>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_timeseries/input_target_leak4.png" alt="image" width="640">
</div>
</div>
<div class="paragraph">
<p>While in general many future process conditions (e.g., the planned amount of product that should be produced in the next weeks), can be used as input variables at \(t' &gt; t\), this does not hold for the process condition &#8216;temperature&#8217; in this example, since it is not a true exogenous variable, even though it could theoretically be set independently. In the historic data, the value of the temperature at \(t+1\) is dependent on the target variable (pressure) at \(t\), therefore, if you want to forecast the target for more than one time step, only the past values of temperature can be used as input features.</p>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="paragraph">
<p>You need a feature vector for every time point you want to make a prediction about. Think about what it is you&#8217;re trying to predict and what values could influence this target variable, i.e., what inputs are needed such that you have all the required information to make the prediction. Especially when using stateless models (see below), the feature vectors need to capture all the relevant information about the past.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Possible Input Features</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>known information about future (e.g., weather forecast, planned process conditions)</p>
</li>
<li>
<p>auto-regressive: lagged (target) variable (i.e. values at \(t' \leq t\))<br>
❗️ don’t use the <em>predicted</em> target value for this (in a multi-step forecast) – errors accumulate!</p>
</li>
<li>
<p>account for cyclical (e.g., seasonal) trends (&#8594; check auto-correlation or spectral analysis)<br>
<span class="image"><img src="images/07_timeseries/ts_months.png" alt="image" width="160"></span>
<span class="image"><img src="images/07_timeseries/ts_week.png" alt="image" width="160"></span><br>
&#8594; include categorical variables <code>month</code> and <code>day_of_week</code></p>
</li>
<li>
<p>hours / integral of input variable since last maintenance event (maybe take log)<br>
<span class="image"><img src="images/07_timeseries/ts_integralfeat.png" alt="image" width="470"></span></p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>&#8594; For more ideas: <a href="https://tsfresh.readthedocs.io/en/latest/">tsfresh library</a>, <a href="https://machinelearningmastery.com/category/deep-learning-time-series/">time series analysis blog posts</a></p>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_stateless_vs_stateful_models">Stateless vs. Stateful Models</h4>
<div class="paragraph">
<p>When dealing with time series data, one should always think carefully about how complex the dependencies between the past and future process values in the respective forecasting task are.<br>
For example, when trying to predict <strong>spontaneous events</strong>, like a sudden increase in the emissions produced in the process, then the relevant time window into the past, when the process conditions might have had an influence on this target variable, would be very short, i.e., only the process values from time \(t\) need to be included in the input feature vector to predict the anomalous event at time \(t+1\).<br>
For other prediction tasks, what happened over a <strong>longer (but uniquely determined) interval</strong> might be relevant, but can be <strong>summarized with simple features</strong>. For example, in a production process, one might want to predict the quality of the final product that is produced within a fixed time interval. In this case, the process conditions during the time interval where the respective product is produced will be important for the prediction, but the process conditions during the time where the previous product was produced are most likely not relevant. Additionally, it would be enough to compute only some summary statistics (like mean/max/min values of the process conditions during the time interval of interest) and use these as input features to capture all the relevant information.<br>
A third case would be prediction tasks for which it is necessary to consider <strong>very long time windows</strong>, often of varying lengths, with some <strong>complex long-ranging dependencies</strong> between the process conditions at different time points. For example, in some predictive maintenance tasks, the decay of the critical process component might not happen in some linear fashion (unlike, for example, a light bulb, which might have some fixed life expectancy and one only needs to count the number of hours it was turned on up to now to estimate when it needs to be replaced), but there might be a more complex dependency, for example, the component might decay faster if it is already in a poor state, therefore, if some unfortunate combination of process conditions lead to a strain on the component early on, it might have to be replaced a lot sooner then under otherwise identical conditions without this initial mishap.</p>
</div>
<div class="paragraph">
<p>Depending on how complex the dependencies between process values over time are, it will be more or less complicated to construct feature vectors that capture all the relevant information to make the prediction. In general, one should always try to come up with <strong>features that contain all the relevant information about the past</strong>, i.e., that fulfill the <a href="https://en.wikipedia.org/wiki/Markov_property">Markov assumption</a> that given this information the future is otherwise independent of the history of the process. (For example, if I knew the number of hours a light bulb was turned on up to now, I would have a complete picture about the state the light bulb is currently in; everything else that happened in the past, like how many people were in the room while the light was on, is irrelevant for the state of the light bulb. Another example would be the current position of pieces on a chess board: To plan my next move, I don&#8217;t need to know the exact order in which the pieces were moved before, but only the position of all the pieces right now.)<br>
If you are able to derive such input features, you can use a <strong>stateless model</strong> (e.g., any of the supervised learning models we&#8217;ve discussed so far except RNNs) for the prediction, i.e., treat all your data points as independent regardless of where in time they occurred. If it is not possible to construct such an informative feature vector that captures all the relevant information about the past, e.g., because of complex long-ranging dependencies that can not be adequately captured by simple summary statistics, then you have to use a <strong>stateful model</strong> (e.g., a form of Recurrent Neural Network (RNN)), which internally constructs a full memory of the history of the process (i.e., it keeps track of the current state of the process).</p>
</div>
<div class="paragraph">
<p>Whether to use a stateless or stateful model is also an important consideration when dealing with other kinds of sequential data such as text. Analogous to the three scenarios described above, we can also find similar cases for natural language processing (NLP) problems that either benefit from the use of stateful models or where a simple stateless model is enough:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>spontaneous event:</strong> trigger word detection for smart speakers: a simple classification task for which only the last 1-2 spoken words, i.e., the audio signal from a time window of a few seconds, are relevant</p>
</li>
<li>
<p><strong>fixed interval &amp; summary features:</strong> text classification, e.g., determining the category of a newspaper article (e.g., &#8216;sports&#8217; or &#8216;politics&#8217;): while here a longer span of text needs to be considered to make the prediction, a simple TF-IDF vector is usually sufficient to represent the contents of the whole document, since such categories can easily be identified by simply checking whether the terms &#8220;soccer&#8221; or &#8220;politician&#8221; occur more often in the current article</p>
</li>
<li>
<p><strong>complex long-ranging dependencies:</strong> for some tasks like sentiment analysis or machine translation, it doesn&#8217;t just matter which words occurred in a text, but also in which order and what their larger surrounding context was</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>&#8594; While for 1. and 2. a stateless model will do just fine, for 3. the best performance will be achieved with a stateful model that can keep track of the more complex dependencies.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">TL;DR: Which type of model should you use?</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>How much does the future depend on the past?<br>
a) values at \(t\) or simple summary statistics are sufficient as input features to predict \(t' &gt; t\)<br>
b) there exist complex long-ranging dependencies between past and future values</p>
</li>
<li>
<p>How many time steps into the future do you need to predict?<br>
a) a fixed, small window of \(1\) or \(k\) steps<br>
b) arbitrarily long prediction horizons</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>if <strong>only a)</strong>:<br>
&#8594; <em>stateless</em> model, e.g., linear model, FFNN, random forest, &#8230;&#8203;<br>
if <strong>any b)</strong>:<br>
&#8594; <em>stateful</em> model, e.g., recurrent neural network (RNN)</p>
</div>
</div>
</div>
<div class="openblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Output prediction with <em>stateless</em> models (e.g., linear regression, FFNN)</dt>
<dd>
<p>Only predict for a fixed time window of 1 or <em>k</em> steps:<br></p>
</dd>
</dl>
</div>
<div class="ulist none">
<ul class="none">
<li>
<p>univariate, single-step prediction:</p>
<div class="stemblock">
<div class="content">
\[[\underbrace{\quad y_1 \quad}_{t' \,\leq\, t} | \underbrace{\, x_1 \, | \,  x_2 \, }_{t+1} ] \; \to \; [\underbrace{y_1}_{t+1}]\]
</div>
</div>
</li>
<li>
<p>multivariate, single-step prediction:</p>
<div class="stemblock">
<div class="content">
\[[\underbrace{\quad y_1  \quad | \quad y_2 \quad}_{t' \,\leq\, t} | \underbrace{\, x_1 \, | \,  x_2 \, }_{t+1} ] \; \to \; [\underbrace{\, y_1  \, | \, y_2 \, }_{t+1}]\]
</div>
</div>
</li>
<li>
<p>multivariate, multi-step prediction:</p>
<div class="stemblock">
<div class="content">
\[[\underbrace{\quad y_1  \quad | \quad y_2 \quad}_{t' \,\leq\, t} | \underbrace{\quad\quad x_1 \quad\quad | \quad\quad  x_2 \quad\quad }_{t+1\, ...\, t+k} ] \; \to \; [\underbrace{\quad\quad y_1 \quad\quad | \quad\quad  y_2 \quad\quad }_{t+1\, ...\, t+k}]\]
</div>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Output prediction with <em>stateful</em> models (e.g., RNN, LSTM, GRU, Echo State Network)</dt>
<dd>
<p>The model builds up a memory of the past by mirroring the actual process, i.e., even if you don&#8217;t need the prediction at some time step \(t-5\), you still need to feed the model the inputs from this time step such that it can build up the appropriate hidden state.</p>
<div class="paragraph">
<p>multivariate, multi-step prediction:</p>
</div>
</dd>
</dl>
</div>
<div class="stemblock">
<div class="content">
\[\begin{aligned}
...\\
t-1:\quad [\, x_1 \, | \,  x_2 \,]\; &amp;\to \; [\, y_1  \, | \, y_2 \,]\\
\text{memory state buildup} \quad\quad\quad\quad t:\quad [\, x_1 \, | \,  x_2 \,]\; &amp;\to \; [\, y_1  \, | \, y_2 \,]\\
---------------------&amp;------\\
\text{prediction} \quad\quad\quad\quad\quad t+1:\quad [\, x_1 \, | \,  x_2 \,]\; &amp;\to \; [\, y_1  \, | \, y_2 \,]\\
t+2:\quad [\, x_1 \, | \,  x_2 \,]\; &amp;\to \; [\, y_1  \, | \, y_2 \,]\\
...\\
t+k:\quad [\, x_1 \, | \,  x_2 \,]\; &amp;\to \; [\, y_1  \, | \, y_2 \,]
\end{aligned}\]
</div>
</div>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
When working with time series data, the train, validation, and test data splits should always be in chronological order, i.e., the model should be trained on the oldest time points and evaluated on more recent samples to get a realistic performance estimate, especially in cases where the data might have changed over time, e.g., due to smaller changes in the underlying process.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_recommender_systems_pairwise_data">Recommender Systems (Pairwise Data)</h3>
<div class="paragraph">
<p>Recommender systems can be found on many websites to promote products, content, or ads that a specific user might be interested in (e.g., on Amazon, Netflix, Facebook, YouTube, etc.). What is special about them is that here we&#8217;re not really dealing with single data points, but instead with pairwise data, i.e., we have samples from two groups (e.g., users and movies), where each combination of samples (e.g., each (user, movie)-tuple) is assigned a label (e.g., the rating the user gave to the movie). Typically, the training set contains only very few labels (e.g., since there are many users and many movies, but every user has only rated a handful of movies) and the task is to predict all the missing labels, based on which then, for example, a user would be recommended the movie with the highest predicted rating.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><span class="underline">Recommender Systems Overview:</span></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pairwise data</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>(user, movie) &#8594; rating (1 - 5 stars)</p>
</li>
<li>
<p>(drug, protein) &#8594; bind (yes / no)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p><strong>Idea:</strong> similar users watch similar movies<br>
<strong>Given:</strong> very sparse matrix with known interactions:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_recsys/rec_sys_pairwise.png" alt="image" width="200">
</div>
</div>
<div class="paragraph">
<p><strong>Task:</strong> fill in the missing values</p>
</div>
</div>
</div>
<div class="paragraph">
<p>There are lots of different approaches for how to accomplish this, and we&#8217;ll only look at two here, the very traditional method of collaborative filtering, and a more modern approach relying on neural networks that falls under the category of triplet learning.</p>
</div>
<div class="paragraph">
<p>&#8594; One possible Python library: <a href="http://surpriselib.com/"><code>surprise</code></a></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Collaborative Filtering</dt>
<dd>
<p>Using a <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition">singular value decomposition</a> (SVD; basically the big sister of the eigendecomposition, e.g., from <code>scipy.sparse.linalg.svds</code>), the matrix with the known interactions can be decomposed into two smaller matrices of shapes (number of movies \(\times\) <em>d</em>) and (<em>d</em> \(\times\) number of users) and by multiplying these matrices together, the missing values from the original matrix can be approximated:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_recsys/rec_sys_svd3.png" alt="image" width="600">
</div>
<div class="title"><span class="small">The two matrices we obtain from the SVD contain <em>d</em>-dimensional latent variable representations of movies and users respectively, where <em>d</em> denotes the number of eigenvectors we decided to keep (corresponding to the <em>d</em> largest eigenvalues of the original matrix). You can think of these as feature vectors, where, for example, one of the <em>d</em> dimensions in the vector representing a movie might correspond to how much this movie could be considered a horror movie, while the same dimension in a user vector would indicate how much this user likes horror movies. If both entries for some dimension in the vectors point in the same direction (e.g., the movie is a horror movie and the user likes horror movies), then the product of the two entries will contribute positively to the overall scalar product of the vectors and therefore the approximated rating. (However, please note that just like with the new feature dimensions we got from PCA, it is very difficult to determine exactly what is actually encoded in each dimension.)</span></div>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>One big problem with this approach is that we always need some initial ratings for each user and movie, otherwise we can&#8217;t generate any useful personalized recommendations. This is also referred to as the &#8220;cold start problem&#8221;, which can be addressed with the next method.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Triplet Learning</dt>
<dd>
<p>In triplet learning, we don&#8217;t directly work with the matrix of known interactions, but instead the training dataset consists of triplets (e.g., (user <em>i</em>, movie <em>j</em>, 4 stars), which can also be a more memory-friendly representation). Additionally, we assume that we have feature vectors available for the users and movies (e.g., the users might have filled out a short survey when they set up an account and for the movies we know the genres, directors, and plot keywords; if all fails, this could also just be a one-hot encoding). Given the two feature vectors of a user and a movie, we then try to predict interaction value directly:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_recsys/rec_sys_triplet2.png" alt="image" width="700">
</div>
<div class="title"><span class="small">These are two possible neural network architectures for predicting the rating a user might give to a movie. The architecture on the left first processes the user and movie feature vectors individually (in case they require a certain type of network to be understood, e.g., the movie plot description or the movie poster), and then the representations are concatenated into a single vector, which is then passed to a FFNN to predict the rating. A different approach is shown on the right, where instead the two original feature representations for users and movies are projected into the same vector space, where then the cosine similarity of these two vectors is computed to predict the interaction between them (similar as with the <em>d</em>-dimensional latent variable representations in the collaborative filtering approach).</span></div>
</div>
<div class="paragraph">
<p>&#8594; Given the feature vector of a new user, that has not rated any movies yet, we are now able to generate useful predictions.</p>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_avoiding_common_pitfalls">Avoiding Common Pitfalls</h2>
<div class="sectionbody">
<div class="quoteblock">
<blockquote>
All models are wrong, but some are useful.
</blockquote>
<div class="attribution">
&#8212; George E. P. Box
</div>
</div>
<div class="paragraph">
<p>The above quote is also nicely exemplified by <a href="https://xkcd.com/2048/">this xkcd comic</a>:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="https://imgs.xkcd.com/comics/curve_fitting.png" alt="image" width="540">
</div>
</div>
<div class="paragraph">
<p>A machine learning (ML) model tries to infer the relationship between some inputs and outputs from the given exemplary data points. What kind of relation will be found is largely determined by the chosen model type and its internal optimization algorithm, however, there is a lot you can (and should) do to make sure what the algorithm comes up with is not blatantly wrong.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Before training a model</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Select the right inputs: ask a domain expert which variables could have a causal influence on the output; possibly compute additional, more informative features from the original measurements (&#8594; feature engineering).</p>
</li>
<li>
<p>Sanity check: Does the dataset contain samples with the same inputs but different outputs? &#8658; Some important features might be missing or the targets are very noisy, e.g., due to inconsistent annotations&#8201;&#8212;&#8201;fix this first!</p>
</li>
<li>
<p>Think about the structure of the problem and what type of model might be appropriate to learn the presumed &#8216;input &#8594; output&#8217; relationship. For example, if the problem is clearly non-linear, the chosen model type also needs to be complex enough to at least in principle be able to pick up on this relation (i.e., such that the model does not underfit, see below). A lot of domain knowledge can also be put into the design of neural network architectures.</p>
</li>
<li>
<p>Make sure the data satisfies the model&#8217;s assumptions &#8658; for pretty much all models except decision trees (and models based on decision trees, like random forests) the data should be approximately normally distributed.</p>
</li>
<li>
<p>Make sure you&#8217;ve set aside a representative test set to evaluate the final model (and possibly a validation set for model selection and hyperparameter tuning).</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">After the model was trained</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Evaluate the model with a meaningful evaluation metric (especially for datasets with unbalanced class distributions (&#8594; balanced accuracy)!).</p>
</li>
<li>
<p>Check that the model is capable of interpolation, i.e., that it generalizes to unseen data points <em>from the same distribution as the training set</em> and does not over- or underfit. Please note that this does <em>not</em> ensure that it can also extrapolate, i.e., that it has learned the true causal relation between inputs and outputs and can generate correct predictions for data points outside of the training domain!</p>
</li>
<li>
<p>Check whether the model makes any systematic errors, which would indicate that your assumptions about the data might be wrong (&#8594; performance for all classes should be approximately the same; the prediction errors / <a href="https://statisticsbyjim.com/regression/check-residual-plots-regression-analysis/">residuals</a> in regression problems should be <a href="https://www4.stat.ncsu.edu/~stefanski/NSF_Supported/Hidden_Images/Residual_Surrealism_TAS_2007.pdf">independent</a>).</p>
</li>
<li>
<p>Verify that the model does not discriminate. Due to the large quantities of data used to train ML models, it is not always possible to ensure that the training data does not contain any systematic biases (e.g., gender/race stereotypes) that a model might pick up on, but it is important to test the model on a well balanced and controlled test set to catch any discrimination before the model is deployed in production.</p>
</li>
<li>
<p>Interpret the model and explain its predictions: Does it use the features you (or a domain expert) expected it to use or does it make the predictions based on any spurious correlations?</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p><em>Please note that these steps represent an iterative workflow, i.e., after training some model and analyzing its performance one often goes back to the beginning and, e.g., selects different features or tries a more complex model to improve the performance.</em></p>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">And after the model was deployed&#8230;&#8203;</dt>
<dd>
<p><span class="underline">One of the biggest problems in practice: Data &amp; Concept Drifts:</span></p>
<div class="paragraph">
<p><strong>ML fails silently!</strong> I.e., the program doesn&#8217;t crash even if all predictions are wrong<br>
&#8594; Need constant monitoring to detect changes that lead to a deteriorating performance!</p>
</div>
</dd>
</dl>
</div>
<div class="ulist none">
<ul class="none">
<li>
<p><em>Data drift:</em> input distribution changes, e.g., a new user operates the machine differently<br>
&#8594; Use statistical tests to detect changes in input distributions</p>
</li>
<li>
<p><em>Concept drift:</em> input/output relation changes due to:</p>
<div class="ulist">
<ul>
<li>
<p>External factors (e.g., changes in the process structure / setup)</p>
</li>
<li>
<p>Internal factors (feedback loop: presence of ML model alters behavior)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>&#8594; Check difference between predicted and true (training) label frequencies<br>
&#8594; Frequently retrain models on new data (&amp; verify feature importances)<br>
&#8594; Logging of known external events, e.g., maintenance (!!)<br></p>
</div>
<div class="ulist none">
<ul class="none">
<li>
<p>&#8658; Include changes explicitly in the model as additional features / subgroups</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_interpolation_does_the_model_generalize">Interpolation: Does the model generalize?</h3>
<div class="paragraph">
<p>The first step in verifying that a model is not complete bullshit is to check whether it is capable of interpolating, i.e.:<br>
<strong>Does the model generate reliable predictions for new data points from the same distribution as the training set?</strong></p>
</div>
<div class="paragraph">
<p>While this does not ensure that the model has actually learned any true causal relationship between inputs and outputs and can extrapolate beyond the training domain (we&#8217;ll get to this part in the next section), at least we can be reasonably sure that it will generate reliable predictions for data points similar to those used for training the model. If this isn&#8217;t given, the model is not only wrong, it&#8217;s also useless.</p>
</div>
<div class="sect3">
<h4 id="_over_underfitting">Over- &amp; Underfitting</h4>
<div class="paragraph">
<p>How does a model make mistakes?</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/overunderfitting.png" alt="image" width="840">
</div>
<div class="title"><span class="small">If you were to only look at the test errors for the different models shown here, you might conclude that the model on the left (overfitting) and on the right (underfitting) were equally wrong. While this is true in some sense, the test error alone does not tell you <em>why</em> the models are wrong (or how you could improve their performance). As you can see, the two models make mistakes on the test set for completely different reasons: the model that overfits, memorized the training samples and is not able to generalize to new data points, while the model that underfits, is too simple to capture the relationship between the inputs and outputs in general. Since these two scenarios require vastly different approaches to improve the model&#8217;s performance, it is important to look at the error on the training set (in a addition to the error on the test/validation set) to determine whether the model&#8217;s errors on the test set are be due to over- or underfitting.</span></div>
</div>
<div class="paragraph">
<p><strong>Overfitting:</strong> great training performance, horrible on test set<br>
<strong>Underfitting:</strong> poor training AND test performance</p>
</div>
<div class="paragraph">
<p>This is related to the model&#8217;s complexity:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/modelcomplex3.png" alt="image" width="640">
</div>
<div class="title"><span class="small">While a simple model (e.g., a linear model) has a high bias and might therefore underfit the data, a more complex model (e.g., a deep NN) has high variance and is therefore at risk of overfitting the training set. Often, it makes sense to use a more complex model, but then reduce its variance through explicit (e.g., L2-regularization) and/or implicit regularization (e.g., data augmentation). Also, please note the <a href="https://openai.com/blog/deep-double-descent/">double descent phenomenon</a> for neural networks, which often show a good generalization performance even if they are vastly over-parametrized.</span></div>
</div>
<div class="paragraph">
<p>Depending on whether a model over- or underfits, there are different things you can do to improve its performance:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/overunderfitting_errors4.png" alt="image" width="640">
</div>
</div>
<div class="paragraph">
<p>In general, you should first try to decrease the model&#8217;s bias, i.e., find a model that is at least in principle capable of solving the task, since the error on the training data is the lower limit for the error on the test set. Then make sure the model doesn&#8217;t overfit, i.e., generalizes to new data points (what we ultimately care about). However, it is unrealistic to expect a model to have a perfect performance, as some tasks are just hard, for example, because the data is very noisy.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Additionally: Always look at the data!! Is there a pattern among wrong predictions, e.g., is there a discrepancy between the performance for different classes? Could some additional preprocessing steps help to fix errors for some type of data points (e.g., blurry images)?
</td>
</tr>
</table>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Will more data help?</dt>
<dd>
<p>With little data, you risk overfitting. But is it worth getting more data?<br>
&#8594; check <em>learning curves</em>, i.e., how the performance improves when using more training samples:</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/06_evaluation/learning_curve.png" alt="image" width="840">
</div>
</div>
<div class="paragraph">
<p>Instead of <em>more</em>, it might also be helpful to get <em>cleaner</em> data! (See <a href="https://youtu.be/06-AZXmwHjo">talk by Andrew Ng</a>.)</p>
</div>
</div>
</div>
<div class="sect4">
<h5 id="_feature_selection">Feature Selection</h5>
<div class="paragraph">
<p>In small datasets, some patterns can occur simply by chance (= <a href="https://www.tylervigen.com/spurious-correlations">spurious correlations</a>).<br>
&#8658; exclude irrelevant features to avoid overfitting on the training data</p>
</div>
<div class="paragraph">
<p><span class="underline">Feature Selection Strategies:</span></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">1.) Univariate feature selection</dt>
<dd>
<p>e.g., correlation between feature &amp; target</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.feature_selection</span> <span class="keyword">import</span> <span class="include">SelectKBest</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Careful:</strong> This can lead to the inclusion of redundant features or the exclusion of features that might seem useless by themselves, but can be very informative when taken together with other features:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_explainability/features_informative4.png" alt="image" width="720">
</div>
<div class="title"><span class="small">Guyon, Isabelle, and André Elisseeff. &#8220;An introduction to variable and feature selection.&#8221; <em>Journal of Machine Learning Research</em> 3.Mar (2003): 1157-1182.</span></div>
</div>
<div class="paragraph">
<p>(Also, please note: if we were to reduce the dimensionality with PCA on these two datasets, for the plot on the right, the main direction of variance does not capture the class differences, i.e., while the second PC captures less variance overall, it capture the class-discriminative information that we care about.)</p>
</div>
<div class="paragraph">
<p>&#8658; Better:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">2.) Model-based feature selection</dt>
<dd>
<p>select features based on <code>coef_</code> or <code>feature_importances_</code> attribute of trained model</p>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.feature_selection</span> <span class="keyword">import</span> <span class="include">SelectFromModel</span></code></pre>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">3.) Sequential feature selection</dt>
<dd>
<p>greedy algorithm that iteratively includes/removes one feature at a time:</p>
<div class="ulist">
<ul>
<li>
<p><span class="underline">forward selection:</span> start with no features, iteratively add best feature until the performance stops improving</p>
</li>
<li>
<p><span class="underline">backward elimination:</span> start with all features, iteratively eliminate worst feature until the performance starts to deteriorate</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.feature_selection</span> <span class="keyword">import</span> <span class="include">SequentialFeatureSelector</span></code></pre>
</div>
</div>
<div class="paragraph">
<p><span class="underline">General rule</span>: Always remove truly redundant (i.e., 100% correlated) features, but otherwise if in doubt: keep all features</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
While feature selection can improve the performance, these automatic feature selection techniques will only select a subset of features that are good predictors of the target, i.e., highly correlated, not necessary variables that correspond to the true underlying causes! (see also next section)
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_extrapolation_correlation_vs_causation">Extrapolation: Correlation vs. Causation</h3>
<div class="paragraph">
<p>By following the strategies outlined in the previous section, you will find a model that is good at interpolating, i.e., generating predictions for new data points from the same distribution as the training set. However, this does not mean that the model actually picked up on the true causal relationship between the inputs and outputs!</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
ML models love to cheat &amp; take shortcuts! They will often pick up on spurious correlations instead of learning the true causal relationships. This makes them vulnerable to data/domain shifts (that would force the model to extrapolate instead of interpolate) and adversarial attacks.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Specifically, models that neither over- nor underfit, i.e., that perfectly capture the relation between inputs and outputs in the given samples, often still fail to extrapolate:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_causality/extrapolating_nn10.png" alt="image" width="440">
</div>
<div class="title"><span class="small">These 10 curves were generated by initializing the weights of a FFNN with one hidden layer of 20 units with a ReLU activation with 10 different random seeds and then training the network on the data samples. While all these models generalize well on the known data distribution, they can&#8217;t produce correct predictions for data point outside of the training domain.</span></div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Extrapolation on feature combinations</strong></p>
</div>
<div class="paragraph">
<p>Please note that only because you might have sampled a large range of values for each individual feature, this does not necessary entail that you&#8217;ve also covered all relevant combinations of feature values:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_causality/extrapolate_sampling.png" alt="image" width="240">
</div>
</div>
<div class="paragraph">
<p>If the two features and their effect on the target are independent of each other (e.g., \(y = ax_1 + bx_2\)), this is not too dramatic, however, if these variables interact in some complicated non-linear way, this might not be modeled correctly when relevant combinations of feature values weren&#8217;t sampled.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_causality">Causality</h4>
<div class="paragraph">
<p>When setting up a model, you always have to be clear about whether it is enough that the model is capable of interpolating or whether it might also need to extrapolate every once in a while.
If the model will only be used to generate predictions for new data points from the same distribution as the original training samples and it is unlikely that any data drifts will occur (e.g., a softsensor that just needs to construct a new signal from other fixed inputs in a tightly controlled loop), then a model that has a decent performance on a representative hold-out test set will be sufficient for the task.
However, this assumption seldomly holds in practice and especially in safety-critical situations, such as image recognition in self-driving cars or at security checkpoints, it is vital that the model is robust and can not easily be fooled.</p>
</div>
<div class="paragraph">
<p>Other use cases where it is important that the model picks up on meaningful causal relationships include using a model to identify root causes or generating counterfactual &#8220;what-if&#8221; forecasts (which also requires extrapolation, e.g., when trying to simulate under which conditions a catastrophic event might occur without actually having observed one in the historic data).</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>A correct prediction is not always made for the right reasons!</strong></p>
</div>
<div class="paragraph">
<p>The graphic below is taken from a paper where the authors noticed that a simpler ML model (not a neural network) trained on a standard image classification dataset was performing poorly for all 10 classes in the dataset except one, horses. When they examined the dataset more closely and analyzed <em>why</em> the model predicted a certain class, i.e., which image features were used in the prediction (see also next section on explainability), they noticed that most of the pictures of horses were taken by the same photographer and they all had a characteristic copyright notice in the lower left corner:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_explainability/analyzing_classifiers.png" alt="image" width="840">
</div>
<div class="title"><span class="small">Lapuschkin, Sebastian, et al. &#8220;Analyzing classifiers: Fisher vectors and deep neural networks.&#8221; <em>IEEE Conference on Computer Vision and Pattern Recognition.</em> 2016.</span></div>
</div>
<div class="paragraph">
<p>By relying on this artifact, the model could identify what it perceived as &#8220;horses&#8221; in this dataset with high accuracy (both in the training and the test set, which also included pictures from the same photographer), however, of course the model had failed to learn what actually defines a horse and it would not be able to extrapolate and achieve the same accuracy on other images without this copyright notice or, equally problematic, might mistakenly classify new images of other objects or animals with a similar copyright notice as horses, too. (Purposefully tricking the model by augmenting other images with such a copyright notice would be an example of an adversarial attack, as discussed below.)</p>
</div>
</div>
</div>
<div class="paragraph">
<p>This is by far not the only example where a model has &#8220;cheated&#8221; by exploiting correlations in the training set that resulted in a seemingly good predictive performance, but meant that the model did not pick up on the true causal relationship between the features and labels (e.g., another example would be a dataset with images of dogs and wolves, where all wolves were photographed on snowy backgrounds and the dogs on grass or other non-white backgrounds).</p>
</div>
<div class="paragraph">
<p>To catch these kinds of mishaps, it is important to</p>
</div>
<div class="ulist none">
<ul class="none">
<li>
<p>a) critically examine the test set and hopefully notice any problematic patterns that could result in an overly optimistic performance estimate, and</p>
</li>
<li>
<p>b) interpret the model and explain its predictions to see if it has focused on the features you (or a domain expert) would have expected (as they did in the paper above and we&#8217;ll discuss in the next section).</p>
</li>
</ul>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Adversarial Attacks: Fooling ML models on purpose</strong></p>
</div>
<div class="paragraph">
<p>While a ML model can easily recognize the image on the left as a &#8216;Stop&#8217; sign, the sign on the right is mistaken as a speed limit sign due to the strategically placed, innocent looking stickers:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_explainability/adversarial_attack2.png" alt="image" width="640">
</div>
</div>
<div class="paragraph">
<p>This happened because the model didn&#8217;t pick up on the true reasons humans identify a Stop sign as such (e.g., octagonal form and 4 white letters spelling &#8216;STOP&#8217; on a red background), but instead relied on some less meaningful correlations to distinguish it from other traffic signs.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>Finding a causal model requires even more domain knowledge than learning a model that &#8220;only&#8221; generalizes well to the test set. Specifically, you need to know <strong>which input features should be used</strong> (i.e., which variables have a causal impact on the target) and <strong>what kind of model might best capture the true causal relationship</strong> (e.g., introduce domain knowledge into the design of a neural network architecture, for example, maybe there exist some sub-relationships between some of the inputs that can be modeled separately).</p>
</div>
<div class="paragraph">
<p>While in some cases this might be possible (see example below), in most cases finding a causal model is extremely hard. For example, it would be a very labor-intensive task to remove all the copyright notices in the image dataset mentioned earlier to prevent a model from using these pixels as input features and since CNNs rely a lot on local patterns, they are often easily <a href="https://www.sciencemag.org/news/2018/07/turtle-or-rifle-hackers-easily-fool-ais-seeing-wrong-thing">fooled</a> by leaving the global shape of objects in images intact (what humans rely on to identify objects) but overlaying them with specific textures or other high-frequency patterns and thereby causing them to predict a different class. Finding robust causal models for these use cases is still <a href="https://bdtechtalks.com/2021/03/15/machine-learning-causality/">an active research area</a>.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><span class="small">The following example is adapted from: &#8220;Elements of Causal Inference&#8221; by Jonas Peters, Dominik Janzig, and Bernhard Schölkopf (2017).<br>
See also Jonas Peters' great <a href="https://www.youtube.com/watch?v=zvrcyqcN9Wo">lecture series on causality</a>. You can also play around with this yourself in the <a href="https://github.com/cod3licious/ml_exercises/blob/main/notebooks/causal_model.ipynb">causal model notebook</a>.</span></p>
</div>
<div class="paragraph">
<p><strong>Learning a causal model</strong></p>
</div>
<div class="paragraph">
<p>Assume this is the true <em>causal graph</em> of some process, where the nodes represent different variables and the edges specify their influence on one another:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_causality/causality_network.png" alt="image" width="340">
</div>
</div>
<div class="paragraph">
<p>Please note that individual nodes in a causal graph can also represent hidden variables, i.e., process conditions that can not be directly observed (e.g., for which one might want to build a soft-sensor).</p>
</div>
<div class="paragraph">
<p>Based on the above stated relationships, we can generate a dataset, where each variable additionally depends on an independent (w.r.t. the other variables) normally distributed noise component (e.g., for each sample some process conditions might be set independently (<code>C</code> and <code>A</code>) while for others the value partially depends on the values already set for the other variables):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">n = <span class="integer">20000</span>
C =              <span class="float">1.0</span> * np.random.randn(n)
A =              <span class="float">0.8</span> * np.random.randn(n)
K = A          + <span class="float">0.1</span> * np.random.randn(n)
X = C - <span class="integer">2</span> * A  + <span class="float">0.2</span> * np.random.randn(n)
F = <span class="integer">3</span> * X      + <span class="float">0.8</span> * np.random.randn(n)
D = -<span class="integer">2</span> * X     + <span class="float">0.5</span> * np.random.randn(n)
G = D          + <span class="float">0.5</span> * np.random.randn(n)
Y = <span class="integer">2</span> * K - D  + <span class="float">0.2</span> * np.random.randn(n)
H = <span class="float">0.5</span> * Y    + <span class="float">0.1</span> * np.random.randn(n)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Since the dependencies between the variables are linear, the optimal model type to learn any &#8216;input &#8594; output&#8217; relation on this dataset would be a linear regression  model. The true coefficients that this model should find for one input variable are the values on the edges on the way from this variable&#8217;s node to the target node multiplied with each other, e.g., for <code>X</code> (input) on <code>Y</code> (target) this would be <code>-2</code> (from <code>X</code> to <code>D</code>) times <code>-1</code> (from <code>D</code> to <code>Y</code>), i.e., <code>2</code>.</p>
</div>
<div class="paragraph">
<p>Depending on which variables we include as input features, the models is or isn&#8217;t able to learn the correct coefficients:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="comment"># (1) missing relevant input feature K -&gt; wrong coefficient for X</span>
R^<span class="integer">2</span> (train): <span class="float">0.844</span>; (test): <span class="float">0.848</span> =&gt; Y ~  <span class="float">0.001</span> + <span class="float">1.285</span> * X
<span class="comment"># (2) all the right input features -&gt; correct coefficients</span>
R^<span class="integer">2</span> (train): <span class="float">0.958</span>; (test): <span class="float">0.959</span> =&gt; Y ~  <span class="float">0.003</span> + <span class="float">2.003</span> * X + <span class="float">2.010</span> * K
<span class="comment"># (3) additional input feature D, which has a more direct influence on Y than X</span>
R^<span class="integer">2</span> (train): <span class="float">0.994</span>; (test): <span class="float">0.994</span> =&gt; Y ~ -<span class="float">0.002</span> - <span class="float">0.015</span> * X + <span class="float">1.998</span> * K - <span class="float">1.007</span> * D
<span class="comment"># (4) additional input feature H, which is dependent on (i.e., highly correlated with) Y</span>
R^<span class="integer">2</span> (train): <span class="float">0.995</span>; (test): <span class="float">0.995</span> =&gt; Y ~  <span class="float">0.001</span> + <span class="float">0.242</span> * X + <span class="float">0.245</span> * K + <span class="float">1.759</span> * H
<span class="comment"># (5) additional input feature G that is not directly causal of Y, but dependent on D</span>
R^<span class="integer">2</span> (train): <span class="float">0.977</span>; (test): <span class="float">0.976</span> =&gt; Y ~  <span class="float">0.004</span> + <span class="float">0.978</span> * X + <span class="float">2.002</span> * K - <span class="float">0.510</span> * G</code></pre>
</div>
</div>
<div class="paragraph">
<p>Often the best predictive model is not the true causal model (e.g., (4)) and especially regularized models, which try to explain the target with as few variables as possible, often choose variables dependent on the target (such as <code>H</code>) as the single best predictor instead of relying on multiple true causal influences (e.g., notice how <code>K</code> and <code>X</code> already have much lower coefficients in (4)).<br>
But only the causal models are robust to data drifts and can extrapolate:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="comment"># Changed equations to generate test data (notice larger noise component)</span>
X = C - <span class="integer">2</span> * A  + <span class="float">2.0</span> * np.random.randn(n)
H = <span class="float">0.5</span> * Y    + <span class="float">1.0</span> * np.random.randn(n)

<span class="comment"># model (2): true relationship between X and Y -&gt; test performance equally good</span>
R^<span class="integer">2</span> (train): <span class="float">0.958</span>; (test): <span class="float">0.987</span> =&gt; Y ~ <span class="float">0.003</span> + <span class="float">2.003</span> * X + <span class="float">2.010</span> * K
<span class="comment"># model (4): variable dependent on but not causal of Y -&gt; test performance a lot worse</span>
R^<span class="integer">2</span> (train): <span class="float">0.995</span>; (test): <span class="float">0.866</span> =&gt; Y ~ <span class="float">0.001</span> + <span class="float">0.242</span> * X + <span class="float">0.245</span> * K + <span class="float">1.759</span> * H</code></pre>
</div>
</div>
<div class="paragraph">
<p>But unfortunately none of the models can handle a <em>concept</em> drift, i.e., when the underlying process, from which the data is sampled, changes:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="comment"># Changed equation to generate test data (notice the reversed sign for X on the way to Y)</span>
D =  <span class="integer">2</span> * X     + <span class="float">0.5</span> * np.random.randn(n)

<span class="comment"># model (2): causal relationship between X and Y changed -&gt; test performance catastrophic</span>
R^<span class="integer">2</span> (train): <span class="float">0.958</span>; (test): -<span class="float">1.797</span> =&gt; Y ~ <span class="float">0.003</span> + <span class="float">2.003</span> * X + <span class="float">2.010</span> * K</code></pre>
</div>
</div>
<div class="paragraph">
<p>In this case only retraining the model on new data helps to recover the performance.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>&#8658; If the goal is to find a <strong>good predictive model</strong>, use as input variables the <a href="https://en.wikipedia.org/wiki/Markov_blanket">Markov blanket</a> of the target variable, i.e., its parent nodes, child nodes, and the other parent nodes of these child nodes (in the above example, to predict <code>Y</code> this would be <code>D</code> and <code>K</code> (parent nodes) and <code>H</code> (child node that has no other parents)).<br>
&#8658; If the goal is to find a <strong>causal model</strong> that can extrapolate, use as input variables only the parent nodes of the target variable.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p><strong>Residual Plots</strong></p>
</div>
<div class="paragraph">
<p>Residual plots can give you a hint as to whether or not you might be missing important input variables in the model.<br></p>
</div>
<div class="paragraph">
<p>In regression problems we assume that the input variables explain all important external influences on the target and what remains is just random noise. I.e., as we predict the target as:</p>
</div>
<div class="stemblock">
<div class="content">
\[\hat{y} = b + w_1x_1 + w_2x_2 + ... + w_dx_d\]
</div>
</div>
<div class="paragraph">
<p>we assume that the true process that generated \(y\) looked like this:</p>
</div>
<div class="stemblock">
<div class="content">
\[y = b + w_1x_1 + w_2x_2 + ... + w_dx_d + \epsilon\]
</div>
</div>
<div class="paragraph">
<p>where \(\epsilon \in \mathcal{N}(0, \sigma)\) is the unexplained random noise with mean 0 and standard deviation \(\sigma\), which is assumed to be independent from all other factors.</p>
</div>
<div class="paragraph">
<p>By plotting the residuals (i.e., prediction errors) \(y_i - \hat{y}_i\) against the predicted targets \(\hat{y}_i\) and other variables and observing whether or not these residuals show distinctive patterns or really look like random noise, you can tell whether the model is missing important additional input variables.</p>
</div>
<div class="paragraph">
<p>For example, from the example above for model (1), i.e., when using only <code>X</code> as an input to predict <code>Y</code>, the residuals plots looks like this:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_causality/residuals_dependent.png" alt="image" width="840">
</div>
</div>
<div class="paragraph">
<p>The residuals here are correlated with several other variables, which means we should probably include one of them as an additional input feature.</p>
</div>
<div class="paragraph">
<p>The residuals plots for model (2), i.e., when using both <code>X</code> and <code>K</code> as features, on the other hand, show randomly distributed residuals, which means, we&#8217;re at least not missing some obvious influencing factors:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_causality/residuals_independent.png" alt="image" width="840">
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>In addition to selecting the right input features, it is often also helpful to use some domain knowledge when choosing the model architecture:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_causality/extrapolating_nn10_sin.png" alt="image" width="440">
</div>
<div class="title"><span class="small">Like in the initial example, these 10 curves were generated by initializing the weights of a FFNN with one hidden layer of 20 units with a ReLU activation with 10 different random seeds and then training the network on the data samples, only this time after the last layer a \(sin()\) activation was applied to the output. By including domain knowledge, we get much closer to the true causal relationship and can extrapolate beyond the training domain (to some extent).</span></div>
</div>
</div>
<div class="sect3">
<h4 id="_systematic_bias">Systematic Bias</h4>
<div class="paragraph">
<p>It is not only important to think about what the true causal relations between variables might be, but also if there could be some causal relationships encoded in the historic data that you <em>don&#8217;t</em> want a model to pick up on. For example, if you know that in the past there was some gender or race discrimination going on that might have leaked into your training data, e.g., white men getting systematically lower interest rates on credits that can not solely be explained by their higher incomes, you might want to take some extra measures to make sure that these relations, although they might have been true causal relationships in the past, are not present in your model now.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Biased data leads to (strongly) biased models</dt>
<dd>
<p>Below are some examples where people with the best of intentions have set up a ML model that has learned problematic things from real world data.</p>
</dd>
</dl>
</div>
<div class="sidebarblock">
<div class="content">
<div class="imageblock text-center">
<div class="content">
<img src="images/07_data_issues/bias_microsoft_tay.png" alt="image" width="550">
</div>
<div class="title"><span class="small">What started out as a research project to see how humans would interact with an AI-based chatbot, ended up as a PR-nightmare for Microsoft. The chatbot was supposed to learn from the messages written to it, but since the developers apparently thought more about their natural language models instead of human behavior on the internet, Tay quickly learned to repeat all the racist, sexists things others tweeted at her.</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="imageblock text-center">
<div class="content">
<img src="images/07_data_issues/bias_gender_stereotypes_we.png" alt="image" width="620">
</div>
<div class="title"><span class="small">You&#8217;ve already seen how neural network language models learn word embeddings through self-supervised learning. As it turns out, a lot of the texts these models are trained on include, e.g., gender stereotypes, which are then also encoded in the word embeddings. So while the analogy question "<em>man</em> is to <em>king</em> as <em>women</em> is to <em>XXX</em>" might be answered correctly with "<em>queen</em>",  "<em>man</em> is to <em>doctor</em> as <em>women</em> is to <em>XXX</em>" is more likely to be answered with "<em>nurse</em>" instead of "<em>doctor</em>", since this role allocation was typical in the past and is therefore also present in many texts used as training data for these models.</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="imageblock text-center">
<div class="content">
<img src="images/07_data_issues/bias_twitter_imagecrop.png" alt="image" width="550">
</div>
<div class="title"><span class="small">Since many images posted on Twitter are larger than the available space for the preview image, Twitter decided to train a model to select "the most relevant part" of an image to be displayed as a preview. Unfortunately, as they had trained this model on a dataset with more pictures of white than black or brown people, the model became racist and, for example, given a picture with Barack Obama and some random unimportant white politician, it would always select the white politician for the preview image. Similarly, such cropping algorithms were also reported to more often select faces as preview images for men and the body (specifically, you&#8217;ve guessed it, boobs) as preview images for women.</span></div>
</div>
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="imageblock text-center">
<div class="content">
<img src="images/07_data_issues/bias_household_lowerincome.png" alt="image" width="700">
</div>
<div class="title"><span class="small">Most computer vision models are (pre-)trained on the ImageNet dataset, which contains over 14 million hand-annotated pictures, organized in more than 20k categories. However, since these pictures are sourced from the internet and more people from developed instead of developing nations tend to post pictures online, the variety of common household items, for example, is highly skewed towards products found in richer countries. Subsequently, these models mistake, e.g., bars of soap found in a poorer country as food (e.g., one could argue that it does indeed bear some resemblance to a plate food that might be found in a fancy restaurant).</span></div>
</div>
<div class="paragraph text-center">
<p><span class="small">de Vries, Terrance, et al. &#8220;Does object recognition work for everyone?&#8221; <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops.</em> 2019.</span></p>
</div>
</div>
</div>
<div class="paragraph">
<p>The first step to mitigating these problems is to become aware of them. The above problems all arose because the data was not sampled uniformly:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Tay has seen much more racist and hateful comments and tweets than &#8216;normal&#8217; ones</p>
</li>
<li>
<p>In historic texts, women were underrepresented in professions such as doctors, engineers, carpenters, etc.</p>
</li>
<li>
<p>The image dataset Twitter trained its model on included more pictures of white compared to black people</p>
</li>
<li>
<p>Similarly, given a random collection of photos from the internet, these images will have mostly been uploaded by people from developed countries, i.e., pictures displaying the status quo in developing nations will be underrepresented</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>While the training sets used to train modern ML models are usually too big to identify and correct all these problems, at least the test set should be well balanced and curated, such that it is possible to notice such a systematic bias, i.e., a poor performance for undersampled subgroups:</p>
</div>
<div class="paragraph text-center">
<p><span class="image"><img src="images/07_data_issues/bias_unequal_lr.png" alt="image" width="420"></span>
<span class="image"><img src="images/07_data_issues/bias_equal_lr.png" alt="image" width="420"></span><br></p>
</div>
<div class="paragraph text-justify">
<p><span class="small">These two plots show a simple linear regression model trained on data with 3 subgroups (e.g., subgroups could be based on gender and/or race). In both cases, the model performs well for the subgroup in the middle, but poorly for the marginalized subgroups. However, when only looking at the overall \(R^2\) value of the model, the poor performance of the model is only apparent when the subgroups are sampled equally, while in the first plot on the left, the performance of the model seems fine since here the good performance of the "main" subgroup drowns out the poor performance on the marginalized subgroups, since they are undersampled. Similarly, for example, it took researchers a while to realize that speech recognition algorithms perform considerably worse for women than men, where again the training and test data mostly contained data from men (e.g., transcribed political speeches).</span></p>
</div>
<div class="paragraph">
<p>Therefore:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>assess the model&#8217;s performance for each (known) subgroup individually to verify that the prediction errors of the model are random and the model is not systematically worse for some subgroups<br></p>
</li>
<li>
<p>if it is not possible to obtain a well balanced training and/or test set, assign higher sample weights to data points from undersampled subgroups to make sure the algorithm pays enough attention to them during training and they are given more weight in the evaluation of the model (similar to using the balanced accuracy)</p>
</li>
</ul>
</div>
<div class="sect4">
<h5 id="_explicit_discrimination">Explicit discrimination</h5>
<div class="paragraph">
<p>Even more problematic than a mere underrepresentation of certain subgroups (i.e., a skewed input distribution) is a pattern of systematic discrimination against them in historic data (i.e., a discriminatory shift in the assigned labels).</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="imageblock text-center">
<div class="content">
<img src="images/07_data_issues/bias_apple_card.png" alt="image" width="550">
</div>
<div class="title"><span class="small">A lot of explicit discrimination is often encoded in many datasets used to train models for assigning credit scores or determine interest rates for mortgages or loans. Since these application areas have a direct and severe influence on humans' lives, here you have to be especially careful and, for example, check that your model predicts the same score for a man and a woman if all the features of a data point are equal except those encoding a person&#8217;s gender.</span></div>
</div>
</div>
</div>
<div class="paragraph">
<p>In general, you should always be very careful when including variables in the model that encode attributes such as gender or race. For example, the performance of a model that diagnoses heart attacks will most likely be improved by including &#8216;gender&#8217; as a feature, since men and women present different symptoms when they have a heart attack. On the other hand, a model that assigns someone a credit score should probably not rely on the gender of the person for this decision, since, even though this might have been the case in the historic data because the humans that generated the data relied on their own stereotypes, women should not get a lower score just because they are female.</p>
</div>
<div class="paragraph">
<p>However, a person&#8217;s gender or race, for example, might also be correlated with other variables such as income or neighborhood, so even features that look innocent at first might still leak problematic information to the model, therefore in those cases one should take some extra steps to ensure the model does not discriminate based on these features.</p>
</div>
<div class="paragraph">
<p>This can, for example, be achieved by setting up a neural network that learns subgroup-invariant feature representations:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_data_issues/invariant_rep.png" alt="image" width="720">
</div>
</div>
<div class="paragraph">
<p>This architecture works similar to a <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network">Generative Adversarial Network (GAN)</a> in that there are two parts of the network, one that tries to predict the target from the intermediate feature representation and the other (i.e., the adversary) that tries to predict the subgroup label (e.g., gender) from the same representation. The goal here is to find an intermediate feature representation that still includes all the necessary information such that the first network can predict the target, but from which the adversarial network can not predict the subgroup anymore, which can be achieved by training both networks together.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Other examples of what not to do: <a href="https://incidentdatabase.ai/">AI Incidence Database</a> and</p>
</div>
<div class="openblock float-group">
<div class="content">
<div class="paragraph">
<p><span class="image left"><img src="images/09_ml_in_practice/book_weapons_2016.jpg" alt="image" width="140"></span></p>
</div>
<div class="paragraph">
<p>Book recommendation:<br>
<strong>Weapons of Math Destruction</strong> by Cathy O’Neil (2016)</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_explainability_interpretable_ml">Explainability &amp; Interpretable ML</h3>
<div class="paragraph">
<p>Explainability is essential to trust a model&#8217;s predictions, especially in performance-critical areas like medicine (e.g., diagnosis from x-ray images).</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="paragraph">
<p>Explainable/Interpretable ML – distinguish between:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><span class="underline">Local</span> Explainability: explain individual predictions (&#8594; which features from one particular sample lead the model to make a certain prediction (e.g., visualized as a heatmap like that over the image of a horse in the previous section, where the classification decision was made mostly because of the copyright notice))</p>
</li>
<li>
<p><span class="underline">Global</span> Explainability: explain the model behavior in general (&#8594; which features are most important over all)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>&#8594; Some models are <em>intrinsically interpretable</em> (e.g., linear models, decision trees), others require <em>model-agnostic methods</em> to make them explainable, i.e., for these models the interpretability does not come for free.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
Explaining a model and its predictions helps to understand what it learned from the data and why it makes certain mistakes. But only when the model has a good predictive performance <em>and</em> there is reason to believe that the model actually captured the true causal relationship between the inputs and targets, then these explanations might shed light on the <a href="https://towardsdatascience.com/e68626e664b6">true root causes</a> of the underlying process as well. Always discuss the results with a domain expert!
</td>
</tr>
</table>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Correlated features can lead to misrepresented feature importances! (For example, when using a random forest, one decision tree might use one feature in the root node, while another decision tree uses a second feature that is correlated with the first, which means that overall it seems that both features are only somewhat important, while in fact they are just interchangeable and therefore their true feature importance would be the sum of the two individual feature importances.)</p>
</li>
<li>
<p>Beware of <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson&#8217;s paradox</a></p>
</li>
<li>
<p>Possibly look at results for different subsamples of the data</p>
</li>
<li>
<p>Compare feature importances obtained for different models to get a better feeling for which features truly matter for the problem (e.g., investigate why a linear model and a decision tree might base their decisions on different features)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p><span class="underline">Recommended Reading:</span> <a href="https://christophm.github.io/interpretable-ml-book/">Interpretable ML Book</a>, which additionally covers some more advanced methods (however, please keep in mind that explainable AI is about understanding better what happens&#8201;&#8212;&#8201;if you use a complex method to explain your model (e.g., the popular SHAP values) where it is difficult to understand how the explanations were derived, then this might instead result in further uncertainty)</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_explaining_decision_trees_random_forests">Explaining Decision Trees (&amp; Random Forests)</h4>
<div class="paragraph">
<p><strong>Explaining individual predictions</strong>: retrace decision path (in a single tree)</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_explainability/expl_dt.png" alt="image" width="540">
</div>
<div class="title"><span class="small">This is an example of a decision tree plot generated with <code>sklearn</code>. The decision tree has its root at the top (where you start) and the leaves (i.e., those nodes that don&#8217;t branch off anymore) at the bottom (where you stop and make the final prediction). Each node in the tree shows in the first line the variable based on which the next split is made incl. the threshold value (except for leaf nodes), then the current Gini impurity (i.e., how homogeneous the labels of all the samples that ended up in this node are; this is what the decision tree internally optimizes, i.e., notice how the value gets smaller on at least one side after a split), then the fraction of samples that ended up in this node, and the distribution of samples into the different classes (for a classification problem), as well as the label that would be predicted for a sample at this point. So when making a prediction for a new sample with a decision tree, you start at the root node of the tree and then follow the branches down depending on the sample&#8217;s feature values until you reach a leaf node and would then know exactly based on which feature thresholds the prediction for the sample was made.</span></div>
</div>
<div class="paragraph">
<p><strong>Global interpretation</strong>: attribute: <code>feature_importances_</code><br>
How much does a feature reduce the (Gini) impurity?<br>
(Depends on the position of the feature in the tree and how many samples pass through this node.)</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_explainability/expl_dt_featimp.png" alt="image" width="400">
</div>
<div class="title"><span class="small">This is just a bar plot of the values from the <code>feature_importances_</code> attribute of the decision tree shown above. When you&#8217;re using a random forest instead of a single decision tree, it would be impractical to plot all of the individual trees contained in the forest to explain individual predictions, but a random forest at least also has the <code>feature_importances_</code> attribute to examine the global importance of the different features.</span></div>
</div>
</div>
<div class="sect3">
<h4 id="_explaining_linear_models_neural_networks">Explaining Linear Models (&amp; Neural Networks)</h4>
<div class="paragraph">
<p>Since the formula used to make predictions with a linear model is very simple, you can easily understand what is going on. To assess the importance of individual features, either for a single sample or overall, the sum can be decomposed into its individual components:<br>
\(\hat{y} = b + \sum_{k=1}^d w_k \cdot x_k\) &#8658; effect of feature <em>k</em> for ith data point: \(w_k \cdot x_k^{(i)}\):</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_explainability/expl_lm_effects.png" alt="image" width="540">
</div>
<div class="title"><span class="small">The feature effects for a single sample are indicated by the red crosses, i.e., these show whether each feature contributed positively or negatively (or not at all) to the final prediction for this one sample. By computing the feature effects for all samples, we can generate the box plots shown below the red crosses, which display the distribution of feature effects for all samples and therefore indicate which features are overall important for the prediction (= those with the largest absolute values). For example, in this plot you can see that the feature 'AveOccup' has an effect of around zero for all but one sample, which indicates that the model might have overfit on one outlier point and it might be best to exclude this feature altogether.</span></div>
</div>
<div class="paragraph">
<p>&#8594; It is easier to understand and validate the results if only a few features are considered important, therefore you might want to use a L1-regularized model (e.g., <code>linear_model.LassoLarsCV</code>) to get sparse weights.</p>
</div>
<div class="paragraph">
<p><span class="underline">Generalization for neural networks:</span> <strong>Layer-wise Relevance Propagation (LRP)</strong>: similar to how the prediction of the linear model was split up into the contributions of the individual input features, by keeping track of the gradients of the weights in a neural network, here as well the decision can be decomposed to obtain the influence of each feature on the final prediction. This is similar to what happens in the backpropagation procedure when training the network, only that with LRP not the prediction error, but the prediction itself is propagated backwards layer by layer (hence the name) until we arrive at the input layer and get the individual contributions of the features.<br>
(For <code>torch</code> networks, this approach is implemented in the <a href="https://captum.ai/"><code>captum</code> library</a> as the &#8216;Input X Gradient&#8217; method. The library also contains many other methods for interpreting neural networks, however, I find this the most natural approach, since it is a direct extension of the intuitive feature effects approach used to interpret linear models.)</p>
</div>
</div>
<div class="sect3">
<h4 id="_global_model_agnostic_permutation_feature_importance">[Global] Model-agnostic: permutation feature importance</h4>
<div class="paragraph">
<p>The first question when it comes to global explainability is always &#8220;Which features are important?&#8221;, i.e., how much does the model rely on each feature when making its predictions?
You can shed light on this using the permutation importance, which, for each feature, is computed like this:<br>
&#8216;Feature importance&#8217; = &#8216;performance of trained model on original dataset&#8217;&#8201;&#8212;&#8201;&#8216;performance when values for this feature are shuffled&#8217;.<br>
I.e., first, a trained model is normally evaluated on the original dataset (either training or test set), then for one feature the values for all samples are permuted and the performance of the trained model on this modified dataset is computed again. If there is a big discrepancy between the performance on the original and permuted datasets, this means the model heavily relies on this feature to make correct predictions, while if there is no difference, then this feature is not relevant (e.g., a linear model that has a coefficient of zero for one feature would not change its predictions if this feature was shuffled).</p>
</div>
<div class="paragraph">
<p>Since a single permutation of a feature might by chance shuffle the values in a way that is close to the original ordering, this process is performed multiple times, i.e., we get a distribution of the permutation importance scores for each feature, which can again be visualized in a box plot:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_explainability/expl_perm_imp.png" alt="image" width="540">
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.inspection</span> <span class="keyword">import</span> <span class="include">permutation_importance</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_global_model_agnostic_influence_of_individual_features_on_prediction">[Global] Model-agnostic: influence of individual features on prediction</h4>
<div class="paragraph">
<p>After you&#8217;ve identified which features are important for a model in general, you can dig deeper to see <em>how</em> each of these features influences the final prediction. A simple way to accomplish this is with <strong>Individual Conditional Expectation (ICE) &amp; Partial Dependence (PD) Plots</strong>. These are generated by taking some samples and systematically vary the feature in question (i.e., set it to many different values within the normal range of values for this feature while keeping everything else about the data points the same) and then observe by how much and in which direction the predictions for these samples change in response to the different values set for the feature.</p>
</div>
<div class="paragraph">
<p>The ICE plot then shows the results for individual samples (thin lines), while the PD plot shows the averaged values (think line), where the ICE plot can be used to verify that some opposite changes in individual samples are not averaged out in the PD plot:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/07_explainability/expl_pdp.png" alt="image" width="740">
</div>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
One big drawback of this approach is that it assumes that features are independent of each other, i.e., since the features are varied individually, this can result in unrealistic feature combinations (e.g., if one feature is the height of a person (in the range of 60-200cm) and another feature is the weight (30-120kg), then when these features are varied independently, at some point we would evaluate a data point with height: 200cm and weight: 30kg, which seems like a very unhealthy combination). However, by examining the ICE plot for possibly erratic changes for individual samples, this can usually be spotted. And in general&#8201;&#8212;&#8201;this goes for all explainability methods&#8201;&#8212;&#8201;the results should not be over-interpreted, i.e., they are good for showing rough trends, but remember that the plots might also look completely different when you use them with a different type of model trained on the same dataset, i.e., be careful before concluding anything about the root causes of a problem based on these results.
</td>
</tr>
</table>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python"><span class="keyword">from</span> <span class="include">sklearn.inspection</span> <span class="keyword">import</span> <span class="include">partial_dependence</span></code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_local_model_agnostic_local_interpretable_model_agnostic_explanations_lime">[Local] Model-agnostic: <em>Local Interpretable Model-agnostic Explanations</em> (LIME)</h4>
<div class="paragraph">
<p>To generate an explanation for a single sample of interest:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>generate a local neighborhood dataset through small perturbations of the sample&#8217;s feature vector</p>
</li>
<li>
<p>use the original model to predict labels for these new points (i.e., generate an artificial labeled training set for the local surrogate model)</p>
</li>
<li>
<p>train an intrinsically interpretable model on the neighborhood dataset (e.g., a linear model, i.e., while the decision surface of the original model might be very complex, we assume that we can approximate it locally with a linear function)</p>
</li>
<li>
<p>interpret the local surrogate model&#8217;s prediction for the sample</p>
</li>
</ol>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
explaining ML with more ML&#8230;&#8203;
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>&#8594; <a href="https://github.com/marcotcr/lime"><code>lime</code> Python library</a></p>
</div>
</div>
<div class="sect3">
<h4 id="_example_based_explanations">Example-Based Explanations</h4>
<div class="paragraph">
<p>Manually examine some of the data points for which the model predicted a certain target &amp; hopefully notice a pattern&#8230;&#8203;</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Prototypes</strong>: representative samples, e.g., cluster centroids</p>
</li>
<li>
<p><strong>Optimal inputs</strong>: optimized samples that result in a strong prediction of the given target (e.g., in a neural network you can also optimize the input instead of the weights. I.e., you might start with an image showing random noise and the network will tell you &#8220;I have no idea what that should be!&#8221;. Then you tell the network &#8220;No, you should have predicted 'monkey' for this input!&#8221; and then instead of adapting the weights of the network in response to the prediction error, you change the inputs itself, such that the random noise starts to look a bit more like an image of a monkey. After doing this multiple times, i.e., changing the original inputs more and more towards something where the network is confident that it recognizes a monkey in the image, you&#8217;ve created an optimal input revealing what the network thinks is characteristic for a monkey.)</p>
</li>
<li>
<p><strong>Counterfactual examples</strong>: samples with minor modifications that change the prediction (e.g., similar to how the optimal inputs are generated you can also start with an image from a different class instead of random noise and adapt it until the network changes its prediction for it)</p>
</li>
<li>
<p><strong>Adversarial examples</strong>: counterfactual examples where a human doesn&#8217;t notice the change</p>
</li>
</ul>
</div>
<div class="paragraph text-center">
<p><span class="image"><img src="images/07_explainability/deep_dream1.png" alt="image" width="180"></span> <span class="image"><img src="images/07_explainability/deep_dream2.png" alt="image" width="180"></span><br>
<span class="small">Typical data points and optimal inputs generated with <a href="https://distill.pub/2017/feature-visualization/">Google&#8217;s &#8216;DeepDream&#8217;</a></span></p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_reinforcement_learning">Reinforcement Learning</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Finally, we come to the last main category of ML algorithms besides unsupervised and supervised learning: reinforcement learning.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Main idea</dt>
<dd>
<p>Agent performs actions in some environment and learns their (state-specific) consequences by receiving rewards.</p>
</dd>
</dl>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/08_rl/reinforcement_learning4.png" alt="image" width="640">
</div>
<div class="title"><span class="small">The environment lets the agent know in which state it currently is. Then the agent selects some action, i.e., how it responds to this state, according to its internal policy function \(\pi\) (the main thing that is learned in RL). The environment evaluates the consequences of this action and returns an immediate reward (e.g., "game over" or "collected a coin"), as well as the next state, at which point the cycle repeats.</span></div>
</div>
<div class="paragraph">
<p><span class="underline">Goal:</span> maximize <em>cumulative</em> reward (also called <em>return</em>), i.e., the sum of the immediate rewards received from the environment over all time steps.<br>
The difficult thing here is that sometimes an action might not result in a big immediate reward, but is still crucial for the agent&#8217;s long-term success (e.g., finding a key at the beginning of a level and the door for which you need the key comes much later). This means the agent needs to learn to perform an optimal <em>sequence of actions</em> from <em>delayed labels</em>.</p>
</div>
<div class="paragraph">
<p>The agent&#8217;s decision trajectory basically defines one path among a bunch of different possible parallel universes, which is then judged in the end by the collected return:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/08_rl/rl_trajectory2.png" alt="image" width="720">
</div>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Reinforcement Learning vs. &#8216;normal&#8217; Optimization</dt>
<dd>
<p>In regular mathematical optimization, you are given some fixed function \(f: \mathbb{R}^d \to \mathbb{R}\) and try to find the inputs \(\mathbf{x} \in  \mathbb{R}^d\) that maximize (or minimize) the value of \(f(\mathbf{x})\). Since each evaluation of \(f(\mathbf{x})\) is independent of the next, you could theoretically try as many different values for \(\mathbf{x}\) as you wanted, until you&#8217;ve found some combination of inputs that results in an optimal value for \(f\).<br>
<span class="small">If \(f\) is easily differentiable, the solution to the optimization problem can be found analytically by setting the first derivative of \(f\) to zero to obtain the local extrema or saddle points of \(f\), which can then be examined further to determine the (global) maximum or minimum. If \(f\) is not differentiable (or very complicated), there exist other methods to find optimal values (for example, the gradient descent procedure used to tune the weights of neural networks is one method for obtaining a (local) optimum without calculating the derivative of the network&#8217;s error function directly, while a naive grid search, where you just try many different input combinations and then select the values with the best outcome, or more fancy approaches such as <a href="https://en.wikipedia.org/wiki/Particle_swarm_optimization">particle swarm optimization</a>, can also be applied to functions that are non-differentiable).</span><br></p>
<div class="paragraph">
<p>Translated to RL terms, \(f\) would be the environment <em>in the current state</em>, \(\mathbf{x}\) would be the action, and \(f(\mathbf{x})\) would be the immediate reward as a result of taking this action in the current state. However, since the state of the environment changes with each action that is taken, this means the function \(f\) also changes in each step and an action that might have resulted in a high reward in the previous step could now mean &#8220;game over&#8221;. Furthermore, in RL we&#8217;re not actually too concerned about every single immediate reward, but instead we want to achieve long-term success, measured by the return (i.e., cumulative rewards), and an action with a low immediate reward might still pay off later.</p>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Immediate rewards vs. long-term value of states</dt>
<dd>
<p>To make decisions that are good in the long run, we&#8217;re more interested in what being in a state means w.r.t. reaching the final goal instead of receiving immediate rewards:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/08_rl/rl_value3.png" alt="image" width="640">
</div>
<div class="title"><span class="small"><em>Left:</em> This is a simple "grid world", where an agent can move up, down, left, or right through the states. This small environment contains three terminal states (i.e., when the agent reaches one of them, the episode ends): Two states mean "game over" with an infinite negative reward, while reaching the state in the lower right corner means receiving a large positive immediate reward. When the agent resides in any of the other (reachable) states, it receives a small negative reward, which is meant to "motivate" the agent to go to the goal state as quickly as possible. However, knowing only the immediate reward received in each state is not very helpful to decide which action to take next, since in most states, the reward for moving to the next state or staying in place would be the same. Therefore, what the agent needs to learn in order to be able to choose an action in each state that has the potential of bringing it closer to the goal state, is the value of being in each state. <em>Right:</em> The value of a state is the expected return when starting from this state. Of course, the expected return is highly dependent on the agent&#8217;s policy \(\pi\) (i.e., the actions it takes), e.g., if the agent would always move to the left, then it would never be able to reach the goal, i.e., the expected return starting from any state (except the goal state itself) would always be negative. If we assume an optimal policy (i.e., the agent always takes the quickest way to the goal), then the value of each state would correspond to the ones shown in the graphic, i.e., for each state "100 minus the number of steps to reach the goal from here". Knowing these values, the agent can now very easily select the best next action in each state, by simply choosing that action, which brings it to the next reachable state with the highest value.</span></div>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>The value of a state \(s\) corresponds to the expected return \(G_t\) when starting from state \(s\):</p>
</div>
<div class="stemblock">
<div class="content">
\[V^\pi(s) = \mathbb{E} [G_t | S_t = s]\]
</div>
</div>
<div class="paragraph">
<p>The most naive way to calculate \(V^\pi(s)\) would be to let the agent start from this state several times (depending on how complex the environment is usually several thousand times), note how each of the episodes play out, and then compute the average return that the agent had received in all these runs starting from state \(s\).</p>
</div>
<div class="paragraph">
<p>Similarly, we can also use the expected return when executing action \(a\) in state \(s\):</p>
</div>
<div class="stemblock">
<div class="content">
\[Q^\pi(s, a) = \mathbb{E} [G_t | S_t = s, A_t = a] \quad \quad \text{with } \,a = \pi(s)\]
</div>
</div>
<div class="paragraph">
<p>I.e., here again we could let the agent start from the state \(s\) many times, but this time the first action it takes in this state is always \(a\).</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Exploration/Exploitation trade-off</dt>
<dd>
<p>Of course, it would be very inefficient to always just randomly try out actions in any given state and thereby risk a lot of predictable &#8220;game over&#8221;. Instead, we want to balance exploration and exploitation to keep updating our knowledge about the environment, but at the same time also maximize the rewards collected along the way. This is again inspired by human behavior:</p>
<div class="openblock">
<div class="content">
<div class="ulist none">
<ul class="none">
<li>
<p>&#8594; <strong><em>Exploration:</em></strong> Learn something about the environment (e.g., try a new restaurant)</p>
</li>
<li>
<p>&#8594; <strong><em>Exploitation:</em></strong> Use collected knowledge to maximize reward (e.g., eat somewhere you know you love the food)</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>A very simple strategy to accomplish this is the <span class="underline"><em>Epsilon-Greedy Policy:</em></span></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="python">initialize eps = <span class="integer">1</span>
<span class="keyword">for</span> step <span class="keyword">in</span> <span class="predefined">range</span>(max_steps):
    <span class="keyword">if</span> random(<span class="integer">0</span>, <span class="integer">1</span>) &gt; eps:
        pick best action (= exploitation)
    <span class="keyword">else</span>:
        pick random action (= exploration)
    <span class="predefined">reduce</span> eps</code></pre>
</div>
</div>
</dd>
<dt class="hdlist1">Tabular RL: Q-Learning</dt>
<dd>
<p>This brings us to the simplest form of RL, tabular RL, where an agent has a finite set of actions to choose from and operates in an environment with a finite set of states (like the grid world from above). Here, one could simply compute the Q-value for each (state, action)-combination as described above, and save these values in a big table. This so-called Q-table then acts as a cheat sheet, since for each state the agent is in, it can just look up the Q-values for all of the available actions and then simply choose the action with the highest Q-value:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/08_rl/rl_tabular3.png" alt="image" width="580">
</div>
</div>
</dd>
<dt class="hdlist1">Function Approximation: Deep Q-Learning</dt>
<dd>
<p>Unfortunately, almost no practical RL application operates in an environment consisting of a finite set of discrete states (and sometimes even the agent&#8217;s actions are not discrete (e.g., the steering wheel in a self-driving car), but this goes too far here). In video games, for example, each frame would be considered a new state and depending on the complexity of the game, no two frames might be exactly alike. This is where deep Q-learning comes in:<br></p>
<div class="paragraph">
<p>Given a state \(s\) (represented by a feature vector \(\mathbf{x}_s\)), predict the Q-value of each action \(a_1 ... a_k\) with a neural network:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/08_rl/rl_dqn.png" alt="image" width="640">
</div>
</div>
<div class="paragraph">
<p>This can be seen as a direct extension of the tabular Q-learning: If we represented our states as one-hot encoded vectors and used a linear network with a single weight matrix that consisted of the Q-table we had constructed before, by multiplying such a one-hot encoded vector with the Q-table, the network would &#8220;predict&#8221; the row containing the Q-values for all actions in this state.<br>
By using a more complex network together with meaningful feature representations for the states, with deep Q-learning the agent is able to generalize to unseen states. (Just like in time series forecasting tasks, here again the feature representation of a state needs to include all the relevant information about the past, e.g., in video games (think: old pong game) the feature vector could contain the last 4 frames to additionally capture the direction of movement.)</p>
</div>
</dd>
</dl>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Pros</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>RL works well for games:<br>
&#8594; environment = game = simulation (i.e., no discrepancy between &#8220;real world&#8221; and simulation model)<br>
&#8594; well defined reward function<br>
&#8594; utilize &#8220;self-play&#8221; for multi-player games, i.e., two RL agents playing against each other</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Careful</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>Acting in the real world is too expensive &#8594; need accurate (simulation) model of the environment</p>
</li>
<li>
<p>AIs love to cheat and exploit bugs in the simulation</p>
</li>
<li>
<p>Difficult to design appropriate reward function (and RL will overfit it, resulting in unintended consequences)</p>
</li>
<li>
<p>Model-free RL is very sample inefficient (i.e., needs millions of iterations, which takes too long in real-time)</p>
</li>
<li>
<p>Agent is responsible for collecting its own experiences: bad policy &#8658; bad data &#8658; no improvement</p>
</li>
<li>
<p>Deep RL: complex network architectures, very sensitive to hyperparameter choices<br>
&#8658; hard to train &amp; get robust results (&#8594; requires lots of tricks)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>&#8594; <em>Imitation learning</em> is often used instead of RL, which just means using supervised learning to train an agent to react similar to a human in some situation. Often, it is also easier to collect data from humans than to define a complicated reward function (e.g., humans drive around all the time, however, it is hard to define what would be considered &#8220;good driving&#8221; under lots of different circumstances).</p>
</div>
</div>
</div>
<div class="paragraph">
<p><strong>RL further reading + videos</strong></p>
</div>
<div class="paragraph">
<p><span class="underline">General theory:</span></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://medium.com/emergent-future/d195264329d0">Simple Blog Series</a></p>
</li>
<li>
<p><a href="https://simoninithomas.github.io/deep-rl-course/">Free RL course incl. programming examples</a></p>
</li>
<li>
<p><a href="https://www.davidsilver.uk/teaching/">Lectures by David Silver</a> (from DeepMind)</p>
</li>
<li>
<p><a href="https://cs234.stanford.edu/">Stanford RL course</a> (with <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u">video lectures</a>)</p>
</li>
<li>
<p><a href="http://incompleteideas.net/book/RLbook2020.pdf">Book about RL</a> (with lots of math)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><span class="underline">Words of caution (recommended for everyone):</span></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.alexirpan.com/2018/02/14/rl-hard.html">RL doesn&#8217;t work (yet)</a></p>
</li>
<li>
<p><a href="https://deepmind.com/blog/article/Specification-gaming-the-flip-side-of-AI-ingenuity">Unintended rewards</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><span class="underline">RL in action:</span></p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.youtube.com/watch?v=5GMDbStRgoc">Playing Super Mario</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=rhNxt0VccsE">Learning to walk</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=wL7tSgUpy8w">Learning to drive a car</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=iaF43Ze1oeI">Robot arm data collection</a> (by Google)</p>
</li>
<li>
<p><a href="https://youtu.be/wRCAl9m3ce8?t=1493">Playing video games</a> with Layer-wise Relevance Propagation (LRP) to show the evolution of strategy</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_conclusion">Conclusion</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Now that you&#8217;ve learned a lot about the ML theory, especially the different algorithms:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/01c_ml_overview/ml_algorithms.png" alt="image" width="840">
</div>
</div>
<div class="paragraph">
<p>&#8230;&#8203;it is time to do a bit of a reality check.</p>
</div>
<div class="paragraph">
<p><strong>Hype vs. Reality</strong></p>
</div>
<div class="paragraph">
<p>In the introduction, you&#8217;ve seen a lot of examples that contribute to the ML hype. However, especially when applying ML in the manufacturing industry, the reality often looks quite different and not every idea might work out as hoped:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Hype: <em>Big Data, Deep Learning</em></th>
<th class="tableblock halign-left valign-top">Reality:</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">database with millions of examples</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">150 manual entries in an excel sheet</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">homogeneous unstructured data (e.g., pixels, sound, text)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">measurements from different sources with different scales (e.g., temperature, flow, pressure sensors)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fancy deep learning architectures</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">neural networks are tricky to train and even more difficult to explain<br>
&#8594; need to understand and trust predictions to make business decisions</p></td>
</tr>
</tbody>
</table>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">What if I <em>do</em> have Big Data?</dt>
<dd>
<p>Practical definition:<br>
<em>Big Data is what does not fit in your RAM anymore.</em></p>
</dd>
</dl>
</div>
<div class="paragraph">
<p><strong>Solutions:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Do you <em>really</em> have Big Data?<br>
measurements from 100 sensors every second for 1 year:<br>
❌ \(100\times 365 \times 24 \times 60 \times 60 \times 64 \text{ bits} \approx 25\text{ gb}\)<br>
Process changes slowly &#8594; take hourly averages:<br>
✅ \(100\times 365 \times 24 \times 64 \text{ bits} \approx 7\text{ mb}\)</p>
</li>
<li>
<p>Get more RAM! (E.g., through a cloud service like AWS)</p>
</li>
<li>
<p>Use an ensemble method, i.e.,<br>
a) split your data in equal (RAM-sized) chunks,<br>
b) train a model on each chunk,<br>
c) combine the predictions of all models.</p>
<div class="paragraph">
<p>(This is also what the &#8216;big data&#8217; libraries do internally, e.g., MapReduce; especially useful when the data doesn&#8217;t fit onto a single hard drive anymore.)</p>
</div>
</li>
</ol>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Machine Learning is just the tip of the iceberg</dt>
<dd>
<p>You were already warned that in their day-to-day operations, data scientists usually spend only about 10% of their time doing the fun machine learning stuff, while the bulk of their work consists of gathering and cleaning data. While this is true for an individual ML project, if your goal is to become a data-driven enterprise that uses AI in production for a wide range of applications, there are some additional challenges that should to be addressed (but which would typically not be the responsibility of a data scientist (alone)):</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/09_ml_in_practice/iceberg.png" alt="image" width="640">
</div>
<div class="title"><span class="small">See also: Sculley, David, et al. &#8220;Hidden technical debt in machine learning systems.&#8221; Advances in Neural Information Processing Systems. 2015.</span></div>
</div>
<div class="paragraph">
<p>(However, the nice thing here is that many of these processes and infrastructure only need to be set up once and then all future ML projects will benefit from this (e.g., a centralized data infrastructure and clear governance process.)</p>
</div>
</dd>
<dt class="hdlist1">Domain knowledge is key!</dt>
<dd>
<p>In the introduction, you&#8217;ve seen the Venn diagram showing that ML lies at the intersection of math and computer science. However, this is actually not the complete picture. In the previous chapters, you&#8217;ve hopefully picked up on the fact that in order to build trustworthy models that use meaningful features to arrive at robust conclusions, it is necessary to combine ML with some domain knowledge &amp; understanding of the business problems, what is then often referred to as Data Science:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/venn3.png" alt="image" width="680">
</div>
</div>
<div class="paragraph">
<p>(However, as we will argue the next section, it is unrealistic to expect an individual data scientist to be an expert in all three areas, and we therefore instead propose three data-related roles to divide responsibilities in an organization.)</p>
</div>
</dd>
</dl>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist">
<dl>
<dt class="hdlist1">Take Home Messages</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>ML is &amp; will be transforming all areas of our lives incl. work</p>
</li>
<li>
<p>ML has limitations:</p>
<div class="ulist">
<ul>
<li>
<p>Performance: some problems are hard</p>
</li>
<li>
<p>Data Quality &amp; Quantity: Garbage in, garbage out!</p>
</li>
<li>
<p>Causality &amp; Adversarial Attacks &#8658; Explainability!!!</p>
</li>
</ul>
</div>
</li>
<li>
<p>Combine ML with domain expertise!</p>
</li>
<li>
<p>It’s an iterative process!</p>
<div class="ulist">
<ul>
<li>
<p>Don’t expect ML to work right away!</p>
</li>
<li>
<p>Monitor &amp; update after initial release</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p><span class="underline">Also:</span></p>
</div>
<div class="ulist">
<ul>
<li>
<p>be clear about what you want to do (inputs &amp; outputs; model type; evaluation metric)</p>
</li>
<li>
<p>data preprocessing &amp; feature engineering are at least as important as the &#8220;real&#8221; ML stuff</p>
</li>
<li>
<p>fancy deep learning methods might not work with the data in your excel sheet</p>
</li>
<li>
<p>but linear models and decision trees are great too (with the right features)</p>
</li>
<li>
<p>always be careful when evaluating your models; manually examine some errors</p>
</li>
<li>
<p>KNOW YOUR DATA</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_ai_transformation_of_a_company">AI Transformation of a Company</h3>
<div class="paragraph">
<p>The famous ML researcher Andrew Ng has proposed a five-step process to transform your company into a data-driven enterprise capable of using AI in production to add value.</p>
</div>
<div class="sidebarblock">
<div class="content">
<div class="dlist left">
<dl>
<dt class="hdlist1">5 Steps for a successful AI Transformation by Andrew Ng</dt>
<dd>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Execute pilot projects to gain momentum</p>
</li>
<li>
<p>Build an in-house AI team &amp; data infrastructure</p>
</li>
<li>
<p>Provide broad AI training (for all employees)</p>
</li>
<li>
<p>Develop an AI &amp; data strategy</p>
</li>
<li>
<p>Develop internal and external communications</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><span class="underline">Recommended Materials:</span><br>
&#8594; <a href="https://de.coursera.org/learn/ai-for-everyone">&#8220;AI for everyone&#8221; Coursera course</a><br>
&#8594; <a href="https://landing.ai/ai-transformation-playbook/">AI Transformation Playbook</a><br></p>
</div>
</dd>
</dl>
</div>
<div class="paragraph text-center">
<p><span class="image"><img src="images/09_ml_in_practice/01_Andrew_Ng.jpg" alt="image" width="140"></span><br>
<strong>Andrew Ng</strong><br>
<span class="small">Co-Founder Google Brain</span><br>
<span class="small">Vice President Baidu</span><br>
<span class="small">Co-Founder Coursera</span><br>
<span class="small">Professor @ Stanford University</span></p>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">[Step 1] Start with small pilot projects to understand the potential and challenges of using ML</dt>
<dd>
<p>Machine learning projects are unlike traditional software projects, where you&#8217;re usually pretty certain that a solution at least exists and you only need to figure out an efficient way to get there. Instead, ML heavily relies on the available data and even though it might theoretically be possible to solve your problem with ML, this might not be the case with the data you have at hand.
Before implementing some big AI initiative spanning the whole company, it is therefore strongly recommended that you start with some smaller pilot projects, in order to get a better feeling for what it means to rely on an AI to solve your problems.<br>
When choosing a pilot project, the most important factor is not the Return on Investment (ROI) of the project, since here the experience with ML gained along the way should be the priority. However, it is important to choose a project that is <strong>technically feasible</strong> (i.e., for which existing ML algorithms exist and you don&#8217;t need years of research to develop your own fancy neural network architecture) and where you have enough high-quality <strong>data available</strong> to get started (i.e., so you don&#8217;t spend months just on data preprocessing, e.g., due to the need to combine data from different sources within a poor data infrastructure).<br>
If you do not yet have the necessary AI talent in-house to tackle such a project on your own, you can also partner with external consultants, which provide the ML expertise, while you supply the domain knowledge to ensure the pilot project is a success.</p>
</dd>
<dt class="hdlist1">[Step 2] Set up a centralized AI team and data infrastructure to carry out bigger projects efficiently &amp; effectively</dt>
<dd>
<p>We&#8217;ve already seen that in practice, it&#8217;s really about the intersection of Theory, Programming, and Domain Knowledge, i.e., Data Science. However, it is unlikely that you&#8217;ll find a single person that is truly competent in all three areas. Instead, people will always have a certain focus and we therefore propose three distinct roles, which also align very well with the three main steps for successfully executing a ML project:</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/01b_intro_ml/venn7.png" alt="image" width="680">
</div>
<div class="title"><span class="small">While Data Strategists work in their respective departments to identify suitable problems that can benefit from ML, Data Scientist can experiment and develop prototypical solutions to these problems, which Data Engineers then get ready for production.</span></div>
</div>
<div class="paragraph">
<p>Ideally, data scientists and engineers should be in their own separate team (i.e., the &#8220;AI Team&#8221;) and work on projects from different departments like an in-house consultancy:</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="images/09_ml_in_practice/ai_team_mitceo.png" alt="image" width="400">
</div>
<div class="title"><span class="small">[Adapted from: &#8220;AI for everyone&#8221; by Andrew Ng (coursera.org)]</span></div>
</div>
<div class="paragraph">
<p>This has several advantages:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Data scientists can discuss solutions with other ML experts (&#8594; many problems will be similar from an algorithmic standpoint)</p>
</li>
<li>
<p>Combine data from the whole company for a holistic analysis</p>
</li>
<li>
<p>Funding independent from individual business unit (necessary for the up front investment in data infrastructure, time required to keep up with new research, etc.)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">[Step 3] Train other employees to recognize ML problems &amp; establish a data-driven culture</dt>
<dd>
<p>While data scientists need to be intimately familiar with the algorithms they are using, other employees (especially data strategists and department leaders) should have some basic understanding of what ML is (and is not) capable of, such that they can identify possible ML problems and refer them to the AI team.</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/09_ml_in_practice/ml_workshops.png" alt="image" width="840">
</div>
<div class="title"><span class="small">In addition to the hands-on Data Scientist workshop, I also offer Data Strategist and Executive trainings, which cover the broad ideas discussed in this book, but without the technical details.</span></div>
</div>
</dd>
<dt class="hdlist1">[Step 4] Devise a cohesive strategy with long-term goals that result in a competitive advantage</dt>
<dd>
<p>Developing a strategy might be the first impulse of an executive when confronted with a new topic such as AI. However, since AI problems are so different from other kinds of projects, it really pays off to first gain some experience with this topic (i.e., start at step 1!). After you&#8217;ve successfully completed some pilot projects and set the wheels in motion to create an AI team as well as educate the other employees to get them on board (instead of them being afraid than an AI will soon take their job), here are a few things to consider w.r.t. a companywide strategy to give you an advantage over your competition:</p>
<div class="ulist">
<ul>
<li>
<p>Create strategic data assets that are hard for your competition to replicate:</p>
<div class="ulist">
<ul>
<li>
<p>Long-term planning: Which data might be valuable in the future? &#8594; Start collecting it now!</p>
</li>
<li>
<p>Up-front investments: What infrastructure &amp; processes are needed to make the data accessible to the right people?</p>
</li>
<li>
<p>How can you combine data from different divisions to enable the AI team to &#8220;connect the dots&#8221; and gain a unique edge over the competition?</p>
</li>
<li>
<p>What options do you have in terms of strategic data acquisition, e.g., in the form of &#8216;free&#8217; products, where users pay with their data (like what Google, Facebook, etc. are doing)?</p>
</li>
</ul>
</div>
</li>
<li>
<p>Build AI-powered features that are a unique selling point for your products:</p>
<div class="ulist">
<ul>
<li>
<p>Don&#8217;t try to recreate some off-the-shelf service that could be easily procured from an outside vendor, but use ML together with your unique domain knowledge and data to build new features for your existing products to make them more appealing to your customers or open up new market segments.</p>
</li>
<li>
<p>How can you establish a virtuous cycle, where your AI attracts more users, which in turn generate more data, which can then be used to train the AI to become even better and thereby attracts even more users?</p>
<div class="imageblock text-center">
<div class="content">
<img src="images/09_ml_in_practice/ai_cycle.png" alt="image" width="170">
</div>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">[Step 5] Communicate your success</dt>
<dd>
<p>After successfully implementing AI within the company, you should of course communicate your accomplishments. In addition to (internal and external) press releases, this also includes, for example, job listings, which will attract more (qualified) candidates if they are formulated from an informed standpoint instead of using a bunch of random buzzwords.</p>
</dd>
</dl>
</div>
</div>
<div class="sect2">
<h3 id="_additional_resources">Additional Resources</h3>
<div class="dlist">
<dl>
<dt class="hdlist1">Cheat Sheet &amp; Exercises</dt>
<dd>
<p>If you haven&#8217;t already done so, have a look at:</p>
<div class="ulist">
<ul>
<li>
<p>the <a href="https://github.com/cod3licious/ml_exercises/blob/main/other/exercise_your_ml_project.pdf">ML project worksheet</a>, which can help you plan your next machine learning project</p>
</li>
<li>
<p>the <a href="https://github.com/cod3licious/ml_exercises/blob/main/other/cheatsheet.pdf">cheat sheet</a>, which includes a step-by-step guide on how to solve a data science problem (incl. code snippets)</p>
</li>
<li>
<p>and the <a href="https://github.com/cod3licious/ml_exercises">exercises</a>, to get your hands dirty and apply what you&#8217;ve learned.</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Textbooks: theoretical background (i.e. math!)</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><em>Pattern Recognition and Machine Learning</em> by Christopher M. Bishop (2006)</p>
</li>
<li>
<p><em>Elements of Statistical Learning</em> by T. Hastie, R. Tibshirani, J. Friedman (2009)</p>
</li>
<li>
<p><em>Deep Learning</em> by I. Goodfellow, Y. Bengio, A. Courville (2016)</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="paragraph text-center">
<p><span class="image"><img src="images/09_ml_in_practice/book_bishop_2006.jpg" alt="image" width="188"></span>
<span class="image"><img src="images/09_ml_in_practice/book_hastie_2009.jpg" alt="image" width="188"></span>
<span class="image"><img src="images/09_ml_in_practice/book_deeplearning_2016.jpg" alt="image" width="188"></span></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Other Resources</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><a href="https://scikit-learn.org/stable/user_guide.html"><code>sklearn</code> User Guide</a></p>
</li>
<li>
<p><a href="https://deeplearning.ai/the-batch/">DeepLearning.AI – The Batch Newsletter</a></p>
</li>
<li>
<p><a href="https://machinelearningmastery.com/">Machine Learning Mastery</a> Tutorials &amp; more</p>
</li>
<li>
<p><a href="https://towardsdatascience.com/">Towards Data Science Blog</a></p>
</li>
<li>
<p><a href="https://www.datacamp.com/community/data-science-cheatsheets">Data Camp Cheat Sheets</a></p>
</li>
<li>
<p>Online Courses, e.g., <a href="https://www.coursera.org/">Coursera</a> / <a href="https://www.udacity.com/">Udacity</a> / <a href="https://www.udemy.com">Udemy</a> / <a href="https://www.elementsofai.com/">Elements of AI</a> / &#8230;&#8203;</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Connecting</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.meetup.com/">Meetups</a> (e.g., search for PyData)</p>
</li>
<li>
<p><a href="https://pydata.org/">PyData Conference</a> (e.g., in <a href="https://berlin.pydata.org/">Berlin</a>)</p>
</li>
</ul>
</div>
</dd>
<dt class="hdlist1">Getting your hands dirty</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><a href="https://www.kaggle.com/">Kaggle Competitions</a></p>
</li>
<li>
<p><a href="https://solveforgood.org/">Data Science for Social Good</a></p>
</li>
<li>
<p><a href="https://correlaid.org/">CorrelAid</a></p>
</li>
<li>
<p><a href="https://www.wildlife.ai/">Wildlife Conservation</a></p>
</li>
<li>
<p><a href="https://www.climatechange.ai/">Climate Change</a></p>
</li>
<li>
<p><a href="https://datasetsearch.research.google.com/">Google Dataset Search</a></p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</div>
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains("stemblock")) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
<style type="text/css">
  footer{margin:0;padding:0;border:0;font:inherit;vertical-align:baseline;display:block}
  footer p{color:#f2f2f2}a{text-decoration:none;color:#0F79D0;text-shadow:none;transition:color 0.5s ease;transition:text-shadow 0.5s ease;-webkit-transition:color 0.5s ease;-webkit-transition:text-shadow 0.5s ease;-moz-transition:color 0.5s ease;-moz-transition:text-shadow 0.5s ease;-o-transition:color 0.5s ease;-o-transition:text-shadow 0.5s ease;-ms-transition:color 0.5s ease;-ms-transition:text-shadow 0.5s ease}
  footer a{color:#F2F2F2;text-decoration:underline}
  #footer{background:#212121}
  .outer{width:100%}.inner{position:relative;max-width:640px;padding:0px 0px;margin:0 auto}
 .toc-current{font-weight: bold;} .toc-root{font-family: "Source Sans Pro",sans-serif;
                       font-size: 0.9em;} #content{display: flex; flex-direction: column; flex: 1 1 auto;}
             .nav-footer{text-align: center; margin-top: auto;}
             .nav-footer > p > a {white-space: nowrap;}
</style>

<!-- FOOTER  -->
<div id="footer" class="outer">
  <footer class="inner">
    <p><b>Book/Course Feedback: </b> <a href="https://forms.gle/Ccv5h5zQxwPjWtCS7" target="_blank">Full Feedback Survey</a> or <a href="https://forms.gle/qK8T5ALzgpiZaxd49" target="_blank">Short Comment</a><br>

    <p>Find me on <a href="https://github.com/cod3licious/" target="_blank">GitHub</a> and <a href="https://www.linkedin.com/in/franziska-horn/" target="_blank">LinkedIn</a><br>
      <a href="../index.html">Home</a> ~ <a href="mailto:hey@franziskahorn.de?Subject=Freelance%20opportunity" target="_top">Contact</a> ~ <a href="../impressum.html">Impressum</a></p>
  </footer>
</div>
</body>
</html>